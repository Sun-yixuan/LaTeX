\documentclass[a4paper,12pt, draft]{article}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{physics}
\usepackage{bm}
\usepackage[margin=1.5cm]{geometry}
\usepackage{bigfoot}
\usepackage{amsthm}
\usepackage{etoolbox}



\AtBeginEnvironment{array}{\everymath{\displaystyle}}
\newtheoremstyle{break}
  {\partopsep}
  {\topsep}%  
  {\normalfont}%
  {}%
  {\bfseries}%
  {}%
  {\newline}%
  {}%
  \theoremstyle{break}
\newtheorem{theorem}{Teorema}[section]
\newtheorem{corollary}{Corollario}[section]
\newtheorem{proposition}{Proposizione}[section]
\renewcommand*{\proofname}{\rm\bf{Dimostrazione}}
\renewcommand\qedsymbol{$\bigstar$}
\newtheorem{definition}{Definizione}[section]

\let\oldemptyset\emptyset
\let\emptyset\varnothing

\let\oldepsilon\epsilon
\let\epsilon\varepsilon

\let\oldphi\phi
\let\phi\varphi

\long\def\symbolfootnotemark[#1]#2{\begingroup%
\def\thefootnote{\fnsymbol{footnote}}\footnotetext[#1]{#2}\footnotemark[#1]\endgroup}

\long\def\symbolfootnotetext[#1]#2{\begingroup%
\def\thefootnote{\fnsymbol{footnote}}\footnotetext[#1]{#2}\endgroup}


\numberwithin{equation}{section}





\begin{document}
\title{Equazioni alle Derivate Parziali}
\author{Andrea Bonifacio}
\date{\today}
\maketitle

\newpage
\section*{Premessa}
Prima di iniziare, è necessario specificare come verranno trattati i simboli nel testo: per indicare una derivata parziale si useranno i seguenti simboli in modo interscambiabile:
$$
\begin{array}{cc}
\frac{\partial x}{\partial u}, & u_{xx} = \frac{d^2x}{du} 
\end{array}
$$

\section{Introduzione}
\subsection{Modelli Matematici}
Per modello matematico si intende un insieme di equazioni o relazioni matematiche in grado di catturare le caratteristiche di una situazione in esame. Un modello è generalmente costruito a partire da due principali caratteristiche: $$leggi\ generali\ e\ relazioni\ costitutive.$$
Le leggi generali prese in esame saranno quelle della Meccanica dei Continui e si presentano come leggi di conservazione o di bilancio (della massa, dell'energia, dei momenti...).  
Le relazioni costitutive sono ottenute sperimentalmente e dipendono solamente dal fenomeno in esame (legge di Fourier del calore, di Fick per la diffusione o di Ohm per la corrente elettrica).  
Da questa combinazione si ottiene solitamente un'\textit{equazione alle derivate parziali}.
\subsection{EDP}
Si definisce equazione alle derivate parziali una relazione del tipo
\begin{equation}
F(X_1,\ldots, x_n, u, u_{x1x1}, u_{x1x2}, \ldots, u_{x1xn}, u_{x1x1x1},\ldots) = 0
\end{equation} dove $u = u(x_1,\ldots,x_n)$ è una funzione di $n$ variabili. Si definisce ordine di una equazione il suo grado massimo di derivabilità. \\
Si distinguono due principali categorie: $lineari\ e\ nonlineari$.  
L'equazione (1.1) è lineare se F è lineare rispetto a $u$ e a tutte le sue derivate.
Equazioni lineari: 
\begin{itemize}
\item Equazione del calore $u_t- D\Delta u\symbolfootnotemark[2] = f(x,t)$ \item Laplace/Poisson: $\Delta u = f(x,t)$ 
\item Equazione delle onde: $u_{tt} - c^2 \symbolfootnotemark[3] * \Delta u = 0$
\end{itemize}
\symbolfootnotetext[2]{$\Delta u = \sum_{j = 1}^n \frac {\partial ^2 u}{\partial x_j^2}$}
\symbolfootnotetext[3]{$c(x, t)$}  
Tra i tipi di nonlinearità si distinguono tre principali categorie:
\begin{itemize}
\item Semilineari: se F è nonlineare rispetto ad $u$, ma lo è rispetto alle sue derivate. (e.g. Equazione di Fisher-Kolmogorov: $u_t - D\Delta u = f(u) = ru(1-u)$)
\item Quasilineari: se F è lineare rispetto alle derivate di $u$ di ordine massimo, con coefficienti dipendenti solo da $\bm{x}$, $u$ e dalle derivate di ordine inferiore. (e.g. Equazione di Burgers: ($x \in \mathbb{R}$) $u_t - cuu_x = \epsilon u_{xx}$, Equazione delle superfici minime: $div\left(\frac{\nabla u}{\sqrt{1+|\nabla u|^2}}\right)$
\item Completamente non lineare: se F è nonlineare rispetto alle derivate di $u$ di ordine massimo. (e.g. Equazione iconale: $|\nabla u| ^2 = c(x) \symbolfootnotemark[2] *$)
\symbolfootnotetext[2]{c = indice di rifrazione}
\end{itemize}
\subsection{Problemi ben posti}
Quando si affronta la costruzione di un modello vengono utilizzate solo alcune delle equazioni generali di campo, e le altre vengono semplificate, o direttamente eliminate. Per predire l'esistenza e/o l'unicità di una soluzione si utilizzano le \textit{condizioni al bordo del dominio e/o condizioni iniziali}. Un tipico esempio di condizione al bordo è quello di assegnare la soluzione o la sua derivata normale. 
È necessario stabilire le condizioni sui dati che abbiano le seguenti caratteristiche:
\begin{enumerate}
\item Esista almeno una soluzione
\item Esista una sola soluzione
\item la soluzione dipenda con continuità dai dati
\end{enumerate}
L'ultima affermazione è estremamente importante affinché un piccolo errore nei dati causi una piccola perturbazione nella soluzione. Questa proprietà si chiama \textbf{stabilità locale della soluzione rispetto ai dati}.
La nozione di continuità si precisa introducendo una opportuna distanza. In caso di numeri o vettori come dati una distanza può essere quella $euclidea$: se $\bm{x}$ =($x_1, x_2, \ldots, x_n$), $\bm{y}$ = ($y_1, y_2, \ldots, y_n$)
$$dist(\bm{x}, \bm{y}) =  ||\bm{x}-\bm{y}|| = \sqrt{\sum_{k=1}^n(x_k-y_k)^2}$$
Se si tratta di funzioni reali e definite su un dominio $I$, due distanze molto usate sono:
$$
\begin{array}{lcr}
dist(f,g) = \underset{I}{\max}|f-g| &\quad \quad & dist(f,g) = \sqrt{\int_I (f-g)^2}
\end{array}
$$
Un problema che possiede le caratteristiche (1, 2, 3) si dice \textbf{ben posto}, ed è il tipo di problema con cui è più comodo lavorare.
\subsection{Integrazione per parti}
Siano $$\Omega \in \mathbb{R}^n$$ un dominio limitato di classe $C^1$ e $\textbf{F}: \overline{\Omega}$ un campo vettoriale di classe $C^1(\overline{\Omega})$. Essendo $\textbf{F} \in C^1(\overline{\Omega}; \mathbb{R}^n)$ e $\boldsymbol{\nu}$ il versore normale, allora vale la formula di Gauss o della divergenza:
\begin{equation} 
\int_{\Omega} div\textbf{F} \ dx = \int_{\partial\Omega} \textbf{F} \cdot \boldsymbol{\nu} \ d\sigma \label{Integrazione per parti}
\end{equation}
che permette di ottenere la seguente identità
\begin{equation}
  \int_{\Omega} v\Delta u \, d\bm{x} = \int_{\partial\Omega} v\partial_{\bm\nu} u \, d\sigma - \int_{\Omega} \nabla v \cdot \nabla u \, d\bm{x} \label{Identità di Green}
\end{equation}
L'elemento $d\sigma$ rappresenta la superficie di $\partial\Omega$ e si può definire come:
$$d\sigma = \sqrt{1+|\nabla \phi(\bm{y}')|^2}d\bm{y}'$$
\section{Equazione di diffusione}
\subsection{Introduzione}
Come visto in precedenza, una delle equazioni che verrà analizzata è la cosiddetta equazione di diffusione, o del calore, che si può scrivere come:
\begin{equation}
u_t - D u_{xx} = f
\end{equation}
dove D è una costante positiva, definita come \textit{coefficiente di diffusione}
In una dimensione spaziale $n>1$, l'equazione ha la forma\begin{equation}
u_t - D \Delta u = f
\end{equation}
dove $\Delta$ indica l'operatore di Laplace
$$\Delta = \sum_{k=1}^n \partial_{x_k, x_k}$$
Il nome di questa equazione deriva dal fatto che è in grado di essere soddisfatta dalla temperatura in un mezzo omogeneo e isotropo rispetto alla propagazione del valore, con $f$ che rappresenta l'``intensità" della fonte di calore.  
Più in generale l'equazione rappresenta il trasporto di materia dovuto al moto molecolare del mezzo in cui è immersa, da cui il nome diffusione.
In condizioni di equilibrio l'equazione si definisce stazionaria, ossia
\begin{equation}
-D\Delta u = f
\end{equation}
che per $D=1$ è anche detta Equazione di Poisson, mentre se anche $f \equiv 0$ viene definita di Laplace, e le sue soluzioni sono definite funzioni armoniche. Con $f \equiv 0$ l'equazione si definisce \textit{omogenea} e sono da subito evidenziabili una serie di caratteristiche fondamentali.
\begin{itemize}
\item \textit{Linearità e principio di sovrapposizione}.
Se $u$ e $v$ sono soluzioni e $a, \ b$ scalari, allora anche $au+bv$ è soluzione.  
Si può dire che se $u_k(\bm{x},t)$ è soluzione di $u_t-D\Delta u = 0$ per ogni valore di $k$ e $g=g(k)$ è una funzione che si annulla abbastanza rapidamente all'infinito, allora sono soluzioni anche:
{ 
\everymath={\displaystyle}
$$\begin{array}{lcr}

\sum_{k=1}^{\infty}u_k(\bm{x},t)g(k) & \mbox{ e } & \int_{-\infty}^{+\infty} u_k(\bm{x},t)g(k)dk


\end{array}
$$
}
\item \emph{Cambio di direzione temporale}. Sia $u = u(\bm{x}, t)$una soluzione della equazione $u_t - D\Delta u = 0$, allora la funzione $v(\bm{x},-t)$ ottenuta tramite cambio di variabile sarà soluzione dell'equazione \textbf{backward}
$$v_t + D\Delta v = 0$$
L'equazione $u(\bm{x}, t)$ sarà definita, rispettivamente, \textbf{forward}. Tuttavia il cambio di variabile $\bm{x} \to -\bm{x}$ lascia invariata l'equazione (\emph{invarianza rispetto a riflessioni nello spazio}.
\item \emph{Invarianza rispetto a traslazioni spazio-temporali}.
In un dominio spazio temporale $\Omega \times (0, T)$, sia $u = u(\bm{x}, t)$ soluzione dell'equazione omogenea, dove $\Omega \subseteq \mathbb{R}^n$, allora la funzione 
$$ v(\bm{x}, t) = u(\mathbf{x \mbox{-} t}, t-s)$$
per $\bm{y}, s$ fissati è ancora soluzione in un dominio $(\Omega + \bm{y}) \times (s, s+ T)$
\item \emph{Invarianza rispetto a dilatazioni paraboliche}. La trasformazione 
$$
\begin{array}{ccc}
\bm{x} \to a \bm{x}, & t \to bt, & (a, b >0)

\end{array}
$$
rappresenta una dilatazione/contrazione spazio-temporale.  
Affinché la funzione

$$
u^*(\bm{x},t) = u(a\bm{x},bt)
$$
sia ancora soluzione della funzione omogenea, è necessario trovare delle condizioni per i due coefficienti $a \mbox{ e }b$.
Poiché:
$$ 
u_t^*(\bm{x},t)-\Delta u^* (\bm{x},t) = bu_t(a\bm{x},bt)-a^2D\Delta u(a\bm{x}, bt)
$$
allora $u^*$ è ancora soluzione dell'equazione omogenea se $b = a^2$. La dilatazione parabolica lascia dunque invariati i blocchi 
{\everymath = {\displaystyle}
$$
\begin{array}{lcr}
\frac{|\bm{x}|^2}{t}& \mbox{oppure} & \frac{\bm{x}}{\sqrt{t}}

\end{array}
$$
}
\end{itemize}
\subsection{La conduzione del calore}
Per derivare un modello matematico che descriva la conduzione del calore in un corpo rigido, si assuma un corpo omogeneo ed isotropo, con densità $\rho$ costante e che possa ricevere energia da fonte esterna. Indicato con $r$ il tasso di calore per unità di massa fornito dalla fonte esterna, allora: \\
Sia $V$ un elemento arbitrario di volume all'interno del corpo rigido, allora \emph{il tasso di variazione dell'energia di $V$ eguaglia il flusso di calore attraverso il bordo $\partial V$ più quello dovuto alla sorgente esterna}.  
Indicato con $e = e(\bm{x}, t)$ l'energia interna per unità di massa, la quantità di energia in $V$ è data da 
{
\everymath = {\displaystyle}
$$
\begin{array}{lcr}


\int_V e \rho \  d\bm{x} & \mbox{e il suo tasso di variazione da} &
\frac{d}{dt}\int_V e\rho \ d\bm{x} = \int_V e_t \rho \ d\bm{x}
\end{array}
$$
}
Il vettore \emph{flusso di calore}  sarà \textbf{q}. Più precisamente se $d\sigma$ è l'elemento d'area contenuto in $\partial V$ e $\boldsymbol{\nu}$ il versore normale esterno, il prodotto $\mathbf{q} \cdot \boldsymbol{\nu}$ rappresenta la velocità con cui l'energia fluisce tramite $d\sigma$. Il flusso entrante in $\partial V$ sarà 
$$
-\int_{\partial V} \mathbf{q}\cdot \boldsymbol{\nu} \ d\sigma 
$$
mentre il contributo della fonte esterna sarà
$$\int_V r\rho \ d\bm{x}$$
Per bilanciare l'energia allora sarà necessario che 
\begin{equation}
\int_V e_t\rho \ d\bm{x} = \underset{\mbox{(Teorema di Gauss)}}{-\int_V div\mathbf{q} \ d\bm{x}} + \int_{V} r \rho \ d\bm{x}
\end{equation}
Che si può convertire nell'equazione, data l'arbitrarietà di $V$ nell'equazione:
\begin{equation}
e_t \rho = - div\mathbf{q} + r\rho
\end{equation}
che costituisce l'equazione fondamentale della diffusione del calore.
Inoltre siano da assumere:
\begin{itemize}
\item \textbf{Legge di Fourier} per la conduzione del calore
\begin{equation}
\mathbf{q} = -k \nabla \theta
\end{equation}
dove $\theta$ è la temperatura assoluta e $k>0$ la conduttività termica, dipendente dalle proprietà del materiale. Il segno negativo tiene conto del fatto che il calore tende a fluire verso le regioni dove la temperatura è minore. Generalmente la variazione di $k$ è trascurabile, per cui si può considerare costante
\begin{equation}
div\mathbf{q} = -k\Delta \theta
\end{equation}
\item L'energia interna è proporzionale alla temperatura assoluta
\begin{equation}
e = c_v\theta
\end{equation}
con $c_v$ che è il calore specifico del materiale e che si può assumere anch'esso costante.
\end{itemize}
La (2.5) allora diventa
\begin{equation}
\theta_t = \frac{k}{c_v \rho} \Delta \theta + \frac{1}{c_v} r
\end{equation}
che è l'\emph{equazione di diffusione} con $D=\frac{k}{(c_v\rho )}$ e
 $f=\frac{r}{c_v}$
\subsection{Problemi ben posti (n=1)}
Quali sono i problemi ben posti per l'equazione di diffusione?  
In uno spazio monodimensionale si tratterà di osservare l'evoluzione della temperatura $u$ in una sbarra cilindrica di sezione $A$ e lunghezza $L$ molto superiore al raggio, \emph{isolata termicamente ai lati}.
Utilizzando un modello unidimensionale, su può identificare la sbarra in un segmento $0\leq x \leq L$. Per affrontare in modo ottimale il problema, oltre all'equazione di diffusione, è necessario stabilire:
\begin{itemize}
\item \emph{Condizioni iniziali}, ossia è necessario conoscere lo stato iniziale del sistema per studiarne l'evoluzione, che in questo caso è $u(x, 0) = g(x) \quad 0 \leq x \leq L$

\item \emph{Condizioni al bordo}, ossia mantenere il sistema in uno stato controllato. Tre possibili condizioni al bordo sono:
\begin{enumerate}
\item \emph{Condizioni di Dirichlet}, cioè assegnare un valore ai due estremi della sbarra $$u(0, t) = h_1(t), \quad u(L,t) = h_2(t) \qquad t \in (0, T]$$
\item \emph{Condizioni di Neumann}, permettono di mantenere sotto osservazione la sbarra attraverso il flusso di calore entrante/uscente dagli estremi adottando la legge di Fourier
$$
\phi_{\theta}(x = 0) = -ku_x(0,t), \qquad \phi_{\theta}
= (x = L) ku_x(L,t)
$$
con $k > 0$ costante di conduttività termica, allora si assegnano due valori agli estremi
$$
-u_x(0,t) = h_1(t), \quad u_x(L,t) = h_2(t), \qquad t \in (0,T]
$$
\item \emph{Condizioni di Robin (o radiazione)}, una condizione che deriva dalla legge lineare del raffreddamento di Newton, ossia, se tutto l'ambiente circostante si trova a una temperatura $U$ e il flusso di calore entrante in $x = L$ sia proporzionale alla differenza $U-u$ ossia
$$
ku_x(L, t) = \gamma (U-u(L,t)) \qquad t \in (0,T]
$$
con $\gamma >0$. Si possono allora riscrivere le condizioni di Robin come
$$
u_x(L,T) +\alpha \symbolfootnotemark[2] u(L,t) = \beta \symbolfootnotemark[3] \qquad t \in (0,T]
$$
\symbolfootnotetext[2]{$\alpha  = \frac{\gamma}{k}$}
\symbolfootnotetext[3] {$\beta = \frac{\gamma U}{k}$}
\end{enumerate}
Quando $h_1, h_2$ sono nulli, si dice che le condizioni al bordo sono \emph{omogenee}
\end{itemize}
Tuttavia nessuna \emph{condizione finale} per $0 < x < L, \quad t = T$ è assegnata, Le uniche condizioni assegnabili sono sulla frontiera parabolica del cilindro $Q_T$, indicata da $\partial_p Q_T$, data dall'unione della base $[0, L] \times \{t=0\}$ e dalla parte laterale costituita dai punti $(0,t) \mbox{ e } (L,t)$ con $0 \leq t \leq T$. \\
Si può scrivere allora il \emph{problema di Cauchy globale}
\begin{equation}
\begin{cases}
u_t -D u_{xx} = f \qquad \qquad x \in \mathbb{R}, 0<t<T\\
u(x, 0) = g(x) \qquad \qquad x\in \mathbb{R}\\
\mbox{+ condizioni per } x \to \pm \infty
\end{cases}
\end{equation}

\subsection{Metodo di separazione delle variabili}
Il problema da analizzare è quello di una sbarra di lunghezza $L$ è tenuta inizialmente a temperatura $\theta_0$. Successivamente l'estremo $x = L$ viene sottoposto a una temperatura $\theta_1 > \theta_0$. Il modello atto a rappresentare questa situazione è l'\emph{equazione di diffusione}
$$
\begin{cases}
\theta_t -D \theta_{xx} = 0 & t > 0,\ 0 \leq x \leq L\\
\theta(x, 0) = \theta_0  & 0 \leq x \leq L\\
\theta(0,t) = \theta_0, \quad \theta(L,t)=\theta_1 & t >0
\end{cases}
$$
Il comportamento da analizzare sarà quello a regime, per cui $t$ sarà illimitato. Uno dei metodi che si possono utilizzare è quello della \emph{separazione delle variabili}, ma è necessario applicare delle modifiche al problema.
\begin{itemize}
\item \emph{Variabili adimensionali}. Il problema va riformulato utilizzando variabili non dipendente dalla unità di misura, per cui la variabile $x$, espressa come una lunghezza, può essere sostituita dalla variabile $y$, ossia
$$y = \frac{x}{L}$$
che, essendo un rapporto tra lunghezze, è una variabile adimensionale. \\
Il tempo va riscalato, e per farlo bisogna utilizzare la costante $D$ che ha dimensioni $$
lunghezza^2 \times tempo^{-1}
$$
per cui una costante $\tau
= \frac{L^2}{D}$ avrà dimensione temporale e permette di trovare la variabile $s$:
$$s = \frac{t}{\tau}$$
Passaggio analogo per la temperatura, che verrà trasformata in un rapporto tra temperature
\begin{equation}
u(y,s) = \frac{\theta(Ly,\tau s)-\theta_0}{\theta_1 -\theta_0}
\end{equation}

Le condizioni iniziali diventano allora:
{\everymath = {\displaystyle}
$$
\begin{array}{ll}
u(y, 0) = \frac{\theta(Ly, 0) - \theta_0}{\theta_1 -\theta_0} = 0, & 0 \leq y \leq 1 \\
u(0, s) = \frac{\theta(0, \tau s) - \theta_0}{\theta_1 - \theta_0} = 0, & u(1, s) = \frac{\theta(L, \tau s) - \theta_0}{\theta_1 - \theta_0} = 1

\end{array}
$$
}
La (2.11) permette di ricavare altre due relazioni fondamentali
{\everymath = {\displaystyle}
$$
\begin{array}{l}
(\theta_1 -\theta_0) u_s = \pdv{t}{s} \theta_t=\tau
\theta_t = \frac{L^2}{D} \theta_t \\
(\theta_1 -\theta_0) u_{yy} = \left(\pdv{x}{y}\right)^2 \theta_{xx} = L^2 \theta_{xx}

\end{array}
$$
}
Sapendo inoltre, dalle condizioni del problema che $\theta_t = D \theta_{xx}$ allora
$$(\theta_1 - \theta_0) (u_s -u_{yy}) = \frac{L^2}{D}\theta_t - L^2 \theta_{xx} = \frac{L^2}{D} D\theta_{xx} - L^2 \theta_{xx} = 0$$
Si ottiene così $u_s - u_{yy} = 0$ con condizioni iniziali $u(y,0) = 0$
\begin{equation}
u(0,s) = 0,\quad u(1, s) = 1
\end{equation}

\item \emph{Soluzione stazionaria}. Il metodo di separazione delle variabili richiede di ricavare una soluzione $u^{St}$ che si dimentichi della condizione iniziale e soddisfi solamente l'equazione $u_{yy} = 0$ oltre alle condizioni (2.12), da cui si trova
$$u^{St}(y) = y$$
che si trasforma nelle variabili originali
$$\theta^{St}(x) = \theta_0 + (\theta_1 -\theta_0) \frac{x}{L}$$
\item \emph{Il regime transitorio} Per rappresentare il regime transitorio si utilizza
$$
U(y,s) = u^{St}(y,s) - u(y,s) = y -u(y,s)
$$
$U$ rappresenta il regime transitorio che per $s \to \infty$ tenderà a zero. $U$ soddisfa l'equazione $u_s - u_{yy} = 0$ con le seguenti condizioni 
\begin{equation}
\begin{cases}
U(y,0) = y & \qquad 0 <y< 1\\
U(0,s) = 0 & \qquad s>0\\
U(1,s) = 0 & \qquad s >0
\end{cases}
\end{equation}
\item \emph{Separazione delle variabili} Sfruttando la natura lineare del problema si può costruire una soluzione sovrapponendo due soluzioni della forma $w(s)v(y)$ in cui le variabili $s \mbox{ e } y$ si presentano separate. Fondamentale \textbf{avere condizioni al bordo omogenee}.
\end{itemize}

Una volta stabilito ciò si può cercare una soluzione della forma $$
U(y,s) = w(s)v(y)
$$
con $v(0) = v(1) = 0$.
Poiché $U_s - U_{yy} = w'(s)v(y) - w(s)v''(y) = 0$
si ottiene separando le due variabili
\begin{equation}
\frac{w'(s)}{w(s)} = \frac{v''(y)}{v(y)}
\end{equation}
che è una identità valida per $\forall s > 0 \mbox{ e } \forall y \in (0,1)$.
Tale identità è possibile solo nel caso in cui entrambi i membri siano uguali a una costante comune, definita $\lambda$. Ossia $$
v''(y) - \lambda v(y) = w'(s) - \lambda w(s)$$
Per la formula sopracitata vi sono tre possibili soluzioni per l'integrale
\begin{itemize}
\item[A)] $\lambda = 0, \ v(y) = A +By \mbox{ (A, B costanti arbitrarie)}$ e dalle condizioni $v(0) = v(1) = 0$ si ottiene $A=B=0$
\item[B)] $\lambda > 0,\ \lambda = \mu^2 > 0$ allora $$
v(y) = Ae^{-\mu y} + Be^{\mu y}
$$
e le condizioni iniziali implicano sempre $A=B=0$
\item[C)] $\lambda = -\mu^2 < 0$ allora
$$
v(y) = A\, \sin{\mu y}+B\, \cos{\mu y}
$$
\end{itemize}
Imponendo le condizioni iniziali
\begin{eqnarray*}
v(0) = B = 0 \\
v(1) = A \sin{\mu} + B\cos{\mu} = 0
\end{eqnarray*}
per cui $A \mbox{ arbitrario }, \ B = 0, \ \mu = m\pi, \ m= 1,2, \ldots$
In questo caso si otterranno soluzioni non nulle del tipo 
$$
v_m(y) = A\, \sin{m} \pi y
$$
Tale problema si definisce \emph{problema agli autovalori} con i valori $\mu_m$ che si chiamano \emph{autovalori} e $v_m$ sono le corrispondenti \emph{autofunzioni}.
Assegnando a $\lambda = -\mu^2 = -m^2\pi^2$ la funzione $w'(s) - \lambda w(s) = 0$ ha come integrale generale
$$w_m(s) = Ce^{-m^2-\pi^2s} \, \sin{m\pi y} \qquad \mbox{ (C costante arbitraria)}$$ 
Si ottengono soluzioni del tipo 
$$
U_m(y,s) = A_me^{-m^2\pi^2s}\, \sin{m\pi y}
$$
Nessuna delle soluzioni $U_m$ soddisfa la condizione $U(y,0) = y$, ma una soluzione si può approssimare sommando tutte le soluzioni 
\begin{equation}
U(y,s) = \sum_{m=1}^{\infty} A_m \, e^{-m^2\pi^2s} \, \sin{m\pi y}
\end{equation}

È lecito cercare di capire come scegliere le costanti $A_m$ in modo che la condizione
{\everymath ={\displaystyle}
$$
\begin{array}{lr}
U(y,0) = \sum_{m=1}^{\infty} A_m  \, \sin{m\pi y} = y & \qquad
0 \leq y \leq 1
\end{array}
$$
}
sia verificata.   
Per fare ciò bisogna ricorrere allo \emph{sviluppo di una funzione in serie di Fourier}, in particolare della funzione $f(y) = y$ nell'intervallo $(0,1)$. Poiché le condizioni di Dirichlet sono omogenee agli estremi, l'idea più conveniente è quella di sviluppare una serie di soli seni, ossia \emph{una funzione dispari periodica di periodo 2} che coincida con $y$ nell'intervallo $(0,1)$.  
Per calcolare i coefficienti di Fourier si usa la formula

\begin{equation*}
\begin{aligned}
A_k  = 2 \int_0^2 y\, \sin{k \pi y} \, dy = -\frac{2}{k \pi}[y\,  \cos{ \pi y}]_0^1 + \frac{2}{k \pi} \int_0^1 \cos{k \pi y}\, dy = & \\
 =
 -2 \frac{\cos{k \pi}}{k \pi}
 = (-1)^{k+1} \frac{2}{k \pi} \sin {k \pi y}
\end{aligned}
\end{equation*}
Lo sviluppo di $f(y) = y$ è
$y = \sum_{m = 1}^{\infty} (-1)^{m+1} \frac{2}{m \pi} \sin{m \pi y}$
che però non è valido per esempio in $ y = 1$, dove ha valore $f(1) = 0$. Dalla teoria delle serie di Fourier questo sviluppo è valido nell'intervallo $(-1,1)$, mentre agli estremi è nulla. Tale serie converge uniformemente in ogni intervallo $[a,b] \subset (-1,1)$ 
Tale uguaglianza vale anche in media quadratica, o nel senso della convergenza $L^2$  

$$
\int_0^1[y-\sum_{m=1}^N(-1)^{m+1} \frac{2}{m \pi} e^{-m^2 \pi^2s} \sin{m\pi y}]^2dy \to 0 \qquad \mbox{ per } N \to +\infty
$$
Dunque al momento l'unica soluzione possibile è
\begin{equation}
U(y,s) = \sum_{m=1}^{\infty} (-1)^{m+1} \frac{2}{m \pi} e^{-m^2\pi^2s} \sin{m \pi y}
\end{equation}
Poiché il dato iniziale è assunto in media quadratica, ossia
\begin{equation}
\lim_{s \to 0} \int_0^1[U(y,s)-y]^2dy=0
\end{equation}
Grazie all'uguaglianza di Bessel\footnote{Siano $C_n$ i coefficienti di Fourier della funzione $f(x)$ allora\\
 {\everymath ={\displaystyle} $\sum_{n=-\infty}^{\infty} |C_n|^2 = \frac{1}{2\pi}\int_{-\pi}^{\pi}|f(x)|^2dx$}} si ottiene 
\begin{equation}
\int_0^1 [U(y,s) - y]^2dy = \frac{4}{\pi^2}\sum_{m+1}^{\infty} \frac{(e^{-m^2\pi^2s}-1)^2}{m^2}
\end{equation}
e per $s \geq 0$ si ha
$$
\frac{(e^{-m^2\pi^2s}-1)^2}{m^2} \leq \frac{1}{m^2}
$$
e la serie $\sum \frac{1}{m^2}$ è convergente, dunque per il test di Weierstrass anche la serie (2.18) converge uniformemente in $[0, \infty)$ e si può passare al limite per $s \to 0^+$ ottenendo la (2.17).
Inoltre, nonostante $U_m$ sia soluzione dell'equazione del calore, non vi è la certezza che lo sia anche $U$. Tale affermazione si verifica differenziando sotto il segno di somma, ossia 
\begin{equation}
(\partial_s - \partial_{yy}) U(y,s) = \sum_{m=1}^{\infty}(\partial_s - \partial_{yy})U_m(y,s) = 0
\end{equation}
$U$ è una sovrapposizione di vibrazioni sinusoidali di frequenza $m$ sempre maggiore, con ampiezza fortemente attenuata dalla presenza dell'esponenziale. La rapida convergenza a zero del termine generale della (2.16) e delle sue derivate rispetto al tempo e allo spazio permette di scambiare le operazioni di derivazione con quella di somma. Più precisamente si ha $$\frac{\partial U_m}{\partial s} = \frac{\partial^2 U_m}{\partial y^2} = (-1)^{m+2}2m \pi e^{-m^2\pi^2s}\sin{m\pi y}$$ 
e se $s\leq s_0 < 0$
$$\bigg\lvert \frac{\partial U_m}{\partial s} \bigg\rvert , \bigg\lvert \frac{\partial^2 U_m}{\partial y^2}\bigg\rvert \leq 2 m \pi e^{-m^2\pi^2s}.$$
Dal momento che 
$$\sum_{m=1}^{\infty} me^{-m^2\pi^2s_0}$$
è una serie convergente, per il test di Weierstrass anche le serie
$$\sum_{m=1}^{\infty} \frac{\partial U_m}{\partial s} \quad \mbox{ e } \quad \sum_{m=1}^{\infty} \frac{\partial^2 U_m}{\partial y^2}$$
convergono uniformemente in $[0,1] \times [s_0, \infty)$, e $U$ è soluzione di $u_s - u_{yy} = 0$. Verificando le condizioni di Dirichlet per $s_0 > 0$
$$U(z,s) \to 0 \mbox{ per } (z,s) \to (0,s_0) \mbox{ oppure } (z,s) \to (1,s_0)$$
che è sempre vero per la convergenza uniforme della serie (2.16) che permette di passare al limite sotto il segno di somma in ogni regione $[0,1] \times (b, +\infty)$ con $b>0$. Fino alla frontiera laterale $[0,1] \times (b, +\infty)$ $U$ avrà derivate continue di ogni ordine. \\
Ma è l'unica soluzione? \\
Per rispondere a questa domanda è necessario usare un metodo detto “dell'energia".
Moltiplicando per $u$ l'equazione 
\begin{equation}
u_s - u_{yy} = 0
\end{equation}
e integrando rispetto a $y$ su $[0,1]$, mantenendo $s > 0$ fissato si ottiene
\begin{equation}
\int_0^1 uu_s\, dx - \int_0^1 uu_{yy}\, dy = 0
\end{equation}
e dato che
$$\int_0^1 uu_s \, dx = \frac{1}{2} \int_0^1 \frac{d}{ds}(u^2) dy = \frac{1}{2}\frac{d}{ds}\int_0^1 u^2dy$$
integrando per parti 
$$\int_0^1 uu_{yy}\, dy = [u(1,s)u_y(1,s)-u(0,s)u_y(0,s)] - \int_0^1 (u_y)^2 dy$$
la (2.21) è uguale a
$$\frac{1}{2}\frac{d}{ds}\int_0^1 u^2dy = \int_0^1 uu_{yy}\, dy = [u(1,s)u_y(1,s)-u(0,s)u_y(0,s)] - \int_0^1 (u_y)^2 dy$$
Se $u$ e $v$ sono soluzioni del problema di Cauchy-Dirichlet, ossia con gli stessi dati iniziali e al bordo, data $w = u - v$ soluzione dell'equazione $w_s -w_{yy} = 0$ con dati al bordo e iniziali nulli si trova allora
\begin{equation}
\frac{1}{2}\frac{d}{ds}\int_0^1 w^2dy = \int_0^1 uu_{yy}\, dy = - \int_0^1 (w_y)^2 dy
\end{equation}
poiché
$$w(1,s)w_y(1,s)-w(0,s)w_y(0,s) = 0.$$
La (2.22) indica che la funzione non negativa
$$E(s) = \int_0^1 w^2(y,s) \, dy$$
ha derivata minore o uguale a zero, quindi è decrescente. Inoltre, poiché il dato è assunto in media quadratica e il dato iniziale è nullo, segue che
$$E(s) \to 0 \quad \mbox{ se } s \to 0^+$$
allora $E(s) = 0$ se $s > 0$. \\
Poiché $w^2(y,s)$ è continua e non negativa se $s> 0, w = 0 \Longrightarrow u = v$.
Ritornando al problema originale la soluzione risulta così enunciata
$$\theta(x,t) = \theta_0 + (\theta_1 - \theta_0)\frac{x}{L} - (\theta_1 - \theta_0)\sum_{m=1}^{\infty}(-1)^{m+1}\frac{2}{m \pi}e^{\frac{-m^2 \pi^2 D}{L}t} \sin{ \left(\frac{m\pi}{L}x\right)}$$
Da questa formula si trova conferma dell'ipotesi iniziale, infatti tutti i termini della serie convergono a zero esponenzialmente per $t \to +\infty$ per cui la temperatura di assesta, a regime, sulla soluzione stazionaria
$$
\theta(x,t) \to \theta_0 + (\theta_1 - \theta_0) \frac{x}{L} \qquad t \to + \infty
$$
Inoltre, tra i vari termini della serie, il più lento a decadere, e quindi quello che in maggior misura determinerà l'andamento della temperatura, è $m = 1$, che ha valore
$$
\frac{2}{\pi}e^{\frac{-\pi^2 D}{L^2}t}\sin{\left(\frac{\pi}{L}x\right)}
$$
e andamento sinusoidale smorzato, con ampiezza massima $\frac{2}{\pi} e^{\frac{-\pi^2 D}{L^2}t}$. In un tempo $t$ di ordine $\frac{L^2}{4D}$ l'ampiezza diminuisce di $e^{\frac{-\pi^2}{4}}$ circa l'$8\%$ del valore iniziale. Dunque per raggiungere il valore a regime sarà necessario un tempo di grandezza $\frac{L^2}{D}$.
\subsection{Problemi in dimensione $\mathbf{n>1}$}
Ragionando in dimensione spaziale $n$ generica, si tratta di voler determinare la temperatura di un corpo che occupi nello spazio un dominio limitato $\Omega$ nell'intervallo di tempo $[0,T]$ con la temperatura definita da una funzione $u = u(\bm{x}, t)$ che soddisfi l'equazione $u_t - D\Delta u = f$ nel cilindro spazio-temporale
$$Q_T = \Omega \times (0, T)$$
È necessario assegnare per prima cosa la distribuzione iniziale della temperatura
$$u(\bm{x}, 0) = g(\bm{x}) \qquad \bm{x} \in \overline{\Omega}$$ 
dove $\overline{\Omega} = \Omega\cup \partial \Omega$ indica la chiusura di $\Omega$.\\
Per modellare l'interazione con l'ambiente circostante sono necessarie opportune condizioni al bordo, tra cui:
\begin{itemize}
\item \textbf{Condizioni di Dirichlet.} Si mantiene a un determinato livello la temperatura in ogni punto di $\partial \Omega$. 
$$u(\bm{\sigma}, t) = h(\bm{\sigma}, t) \qquad \bm{\sigma} \in \partial \Omega, \quad t \in (0,T]$$
\item \textbf{Condizione di Neumann.} Come osservato in precedenza, viene assegnato un flusso di calore al bordo di $\Omega$. Indicato con $\bm{\nu} = \bm{\nu}(\bm{\sigma})$ il versore normale a $\partial\Omega$ orientato verso l'esterno, si ottiene, tramite Fourier, che il flusso di calore $\mathbf{q} = -k\nabla u$, da cui si ottiene il flusso entrante
$$
-\mathbf{q}\cdot\bm{\nu} = k\nabla u \cdot \bm{\nu} = k \partial_{\bm{\nu}}u
$$
La condizione di Neumann impone di assegnare al bordo la derivata normale a ogni punto $\bm{\sigma}$ ottenendo
$$
\partial_{\bm{\nu}}u(\bm{\sigma},t) = h(\bm{\sigma}, t) \qquad \bm{\sigma} \in \partial \Omega, \quad t \in (0,T]
$$
\item \textbf{Condizione di Robin.} Secondo la legge del raffreddamento di Newton il flusso attraverso il bordo di $\Omega$ dipende linearmente dalla differenza tra la temperatura ambiente $U$ e la temperatura del corpo $u$. Ossia 
$$
-\mathbf{q}\cdot\bm{\nu} = \gamma(U-u) \qquad \gamma > 0
$$
Si ottiene dalla legge di Fourier
$$
\partial_{\bm{\nu}} u + \alpha u =  \beta \qquad \mbox{su }\partial\Omega
$$
con $\alpha = \frac{\gamma}{k} > 0, \beta = \frac{\gamma U}{k}$
\item \textbf{Condizioni miste.} Alternativamente si possono imporre diverse condizioni a diversi punti della frontiera di $\Omega$. Considerando due sottoinsiemi non vuoti e disgiunti $\partial_D\Omega$ e $\partial_N\Omega$ tali che $\partial\Omega = \overline{\partial_D\Omega} \cup \partial_N\Omega$. A questo punto si possono assegnare diverse condizioni a diversi punti dell'insieme.
\item \textbf{Frontiera parabolica.} Non sono state assegnate delle condizioni finali per $t = T, \bm{x} \in \Omega$. Le condizioni sono soltanto sulla frontiera parabolica del cilindro $Q_T$, dato dall'unione di $\overline{\Omega} \times \{t = 0\}$ e dal bordo laterale $S_T = \partial\Omega \times (0, T]$ per cui la frontiera parabolica sarà:
$$
\partial_p Q_T = (\overline{\Omega} \times \{t = 0\}) \cup S_T
$$
\end{itemize}
\subsection{Principi di massimo e minimo}
Il flusso del calore verso regioni con temperature minori permette alla soluzione della equazione del calore di assumere massimi e minimi globali sulla frontiera parabolica. Il seguente teorema a valore per funzioni continue fino al bordo del cilindro, con derivata prima temporale e derivate seconde legate alle variabili spaziali continue nell'interno $Q_T$. Sarà indicata come $\mathcal{C}^{2,1}(Q_T)\cap \mathcal{C}(\overline{Q}_T)$ questa classe di funzioni.
\begin{theorem}[Principio di massimo/minimo debole]
Sia $w \in \mathcal{C}^{2,1}(Q_T)\cap \mathcal{C}(\overline{Q}_T)$ tale che
$$
w_t - D\Delta w = q \leq 0 \qquad (\mbox{risp. } \geq 0) \mbox{ in }Q_T
$$
Allora il massimo (risp. minimo) di $w$ è assunto sulla frontiera parabolica $\partial_p Q_T$ di $Q_T$:
$$
\max_{\overline{Q}_T}w = \max_{\partial_p Q_T}w \qquad (\mbox{risp. } \min_{\overline{Q}_T}w = \min_{\partial_p Q_T}w)
$$
In particolare, se $w$ è negativa (risp. positiva) su $\partial_p Q_T$, allora è negativa (risp. positiva) in tutto $\overline{Q}_T$.
\end{theorem}
\begin{proof}
La frontiera parabolica è costituita dai punti sulla base del cilindro $Q_T$ e da quelli sulla parte laterale. Sia $q \leq 0$. Per il principio di minimo la dimostrazione è analoga. Sono necessari due passi:
\begin{itemize}
\item \textit{Passo 1}. Sia $\epsilon > 0$ tale che $T - \epsilon > 0$. Bisogna dimostrare che
\begin{equation}
\max_{\overline{Q}_{T-\epsilon}} = \max_{\partial_p Q_{T-\epsilon}}u
\end{equation}

Posto $u = w- \epsilon t$, allora
\begin{equation}
u_t - D\Delta u = q -\epsilon < 0
\end{equation}
e il massimo di $u$ in $\overline{Q}_{T- \epsilon}$ è assunto in un punto di $\partial_p Q_{T-\epsilon}$. Infatti, si immagini che ciò non sia vero. Allora esiste un punto ($\bm{x}_0, t_0$), $\bm{x}_0 \in \Omega$, $0 < t_0 \leq T - \epsilon$, tale che $u$($\bm{x}_0, t_0$) è il massimo di $u$ in $\overline{Q}_{T-\epsilon}$. \\
Ma allora, essendo $u_{x_j x_j} (\bm{x}_0, t_0) \leq 0$ per ogni $j=1, \ldots, n$ si avrebbe
$$
\Delta u (\bm{x}_0, t_0) \leq 0
$$ 
mentre
$$
\begin{array}{ll}
u_t(\bm{x}_0,t_0) = 0 &\quad \mbox{ se } t < T-\epsilon \\
u_t(\bm{x}_0, t_0) \geq 0 &\quad \mbox{ se } t_0 = T-\epsilon
\end{array}
$$
In ogni caso, si otterrebbe $u_t(\bm{x}_0, t_0) - D\Delta u (\bm{x}_0, t_0) \geq 0$, incompatibile con la (2.24). \\
Pertanto,
$$\max_{\overline{Q}_{T - \epsilon}} u = \max_{\partial_p Q_{T-\epsilon}} u$$
ed essendo $w \leq u$, si ha
$$
\max_{\partial_p Q_{T-\epsilon}}u \leq \max_{\partial_p Q_{T-\epsilon}}w
$$
D'altra parte, $w \leq u + \epsilon T$ in $\overline{Q}_T$, quindi 
$$
\max_{\partial_p Q_{T-\epsilon}}w \leq \max_{\partial_p Q_{T-\epsilon}}u + \epsilon T \leq \max_{\partial_p Q_{T}}w + \epsilon T
$$
che è la (2.23).
\item \textit{Passo 2}. Poiché $w$ è continua in $\overline{Q}_T$, se ne deduce che 
$$
\max_{\overline{Q}_{T-\epsilon}} w \leq \max_{\overline{Q}_T} w \qquad \mbox{ per } \epsilon \to 0
$$
Passando al limite per $\epsilon \to 0$ nella (2.23) si ottiene
$$
\max_{\overline{Q}_{T-\epsilon}}w \leq \max_{\partial_p Q_T} w
$$
\end{itemize}
\end{proof}
\begin{definition}
Le funzioni tali che $w_t - D\Delta w \leq 0$ (risp. $\geq 0$) si chiamano sottosoluzioni (risp. soprasoluzioni) dell'equazione del calore. \\
Conseguenza immediata del teorema (2.1) è che: se in $Q_T$ si ha
$$w_t -D \Delta w = 0$$
il massimo e il minimo di $w$ sono assunti sulla frontiera parabolica $\partial_p Q_T$ di $Q_T$. In particolare
$$
\min_{\partial_p Q_T} w \leq w(\bm{x},t) \leq \max_{\partial_p Q_T} \qquad \mbox{per ogni} (\bm{x}, t) \in \overline{Q}_T$$
\end{definition}
\begin{corollary}[Confronto, unicità e stabilità. Problema di Cauchy-Dirichlet]
Siano $v$ e $w$ soluzioni in $\mathcal{C}^{2,1}(Q_T)\cap \mathcal{C}(\overline{Q}_T)$ di
$$
v_t-D\Delta v_t = f_1, \qquad w_t -D\Delta w =f_2
$$
con $f_1, f_2$ limitate in $Q_T$. Allora:
\begin{itemize}
\item[a)] se $v \geq w$ su $\partial_p Q_T$ e $f_1 \geq f_2$ in $Q_T$, si ha $v \geq w$ in tutto $Q_T$
\item[b)] vale la stima di stabilità 
$$
\max_{\overline{Q_T}}|v - w| \leq \max_{\partial_p Q_T}|v - w| + T\sup_{\overline{Q}_T}|f_1-f_2|
$$
\end{itemize}

Dalla stima di stabilità si ricava che la soluzione dipende con continuità dai dati, infatti se $v = g_1$ e $w = g_2$ su $\partial_p Q_T$ e 
$$
\max_{\overline{Q}_T} |g_1 - g_2| \leq \epsilon, \sup_{\overline{Q}_T}|f_1 - f_2| \leq \epsilon
$$
allora 
$$
\max_{\overline{Q}_T} |v - w| \leq \epsilon(1 + T).
$$
\end{corollary}
\begin{corollary}
Il problema di Cauchy-Dirichlet
$$
\begin{cases}
u_t -D\Delta u = f & \qquad \mbox{in } Q_T \\
u = g & \qquad \mbox{su }\partial_p Q_T
\end{cases}
$$
ha una sola soluzione in $\mathcal{C}^{2,1}(Q_T)\cap \mathcal{C}(\overline{Q}_T)$
\end{corollary}
\begin{proof}
Siano $v, u$ soluzioni del problema di Cauchy-Dirichlet, e sia $w = v - u$ soluzione di
$$
\begin{cases}
w_t - D\Delta w = 0 & \mbox{in }Q_T \\
w = 0 & \mbox{su } \partial_p Q_T
\end{cases}
$$
allora se 
$$
\min_{\partial_p Q_T} w = \max_{\partial_p Q_T} w = 0 \Longrightarrow w = 0 \mbox{ in } \overline{Q}_T
$$
\end{proof}
Il teorema (2.1) non esclude la possibilità che il massimo o il minimo possano essere assunti anche in un punto al di fuori della frontiera parabolica. Vale quindi anche un risultato più preciso, detto:
\begin{theorem}[Principio di massimo forte]
Sia $u \in \mathcal{C}^{2,1}(Q_T)\cap \mathcal{C}(\overline{Q}_T)$ una sottosoluzione dell'equazione di diffusione. Se $u$ assume il massimo $M$ in un punto $(\bm{x}_1, t_1)$ con $\bm{x}_1 \in \Omega$ e $0 < t_1 \leq T$ allora $u \equiv M$ in $\overline{\Omega} \times [0, t_1]$.
L'enunciato analogo vale per il minimo se $u$ è soprasoluzione in $Q_T$
\end{theorem}
Per calcolare la pendenza con la quale $u$ raggiunge un punto di massimo o minimo sulla frontiera laterale $S_T$ in un punto dove esiste una sfera tangente internamente a $\Omega$.
\begin{theorem}[Principio di Hopf]
Sia $u \in \mathcal{C}^{2,1}(Q_T)\cap \mathcal{C}(\overline{Q}_T)$ una sottosoluzione dell'equazione di diffusione. Posto che:
\begin{enumerate}
\item $\bm{x}_0 \in \partial \Omega$ ha la proprietà della sfera interna, ossia esiste una sfera $B_R \subset \Omega$ tangente a $\partial \Omega$ in $\bm{x}_0$
\item ($\bm{x}_0, t_0$)$\in S_T$ è punto di minimo per $u$ in $\overline{Q}_T$ e inoltre $u(\bm{x}_0, t_0) < u(\bm{x}, t)$ in $\Omega \times [0, t_0)$
\item esiste $\partial_{\bm{\nu}}u(\bm{x}_0, t_0)$
\end{enumerate}
Allora 
$$
\partial_{\bm{\nu}} u(\bm{x}_0, t_0) < 0
$$
Se il punto è di massimo, per ottenere lo stesso risultato vanno invertite tutte le disuguaglianze. Il teorema esprime chiaramente che la derivata normale \textbf{non} può essere nulla in $(\bm{x}_0, t_0)$
\end{theorem}
\begin{corollary}[Unicità per i problemi di Cauchy-Neumann/Robin]
Esiste un'unica $u \in \mathcal{C}^{2,1}(Q_T)\cap \mathcal{C}(\overline{Q}_T)$ tale che $\partial_{\bm{\nu}}u$ esiste su $\partial \Omega$, soluzione di 
\begin{equation}
\begin{cases}
u_t - D\Delta u = f & \qquad \mbox{in } Q_T \\
\partial_{\bm{\nu}} u + \alpha u = h & \qquad \mbox{su } S_T \quad (\alpha > 0) \\
u(\bm{x}, 0) = g(\bm{x} & \qquad \mbox{in } \Omega
\end{cases}
\end{equation}
\end{corollary}
\begin{proof}
Siano $u$ e $v$ soluzioni della (2.25) in grado di soddisfare le ipotesi del teorema, allora la soluzione $w = u - v$ è soluzione dell'equazione omogenea, con $w(\bm{x}, 0) = 0 \mbox{ e } \partial_{\bm{\nu}}w + \alpha w = 0$ su $S_T$. Se $w$ è costante allora è nulla, mentre se dovesse avere un massimo positivo in $(\bm{x}_0, t_0)$ quest'ultimo dovrebbe essere $(\bm{x}_0, t_0) \in S_T$ e $w(\bm{x}, t) < w(\bm{x}_0, t_0)$ in $\Omega \times [0, t_0)$, per il principio di Hopf. Allora si avrebbe $\partial_{\bm{\nu}} w(\bm{x}_0, t_0) > 0$, che sarebbe in contraddizione con la condizione al bordo
$$
\partial_{\bm{\nu}}w(\bm{x}_0, t_0) = -\alpha w (\bm{x}_0, t_0) \leq 0
$$
Per identiche ragioni, non si può avere un minimo $< 0$. Pertanto $w = 0$ è l'unica soluzione della (2.36).
\end{proof}
\subsection{La soluzione fondamentale (n = 1)}
Alcune soluzioni dell'equazione di diffusione permettono di costruirne molte altre e sono dette \emph{soluzioni fondamentali}.
Ragionando in dimensione $n=1$, si ipotizza una sbarra di lunghezza infinita posta sull'asse $x$, con sorgente puntiforme nell'origine. \\
Indicata con $u^*$ la soluzione dell'equazione del calore omogenea
\begin{equation}
u_t^*-Du_{xx}^* = 0
\end{equation}
Data l'assenza di sorgenti distribuite, non vi sono né produzione né assorbimento di calore, per cui l'energia deve mantenersi costante
\begin{equation}
E = \rho c_{v} \int_{\mathbb{R}} u^*(x,t) dx \qquad \mbox{per ogni } t>0
\end{equation}
Data l'invarianza della (2.26) per riflessioni nello spazio, ci si aspetta che $u^*$ sia positiva e pari rispetto a $x$.
Ci sono due passi per determinare la soluzione.
\begin{itemize}
\item Passo 1. Mostrato che $u^*$ ha una espressione analitica tipo
\begin{equation}
u^*(x, t) = \frac{Q}{\sqrt{Dt}} U \left(\frac{x}{\sqrt{Dt}}\right)
\end{equation}
dove $Q = \frac{E}{\rho c_v}$ e $U = U(\xi), \xi \in \mathbb{R}$ è una funzione positiva e pari, al momento non nota. Per la dimostrazione si utilizzerà il Teorema Pi di Buckingham che sarà analizzato in seguito.
\item Passo 2. Per dimostrare che 
\begin{equation}
U(\xi) = \frac{1}{2\sqrt{\pi}}e^{-\frac{\xi^2}{4}}
\end{equation}
\begin{itemize}
\item[a)] La temperatura $u^*$ in $x$ all'istante $t$ è determinata da: il tempo $t$, la distanza $x$ dall'origine e i parametri $D \mbox{ e } Q$. Esiste allora una relazione del tipo
\begin{equation}
u^* = \mathcal{U}(x, t, D, Q)
\end{equation}
in cui tutte le quantità sono \emph{dimensionali}, e si possono convertire, sempre secondo il Teorema Pi di Buckingham, in variabili \emph{adimensionali}.
Le variabili di $\mathcal{U}$ si possono esprimere nelle grandezze fondamentali $\Theta$ (grado), $L$ (lunghezza) e $T$ (tempo).
$$
[x] = L,\quad [t]=T,\quad [D] = L^2T^{-1}, \quad Q = \Theta L
$$
Per esprimere queste relazioni algebricamente si introduce un vettore con le seguenti componenti $$\mathbf{v} =\begin{pmatrix}
\Theta \\
L \\
T
\end{pmatrix}$$
che permette di riscrivere le relazioni sopracitate come
\begin{equation}
[\bm{x}] \rightleftarrows \begin{pmatrix}
0\\ 1 \\ 0
\end{pmatrix}, \quad
[\mathbf{t}] \rightleftarrows \begin{pmatrix}
0\\ 0 \\ 1
\end{pmatrix}, \quad
[\mathbf{D}] \rightleftarrows \begin{pmatrix}
0\\ 2 \\ -1
\end{pmatrix}, \quad
[\mathbf{Q}] \rightleftarrows \begin{pmatrix}
1\\ 1 \\ 0
\end{pmatrix}, \quad
\end{equation}
I vettori (2.31) generano tutto $\mathbb{R}^3$. Selezionandone tre linearmente indipendenti tra di loro, per esempio $\mathbf{t}, \mathbf{Q} \mbox{ e } \mathbf{D}$, si possono definire quantità primarie e riscrivendo $u^*$ trasformando $\bm{x}$ nelle dimensioni primarie si ottiene
$$
[u^*] = [Q][D]^{-\frac{1}{2}}[t]^{\frac{1}{2}} \quad \mbox{ e }\quad [x] = [D]^{\frac{1}{2}}[t]^{\frac{1}{2}} 
$$
Prese due quantità $\Pi$ e $\Pi_1$ definite come
$$
\Pi = \frac{u^*\sqrt{Dt}}{Q} \quad \mbox{ e } \quad \Pi_1 = \frac{x}{\sqrt{Dt}}
$$
che sono adimensionali. Moltiplicando entrambi i membri della (2.30) per $\frac{\sqrt{Dt}}{Q}$ e ponendo $x = \Pi_1\sqrt{Dt}$ si ottiene
$$
\Pi = \frac{\sqrt{Dt}}{Q}\mathcal{U}(x, t, D, Q) = \frac{\sqrt{Dt}}{Q}\mathcal{U}(\Pi_1\sqrt{Dt}, t, D, Q)
$$
Che si può riscrivere nella forma
\begin{equation}
\Pi = U(\Pi_1, t, D, Q)
\end{equation}
dove a sinistra si trova una quantità adimensionale, ma ciò implica che anche $U(\Pi_1, t, D, Q)$ debba essere adimensionale e quindi che $U$ sai indipendente dalle quantità primarie $t, Q, D,$ altrimenti a una variazione di queste ultime non corrisponderebbe una variazione di $\Pi$. Si deduce quindi che $\Pi = U(\Pi_1)$ che, riportato alle variabili originali, vale 
$$
u^* (x,t) = \frac{Q}{\sqrt{Dt}}U\left(\frac{x}{\sqrt{Dt}}\right)
$$
dove $U>0$ dal momento che $u^* > 0$. Una soluzione della forma (2.28) si dice soluzione di autosimilarità\footnote{Una soluzione si dice di autosimilarità o autosimile se il suo grafico rimane uguale a sé stesso per ogni $t$ durante l'evoluzione temporale. La forma generale è $$
u(x,t) = a(t)F\left(\frac{x}{b(t)}\right)
$$
dove $\frac{u}{a} \mbox{ e } \frac{x}{b}$ sono, preferibilmente, quantità adimensionali.}
\item [b)] Occorre ora determinare $U = U(\xi), \xi \in \mathbb{R}$ in modo che $u^*$ sia soluzione della (2.26). La (2.27) per la conservazione dell'energia deve essere
$$
Q = \frac{Q}{\sqrt{Dt}}\int_{\mathbb{R}}U \left(\frac{x}{\sqrt{Dt}}\right)dx \underset{\xi=\frac{x}{\sqrt{Dt}}}{=}Q\int_{\mathbb{R}}U(\xi)d\xi
$$
Va imposto allora
\begin{equation}
\int_{\mathbb{R}} U(\xi)d\xi = 1
\end{equation}
Per determinare $U$, $u^*$ deve essere soluzione di (2.26), ossia
{\everymath = {\displaystyle}
$$
\begin{array}{rcl}
u_t^* & = & \frac{Q}{\sqrt{D}} \left[-\frac{1}{2}t^{-\frac{3}{2}}U(\xi) - \frac{1}{2\sqrt{D}}xt^{-2}U'(\xi) \right]
\\
& = & -\frac{Q}{2t\sqrt{Dt}}\left[U(\xi)+ \xi U'(\xi)\right] \\
u_{xx}^* & = & \frac{Q}{(Dt)^{\frac{3}{2}}}U''(\xi)
\end{array} 
$$
}
che, inserito nella (2.26) 
$$
u_t^* -D u_{xx}^* = -\frac{Q}{t\sqrt{Dt}} \left\lbrace U''(\xi) + \frac{1}{2}+\xi U'(\xi) + \frac{1}{2}U(\xi)\right\rbrace
$$
Affinché $u^*$ sia soluzione della (2.26), occorre che $U$ soddisfi l'equazione differenziale in $\mathbb{R}$:
\begin{equation}
U''(\xi) + \frac{1}{2}\xi U'(\xi) + \frac{1}{2}U(\xi) = 0
\end{equation}
Si tratta di una equazione del secondo ordine, per la quale sono necessarie due condizioni supplementari. La (2.33) implica
$$
U(-\infty) = U(+\infty) = 0 
$$
Le soluzioni che vanno trovate devono essere \emph{pari}, di modo da poter limitare la ricerca al semiasse $\xi \geq 0$, con condizioni
\begin{equation}
U'(0) = U(+\infty) = 0
\end{equation}
La (2.34) si può riscrivere come 
$$
\frac{d}{d\xi} \left\lbrace U'(\xi) + \frac{1}{2}\xi U (\xi) \right\rbrace = 0
$$
che diventa
\begin{equation}
U'(\xi) + \frac{1}{2}\xi U(\xi) = C \qquad (C \in \mathbb{R})
\end{equation}
Con $\xi = 0$ e ricordando la (2.35) si deduce che $C = 0$, allora si può riscrivere
$$
U' (\xi) + \frac{1}{2}\xi U (\xi) = 0
$$
che è a variabili separabili, il cui integrale generale è la famiglia di esponenziali
$$
U(\xi) = c_0e^{-\frac{\xi^2}{4}} \qquad (c_0 \in \mathbb{R})
$$
che sono funzioni pari e si annullano a $+\infty$. Affinché valga la (2.33) va trovato un valore accettabile di $c_0$, per cui
$$
\int_{\mathbb{R}} e^{-\frac{\xi^2}{4}}d\xi \underset{\xi = 2z}{=} 2 \int_{\mathbb{R}} e^{-z^2}dz = 2\sqrt{\pi}
$$
per cui
$c_0 = (4 \pi)^{\frac{1}{2}}$
\end{itemize}
\end{itemize}
Tornando alle variabili originali l'unica soluzione positiva trovata è
$$
u^*(x,t)=\frac{Q}{\sqrt{4\pi Dt}}e^{-\frac{x^2}{4Dt}}, \qquad x \in \mathbb{R}, t > 0
$$
tale che 
$$
\int_{\mathbb{R}} u^* (x,t)dx = Q \qquad \mbox{ per ogni } t>0
$$
Se $Q = 1$ si parla di \emph{famiglia di Gaussiane}, strettamente correlate con la \emph{distribuzione normale di probabilità}.
\begin{definition}
La funzione 
$$
\Gamma_D (x,t) = \frac{1}{\sqrt{4\pi Dt}}e^{-\frac{x^2}{4Dt}}
$$
è la soluzione fondamentale dell'equazione di diffusione in dimensione uno.
\end{definition}
\subsection{La distribuzione di Dirac}
La soluzione fondamentale descrive l'evoluzione della temperatura da una sorgente puntiforme. Esaminando il comportamento per \(t \to 0^+\) della soluzione fondamentale si ha, per ogni \(x \not = 0\) fissato:
\begin{equation}
\lim_{t \to 0}\Gamma_D (x,t) = \lim_{t \to 0} \frac{1}{\sqrt{4 \pi Dt}}e^{-\frac{x^2}{4Dt}} = 0
\end{equation}
mentre
\begin{equation}
  \lim_{t \to 0}\Gamma_D (0,t) = \lim_{t \to 0} \frac{1}{\sqrt{4 \pi Dt}}e^{-\frac{x^2}{4Dt}} = +\infty
\end{equation}
Le equazioni (2.37) e (2.38) assieme a \(\int_{\mathbb{R}}\Gamma_D(x,t)dx = 1 \, \forall t >0\) implicano che per $t$ che tende a \(0\), la soluzione fondamentale tende a concentrarsi attorno all'origine. Se \(\Gamma_D\) viene interpretata come una densità, al limite tutta la massa è concentrata in \(x=0\). Tale distribuzione si può modellare introducendo la distribuzione di Dirac, indicata dal simbolo \(\delta\) (nel caso della distribuzione in \(x = 0\) si utilizza \(\delta_0\)). Non si tratta di una funzione nel senso classico perché ha le seguenti proprietà
\begin{itemize}
  \item \(\delta (0) = \infty, \delta(x) = 0 \mbox{ per } x \not= 0\)
  \item \(int_{\mathbb{R}} \delta(x)dx = 1\)
\end{itemize} 
incompatibili con i concetti classici di funzioni e integrali. Si tratta di una distribuzione di L. Schwartz, che verranno approfondite in seguito. Per comprenderla meglio, è necessario introdurre una funzione caratteristica dell'intervallo \([0, \infty)\), anche detta \emph{funzione di Heaviside}:
\[
\mathcal{H}(x) = \begin{cases}
  1 &\mbox{se } x \geq 0 \\
  0 & \mbox{se } x < 0
\end{cases}  
\]
che si può utilizzare per definire la funzione
\[
I_{\epsilon}(x) = \frac{\mathcal{H}(x + \epsilon) - \mathcal{H}(x - \epsilon)}{2\epsilon} = \begin{cases}
  \frac{1}{2\epsilon} &\mbox{se } -\epsilon \leq x < \epsilon \\
  0 &\mbox{altrove}
\end{cases} 
\]
Valgono le seguenti proprietà
\begin{enumerate}
  \item \(\forall \epsilon > 0\), 
  \[
  \int_{\mathbb{R}} I_{\epsilon} (x) dx = \frac{1}{2\epsilon} \times 2\epsilon = 1  
  \]
  \item \[
    \lim_{\epsilon \to 0} I_{\epsilon}(x) = \begin{cases}
      0  &\mbox{se } x \not = 0 \\
      \infty & \mbox{se } x = 0
    \end{cases}
  \]
  \item Se \(\phi = \phi (x)\) è una funzione regolare, con valore nullo al di fuori di un intervallo limitato (detto \emph{test}), so ottiene 
  \[
  \int_{\mathbb{R}} I_{\epsilon}(x)\phi(x)dx = \frac{1}{2\epsilon}\int_{-\epsilon}^{\epsilon} \phi(x) dx \underset{\epsilon \longrightarrow 0}{\longrightarrow}   \phi (0)
  \]
\end{enumerate}
La prima e l'ultima proprietà elencate indicano che \(I_{\epsilon}\) al limite possiede le proprietà della distribuzione di Dirac.
\begin{definition}
  Si chiama distribuzione di Dirac nell'origine la funzione generalizzata che si indica con \(\delta\) e agisce su una funzione \emph{test} nel seguente modo 
  \begin{equation}
    \phi \overset{\delta}{\longrightarrow} \phi (0) 
  \end{equation}
\end{definition}
La relazione (2.39) viene risrcritta anche come \(\left\langle \delta, \phi \right\rangle = \phi (0) \) o \(\int \phi(0)\delta(0)dx = \phi(0)\)
Dalla proprietà (2) si evince che
\[
\mathcal{H}' = \delta
\]
ricavato da 
\begin{equation}
  \int_{\mathbb{R}} \phi d\mathcal{H} = -\int_{\mathbb{R}}\mathcal{H}\phi' = -\int_{0}^{\infty} \phi' = \phi(0)
\end{equation}
poiché per valori grandi di \(x\) \(\phi\) è nulla. Si parla di distribuzione di Dirac in \(y\) se la massa non è concentrata nell'origine, ma in un punto \(y\) e si indica come \(\delta(x-y)\), definita da
\begin{equation}
  \int \delta (x -y) \phi(x) dx = \phi (y)
\end{equation}
La funzione \(\Gamma_D (x-y, t)\) è unica soluzione dell'equazione del calore con massa unitaria per ogni tempo, che soddisfi
\[
  \Gamma_D (x-y, 0) = \delta(x-y)  
\]
Si può pensare a \(\Gamma_D(x,t)\) come a una \emph{unit source solution}, dove vi sono un numero \(N\) di particelle in un istante \(x\) e la funzione \(\Gamma_D\) descrive la probabilità che una singola particella si trovi tra \(x \mbox{ e } x+dx\) al tempo \(t\). All'istante iniziale \(\Gamma-D\) è nulla al di fuori dell'origine. Appena \(t > 0,\) \(\Gamma_D\) è sempre positiva in tutto \(\mathbb{R}\), ciò indica che la massa è concentrata in \(x = 0\) e si diffonde istantaneamente in tutto l'asse reale con \textbf{velocità di propagazione infinita}.
\subsection{La soluzione fondamentale $\mathbf{(n > 1)}$}
In dimensione spaziale maggiore di uno, si ripetono sostanzialmente gli stessi discorsi. L'assenza di sorgenti distribuite implica la legge di conservazione per la soluzione \(u^*\)
\begin{equation}
\int_{\mathbb{R}^n} u^*(\bm{x}, t)d\bm{x} = Q \qquad \mbox{ per ogni } t > 0
\end{equation}
Grazie all'analisi dimensionale si ottiene l'espressione analitica per \(u^*\)
\[
u^*(\bm{x}, t) = \frac{Q}{(Dt)^{\frac{n}{2}}}U(\xi) \qquad \xi = \frac{|\bm{x}|}{\sqrt{Dt}}  
\]
dove \(U\) è una funzione positiva. \\
Posta \(u^*\) come soluzione di \(u_t^* - D\Delta u^* = 0\). Grazie all'operatore di Laplace per funzioni radiali si ottiene
{\everymath = {\displaystyle}
\[
\begin{array}{c}
  u_t^* = -\frac{1}{2t(Dt)^{\frac{n}{2}}}[nU(\xi) + \xi U'(\xi)] \\
  \Delta u^* = \frac{1}{(Dt)^{\frac{1+n}{2}}} \left\lbrace U''(\xi) + \frac{n-1}{\xi}U'(\xi)\right\rbrace
\end{array}  
\]
}
Affinché \(u^*\) sia soluzione di \(u - D\Delta u = f\), \(U\) deve essere soluzione in \((0, +\infty)\) dell'equazione differenziale ordinaria
\begin{equation}
  \xi U''(\xi) + (n -1)U'(\xi) + \frac{\xi^2}{2}U'(\xi) + \frac{n}{2}\xi U (\xi) = 0
\end{equation}
che si può riscrivere, moltiplicando tutto per \(\xi^{n-2}\), come
\[
(\xi^{n-1}U'(\xi))'+\frac{1}{2}(\xi^n U(\xi))'= 0  
\]
che, integrando, restituisce
\begin{equation}
  \xi^{n-1} U'(\xi) +\frac{1}{2}\xi^n U(\xi) = C \qquad (C\in \mathbb{R})
\end{equation}
Assunti i limiti per \(\xi \to 0^+\) di \(U\) e \(U'\) siano finiti, si può passare al limite per \(\xi \to 0^+\) e dedurre che \(C = 0\), per cui
\[
U'(\xi) + \frac{1}{2}\xi U(\xi) = 0 
\]
da cui si ottiene sempre la famiglia di esponenziali
\[
U(\xi) = c_0e^{-\frac{\xi^2}{4}} \qquad (c_0 \in \mathbb{R})  
\]
Usando la conservazione della massa si ricava, dividendo per \(Q\):
\begin{align*}
  1 = \frac{1}{(Dt)^{\frac{n}{2}}} \int_{\mathbb{R}^n} U \left(\frac{|\bm{x}|}{\sqrt{Dt}}\right)d\bm{x} = \frac{c_0}{(Dt)^\frac{n}{2}} \int_{\mathbb{R}^n}e^{\left(-\frac{|\bm{x}|^2}{4Dt}\right)}d\bm{x} \\
  \underset{\bm{y}=\frac{\bm{x}}{\sqrt{4Dt}}}{=} c_02^n \int_{\mathbb{R}^n} e^{-|\bm{y}|^2}d\bm{y} = c_02^n\left(\int_{\mathbb{R}^n}e^{z^2}dz\right)^n = c_0(4\pi)^{\frac{n}{2}}
\end{align*}
da cui \(c_0 = (4\pi)^{-\frac{n}{2}}\). Si ottengono quindi soluzioni della forma
\[
  u^*(\bm{x}, t) = \frac{Q}{(4\pi Dt)^{\frac{n}{2}}}e^{-\frac{|\bm{x}|^2}{4Dt}} \qquad (x \in \mathbb{R}^n, t > 0)
\]
Anche in dimensione \(n > 1\) la scelta di \(Q = 1\) è speciale.
\begin{definition}
  La funzione 
  \[
     \Gamma_D(\bm{x}, t) = \frac{Q}{(4\pi Dt)^{\frac{n}{2}}}e^{-\frac{|\bm{x}|^2}{4Dt}} \qquad (\bm{x} \in \mathbb{R}^n, t>0)
  \]
  si chiama \textbf{soluzione fondamentale} dell'equazione di diffusione in dimensione \(n\).

\end{definition}
Si può generalizzare al caso multidimensionale anche la distribuzione di Dirac in un punto \(\bm{y}\) come
\[
\int\delta_n (\bm{x} - \bm{y}) \phi (\bm{x}) d\bm{x} = \phi(\bm{y})  
\]
con \(\phi\) funzione di test, continua su \(\mathbb{R}^n\) e nulla al di fuori di un insieme chiuso e limitato. \\
La soluzione fondamentale \(\Gamma_D(\bm{x} - \bm{y}, t)\) per un \(\bm{y}\) fissato è l'unica soluzione del problema di Cauchy
\[
  \begin{cases}
    u_t -D\Delta u = 0 & \bm{x}\in \mathbb{R}^n, \, t>0 \\
    u(\bm{x}, 0) = \delta_n (\bm{x} -\bm{y}) & \bm{x} \in \mathbb{R}^n
  \end{cases}
\]
\subsection{Passeggiata aleatoria simmetrica (n = 1)}
In questa sezione si affronterà la costruzione di un modello probabilistico, sia discreto che continuo.
In questo modo si può affrontare l'equazione del calore approssimandola a una equazione alle differenza che la `discretizzi' e sarà più semplice comprendere la natura del coefficiente \(D\). \\
Si ipotizzi una particella di massa unitaria in moto lungo l'asse \(x\) che segua due regole (fissati un passo \(h\) e un intervallo \(\tau\)):
\begin{enumerate}
  \item In un tempo \(\tau\) la particella si muove di \(h\) (all'istante \(t = 0\) la particella sta in \(x = 0\))
  \item La particella si muove in modo indipendente dal passo precedente a destra o a sinistra con probabilità \(p = \frac{1}{2}\).
\end{enumerate}
All'istante \(t = N\tau\), ossia dopo \(N\) passi, la particella si troverà in un punto \(x = mh\), con \(-N \leq m \geq N\). \\
Le due variabili \(x\) ed \(m\) sono variabili aleatorie, per cui si cerca di risolvere il seguente problema: calcolare la probabilità \(p(x,t)\) che la particella si trovi in un punto \(x\) al tempo \(t\).
\begin{itemize}
  \item Calcolo di \(p(x,t)\)
\end{itemize}
Sia \(x = mh\) la posizione della particella dopo \(N\) passi, per arrivare alla posizione \(x\) la particella avrà eseguito un numero di passi a destra \(k\) e un numero di passi a sinistra \(N - k\). Dal momento che \(0 \leq k \leq N\) e 
\begin{equation}
  m = k - (N - k) = 2k - N
\end{equation}
cosicché \(N\) e \(m\) hanno la stessa parità e 
\[
k = \frac{1}{2} (N + m)  
\] 
Ne segue che \(p(x,t) = p_k\) dove\begin{equation}
  p_k = \frac{\mbox{numero di cammini con }k \mbox{ passi a destra su }N}{\mbox{numero dei cammini con }N\mbox{ passi}}
\end{equation}
Ora, il numero di cammini con \(k\) a destra e \(N - k\) è dato dal coefficiente binomiale
\[
  C_{N, k} = \binom{N}{k} \frac{N!}{k!(N - k)!} 
\]
D'altra parte, il numero dei possibili cammini è \(2^N\). Si ha:
\begin{equation}
  p_k = \frac{C_{N,k}}{2^N} \quad x = mh, \, t = N\tau, \, k = \frac{1}{2}(N+m)
\end{equation}
\begin{itemize}
  \item Media e deviazione standard di x
\end{itemize}
Il passaggio in dimensione continua implica il far tendere a \(0\) sia \(h\) che \(\tau\). Alcuni parametri fondamentali devono rimanere inalterati:
\begin{itemize}
  \item la media di \(x\) dopo \(N\) passi \(\left\langle x\right\rangle\ = \left\langle m \right\rangle) h\)
  \item il momento secondo \footnote{Una variabile aleatoria \(x\) assume \(N\) possibili \(x_1,\ldots, x_N\) con probabilità \(p_1,\ldots,p_N\) e i suoi \emph{momenti di ordine \(q\geq 1\) sono dati da:
  \[
    E(x^q) = \langle x^q \rangle = \sum_{j=1}^N x_j^q p_j
  \]}} di \(x\) dopo \(N\) passi \(= \langle x^2 \rangle = \langle m^2 \rangle h^2\)
\end{itemize}
La quantità \(\sqrt{\langle m^2\rangle}h\) rappresenta la distanza media dall'origine dopo \(N\) passi. 
Dal momento che \(\langle m \rangle = 2\langle k\rangle - N\) e \(\langle m^2 \rangle = 4 \langle k^2 \rangle - 4 \langle k \rangle N + N^2\). \\
Sia \(\langle m \rangle\) che \(\langle m^2 \rangle\) si possono ottenere calcolando \(\langle k \rangle\) e \(\langle k^2 \rangle\). Allora si può definire
\begin{align}
  & \langle k \rangle = \sum_{k = 1}^N kp_k = \frac{1}{2^N} \sum_{k=1}^N kC_{N,k} \\
  & \langle k^2 \rangle = \sum_{k=1}^N k^2 p_k = \frac{1}{2^N} \sum_{k=1}^N k^2 C_{N, k}
\end{align}
Nonostante dalla (2.48) e (2.49), si tende a utilizzare la \emph{funzione generatrice delle probabilità}:
\[
  G(s) = \sum_{k = 0}^N p_k s^k = \frac{1}{2^N} \sum_{k = 1}^N C_{N,k}s^{k}
\]
La funzione  \(G\) contiene in forma più compatta informazioni sui momenti di \(k\)e funziona per variabili aleatorie a valori interi
\begin{align}
  & G'(s) = \frac{1}{2^N} \sum_{k = 1}^N kC_{N,k} s^{k-1} \\
  & G''(s) = \frac{1}{2^N} k(k-1) C_{N,k} s^{k-2}
\end{align}
Con \(s = 1\) si ha 
\begin{align}
  & G'(1) = \frac{1}{2^N} \sum_{k = 1}^N k C_{N,k} = \langle k \rangle \\
  & G''(1) = \frac{1}{2^N} \sum_{k = 1}^N k(k -1)C_{N,k} = (k(k-1)) = \langle k^2 \rangle - \langle k \rangle
\end{align}
Poiché la formula del binomio è
\[
  (a + b)^N = \sum_{k = 0}^N C_{N,k}a{N-k}b^k 
\]
si deduce che 
\[
  G(s) = \frac{1}{2^N} \sum_{k=0}^N C_{N,k}s^k = \frac{1}{2^N}(1+s)^N
\]
da cui 
\[
\begin{array}{ccc}
 G'(1) = \frac{N}{2} & & G''(1) \frac{N(N+1)}{4}\\
 & \Downarrow & \\
 \langle k \rangle = \frac{N}{2} & & \langle k^2 \rangle = \frac{N(N+1)}{4}
\end{array}
\]
Per cui, poiché \( \langle m \rangle = 2 \langle k \rangle - N\) si ottiene \(2\frac{N}{2} - N = 0\), che si riflette in \(\langle x \rangle = 0\) a conferma della simmetria della passeggiata aleatoria. \\
Inoltre 
\[
  \langle m^2 \rangle = 4 \langle k^2 \rangle - 4N \langle k \rangle + N^2 = N^2 +N- 2N^2 + N^2 = N
\]
da cui \(\sqrt{\langle x^2 \rangle} = \sqrt{N}h\) che è la deviazione standard di \(x\), dal momento che \(\langle x \rangle = 0\). Si evince da quest'ultima informazione che dopo \(N\tau\) istanti la distanza da \(x = 0\) è dell'ordine di \(\sqrt{N}h\), ossia che la scala temporale è dell'ordine del quadrato della scala spaziale, per cui occorre utilizzare le dilatazioni paraboliche viste precedentemente.
Il secondo passaggio consiste nel trovare una equazione alle differenze \(p = p(x, t)\) sulla quale effettuare il passaggio al limite. \\
Poiché la particella si muove indipendentemente dal passo precedente, se essa si trova in \(x\) al tempo \(t+\tau\), allora al tempo \(t\) si trovava: o in \(x-h\), o in \(x+h\), da cui si ricava
\begin{equation}
\begin{cases}
   p(x, t+\tau) = \frac{1}{2}p(x-h. t) +\frac{1}{2}p(x+h, t) \\
   p(0,0) = 1 \\
   p(x, 0) = 0 & \mbox{se } x \not = 0 
\end{cases}
\end{equation}
Dati \(x \mbox{ e } t\), si vuole studiare il passaggio al limite di \(h \to 0, \tau \to 0\). 
Si supponga che \(p(x, t)\) sia differenziabile, si ottiene allora
\begin{flalign*}
  p(x, t+\tau) = p(x, t) + p_t(x,t)\tau +o(\tau) \\
  p(x\pm h, t) = p(x,t)\pm p_x(x,t)h+\frac{1}{2}p_{xx}(x,t)h^2+o{h^2}
\end{flalign*}
che all'interno della (2.54) restituiscono, dopo le opportune semplificazioni
{\everymath={\displaystyle}
\[
  \begin{array}{c}
   p_t\tau + o(\tau) = \frac{1}{2}p_{xx}h^2 +o(h^2) \\
   \Downarrow \mbox{ dividendo per }\tau \\
   p_t + o(1) = \frac{1}{2}\frac{h^2}{\tau} p_{xx}+o\left(\frac{h^2}{\tau}\right) 
  \end{array}
\]
}
Si supponga inoltre che 
\[
  \frac{h^2}{\tau} = 2D \quad (D > 0)
\]
Si può passare al limite e sostituire \(\frac{h^2}{\tau}\) per ottenere
\[
  p_t = Dp_{xx}
\]
che è l'equazione del calore con condizioni iniziali
\[
  \lim_{t \to 0^+} p(x, t) = \delta
\]
Dalla soluzione fondamentale trovata in precedenza si ottiene
\[
  p(x,t) = \Gamma_D(x,t)
\]
Dunque la costante \(D\) è proprio il \emph{coefficiente di diffusione}. Infatti si ha
{\everymath = {\displaystyle}
\[
\begin{array}{c}
  \langle x^2 \rangle = Nh^2, \qquad t= N\tau \\
   \Downarrow  \\
   \frac{\langle x^2 \rangle}{t} = \frac{h^2}{\tau} = 2D 
  \end{array}  
\]}
Ossia: nell'unità di tempo la particella diffonde a una distanza media \(\sqrt{2D}\) con velocità che tende all'infinito.
Utilizzando il Teorema Centrale del Limite (TCL) si può avere una idea più chiara di cosa sia diventata la passeggiata aleatoria. \\
Sia  \(x_j = x(j\tau)\) la posizione raggiunta dopo \(j\) passi e posto \(j \geq 1\) 
\[
  h\xi_j = x_j - x_{j -1} 
\]
Le variabili \(\xi_j\) sono aleatorie i.i.d. con valore \(1 \mbox{ o } -1\), entrambi con probabilità \(\frac{1}{2}\). La loro media è \(\langle \xi_j \rangle = 0 \mbox{ e varianza }\langle \xi^2_j \rangle = 1\). La posizione della particella dopo \(N\) passi è 
\[
  x_N = h\sum_{j = 1}^N \xi_j
\]
Affinché \(\frac{h^2}{\tau} = 2D\), il valore di \(h\) deve essere \(\sqrt{\frac{2Dt}{N}}\). Passando al limite per \(N \to \infty\), il TCL assicura\footnote{se \(N \to \infty\), \[\mbox{Prob}\{a < x_N < b\} \to \int_a^b \Gamma_D(x,t)dx\]} la convergenza ad una variabile aleatoria con media \(0\) e varianza \(2Dt\), la cui densità corrisponde a \(\Gamma_D(x,t)\).
Nel caso particolare \(D=\frac{1}{2}\) la passeggiata aleatoria è un moto continuo, definito come \textbf{moto Browniano}, caratterizzato dalla notazione \(B = B(t)\), che indica la posizione di una particella che si muove con tale moto nel tempo. \\
Le variabili aleatorie \(B(t)\) sono definite su uno spazio \((\Omega, \mathcal{F}, P)\). Si omette per comodità di definite la variabile aleatoria come \(B(t, \omega)\), in quanto si sottintende la dipendenza da \(\omega\). \\
Fissando \(\omega \in \Omega\), si ottiene la funzione
\[
  t \longrightarrow B(t, \omega)
\]
che descrive uno dei possibili cammini Browniani. Bloccando \(t\) si ottiene una variabile aleatoria
\[
  \omega \longrightarrow B(t, \omega)
\]
Fissare \(t\) significa fissare una retta verticale nel piano su cui si sta muovendo la particella all'istante \(\overline{t}\) e prendere un sottoinsieme \(I\) appartenente a quella retta. \(P\{B(t) \in I\}\) è la probabilità che \(B(t)\) si trovi in \(I\) all'istante \(\overline{t}\).
Per valori generici di \(D\) la particella si muoverà come multiplo di un moto Browniano. 
\begin{itemize}
  \item Continuità delle traiettorie
\end{itemize}
I possibili cammini di una particella che segue un moto Browniano con probabilità \(1\) sono funzioni 
\[
  t \longrightarrow B(t) 
\]
continue per \(t \geq 0\). Dal momento che la velocità è infinita, la traiettoria non è differenziabile in nessun punto-
\begin{itemize}
  \item Legge di Gauss per gli incrementi
\end{itemize}
Partendo da un punto \(x \not = 0\) e considerando il processo
\[
  B^x(t) = x + B(t),
\]
si ottiene che ad ogni punto \(x\) corrisponda una probabilità \(P^x\), da interpretarsi come la distribuzione associata ai cammini che una particella, inizialmente ferma in \(x\), compie seguendo le proprietà\footnote{se \(x = 0\), allora \(P^{x=0}\) si scrive come \(P^0\)}:
\begin{itemize}
  \item [a)] \(P^x\{B^x(0) =x\} = P\{B(0) = 0\} = 1\)
  \item [b)] per ogni \(s\geq 0, t \geq 0\), l'incremento 
  \[
  B^x(t+s) -B^x(s) = B(t+s) - B(s) 
  \]
\end{itemize}
ha distribuzione normale con media \(0\) e varianza \(t\). Si può allora ricavare la densità dalla soluzione fondamentale
\[
  \Gamma(x,t) \equiv \Gamma_{\frac{1}{2}}(x,t) = \frac{1}{\sqrt{2\pi t}}e^{-\frac{x^2}{2t}}
\]
ed è indipendente da ogni evento accaduto in un tempo  \(\leq s\).
\begin{itemize}
  \item Probabilità di transizione 
\end{itemize}
Per ogni insieme di Borel \(I \subseteq \mathbb{R}\) è definita una funzione di transizione
\[
  P(x,t,I) = P^x\{B^x(t)\in I\} 
\]
che permette di rappresentare la probabilità all'instante \(t\) della particella, inizialmente in \(x\), di trovarsi in \(I\). Si hanno
\[
  P(x, t, I) = P\{B(t) \in I-x\} = \int_{I-x} \Gamma(y,t) dy = \int_I \Gamma(y-x,t)dy
\]
\begin{itemize}
  \item Proprietà di Markov
\end{itemize}
Sia \(\mu\) una misura di probabilità su \(\mathbb{R}\). Se si può ricondurre la posizione iniziale della particella a una distribuzione di probabilità \(\mu\), allora si tratta di \emph{moto Browniano con distribuzione iniziale }\(\mu\), indicato da \(B^{\mu}\). A questo processo si associa la distribuzione \(P^{\mu}\) definita come
\[
  P^{\mu}\{B^{\mu}(0)\in I\} = \mu(I)
\]
La probabilità che la particella si trovi in \(I\) si calcola come
\[
  P^{\mu}\{B^{\mu}(t) \in I\} = \int_{\mathbb{R}} P^{x}\{B^x(t)\in I\}d\mu (x) = \int_{\mathbb{R}}P(x,t,I)d\mu(x)                                             
\]

La proprietà di Markov si può esprimere come una condizione \(H\), legata al comportamento della particella prima di un istante \(s\geq 0\), che, con un determinato moto Browniano 
\(Y(t) = B^x (t+s),\)
stabilisce l'indipendenza del processo futuro 
\(B^x(t+s)\)
da quello prima di un istante \(s\). \\
L'assenza di memoria è una caratteristica della passeggiata aleatoria. \\
In alternativa esiste la proprietà di Markov forte che sostituisce all'istante \(s\) un istante di tempo \(\tau\) aleatorio che dipende dal comportamento della particella dentro l'intervallo \([0, \tau]\).
\begin{itemize}
  \item Valore atteso
\end{itemize}
Per \(x,t\) fissati, la funzione \(P(x,t,I)\) coincide con la legge di un moto Browniano. Data allora una funzione \(g = g(y), \, y \in \mathbb{R}\) si può definite una variabile aleatoria
\[
  Z(t) = (g \circ B^x)(t) = g(B^x(t))
\]
il cui valore atteso sarà
\[
  E[Z(t)] = \int_{\mathbb{R}} g(y)P(x,t,dy) = \int_{\mathbb{R}} g(y) \Gamma(x-y,t)dy
\]
\subsection{Diffusione, trasporto e reazione}
Eliminando la simmetria dalla passeggiata aleatoria si ottiene la cossiddetta variante con \emph{drift}. Si abbia sempre una particella in moto sull'asse \(x\) con le proprietà:
\begin{itemize}
 \item La particella si muove di un passo \(h\) in un tempo di misura \(\tau\).
 \item Si può muovere a sinistra con una probabilità \(p_0 \not = \frac{1}{2}\) e a destra con probabilità \(q_0 = 1- p_0\), indipendentemente dal passo precedente.
\end{itemize}
Come prima, \(p = p(x,t)\) è la probabilità che la particella si trovi in \(x = mh\) al tempo \(t = N\tau\). Come prima \(k\) rappresenta il numero di passi a destra compiuti dalla particella, allora si avrà la probabilità
\[
  p_k = C_{N,k}p_0^k\_0^{N-k}
\] 
Con la funzione generatrice delle probabilità pari a
\[
  G(s) = (p_0s + q_0)^N
\]
il valore atteso di \(x\) dopo \(N\) passi sarà: \(\langle x \rangle = N (p_0 - q_0)h\) e la sua varianza sarà pari a: \(\langle x^2 \rangle - \langle x \rangle^2 = 4p_0q_0Nh^2\). \\
La posizione media rispetto all'origine si può dividere per l'unità di tempo, in questo caso \(t = N\tau\) e si ottiene
\begin{equation}
  \frac{\langle x  \rangle}{t} = \frac{(p_0 - q_0)h}{\tau}
\end{equation}
che indica la posizione media nell'unità di tempo. Passando al limite per \(h, \tau  \to 0 \) sarà necessario che si mantenga questa caratteristica del moto. \\
La deviazione standard, come noto, è data da \(\sqrt{\mbox{Var}(x)}\) ed è sempre di ordine \(\sqrt{N}h\). 
Il calcolo delle probabilità è influenzato in questo modo
\[
  \begin{cases}
  p(x, t+\tau) = p_0p(x-h, t) + q_0(x-h,t) \\
  p(0,0) = 1 \\
  p(x, 0) = 0 \qquad \mbox{se }x \not = 0
 \end{cases}
\]
Come prima, passando al limite per \(h, \tau \to 0\) e supponendo \(p\) differenziabile, si ha
\begin{flalign*}
  p(x,t+\tau) = p(x,t) = p_t(x,t)\tau + o(\tau) \\
  p(x \pm h, t) = p(x,t) \pm p_x(h,t)h + p_{xx}(x,t)h^2 + o(h^2)
\end{flalign*}
Con le opportune semplificazioni, come prima si ottiene
{\everymath={\displaystyle}
\[
  \begin{array}{c}
   p_t\tau + o(\tau) = \frac{1}{2}p_{xx}h^2 + (q_0 -p_0)hp_x + o(h^2) \\
   \Downarrow \mbox{ dividendo per }\tau \\
   p_t + o(1) = \frac{1}{2}\frac{h^2}{\tau} p_{xx}+\frac{(q_0-p_0)h}{\tau}p_x+o\left(\frac{h^2}{\tau}\right) 
  \end{array}
\]
}
Rispetto al caso simmetrico appare un nuovo termine, il cui coefficiente inoltre è esattamente uguale alla media della posizione della particella rispetto all'unità di tempo. 
Il passaggio al limite assume nuovamente
\[
 \frac{h^2}{\tau} = 2D 
\]
ma in questo caso non più sufficiente, in quanto mantenendo costanti \(p_0 \mbox{ e } q_0\) si avrebbe
\[
  \frac{(q_0 - p_0h)}{q} \to \infty
\]
Occorre dunque richiedere che 
\[
  \frac{q_0 - p_0}{h} = \beta
\]
con \(\beta\) finito. Inoltre, dato che \((p_0 + q_0) = 1\) si può riscrivere 
\begin{flalign}
  p_0 = \frac{1}{2} - \frac{\beta}{2}h + o(h) \\
  q_0 = \frac{1}{2} + \frac{\beta}{2}h + o(h)
\end{flalign}
da cui deriva 
\begin{equation}
  \frac{(q_0 - p_0)}{h} \frac{h^2}{\tau} \to 2D\beta \equiv b
\end{equation}
che permette di ottenere l'equazione 
\begin{equation}
  p_t = Dp_{xx} + bp_x
\end{equation}
Il termine \(bp_x\) ha delle dimensioni specifiche, essendo \(p_0 - q_0\) adimensionale, deve avere le dimensioni di \(\frac{h}{\tau}\), ossia una velocità. Tale coefficiente allora codifica la velocità della particella e, a seconda del suo segno, la sua direzione. La passeggiata aleatoria allora descrive un processo di \emph{diffusione con deriva}.
Tale modello è spesso usato per descrivere la diffusione, per esempio, di un agente inquinante in un corso d'acqua. \\
Il canale scorre con velocità \(v\) costante lungo l'asse \(x\).
Il modello ha come obiettivo la descrizione della concentrazione \(c = c(x,t)\) della sostanza inquinante. 
Allo stesso tempo \(c(x,t)dx\) rappresenta la massa al tempo \(t\) presente in \([x, x+\Delta x]\). La massa presente al tempo \(t\) è rappresentata dall'integrale 
\begin {equation}
  \int_x^{x+\Delta x} c(y,t)dy
\end{equation}
In generale vige il principio di conservazione della massa, ossia \emph{il tasso di variazione della massa contenuta in un intervallo \[x, x+\Delta x\]}. Il tasso di variazione è dato da
\begin{equation}
  \frac{d}{dt} \int_x^{x+\Delta x} c(y,t)dy = \int_x^{x+\Delta x} c_t(y,t)dy
\end{equation}
La quantità \(q = q(x,t)\) rappresenta il flusso di massa entrante nell'intervallo \([x, x+\Delta x]\). Il flusso netto agli estremi dell'intervallo si ottiene come 
\begin{equation}
  q(x,t) - q(x+\Delta x, t)
\end{equation}
e uguagliando la (2.61) e la (2.62) si ottiene
\[
  \int_x^{x+\Delta x} c_t (y,t)dy = q(x,t) - q(x+\Delta x, t)
\]
Passando al limite per \(\Delta x \to 0\) e dividendo per \(\Delta x\) si ha
\begin{equation}
  c_t = -q_x
\end{equation}
Per avere una idea del tipo di flusso di massa con cui si ha a che fare, è necessario stabilire una legge costitutiva per \(q\). Le opzioni sono:
\begin{enumerate}
  \item \emph{Convezione o trasporto}. Il flusso è determinato dalla corrente d'acqua, nel caso in cui la massa inquinante mantenga la sua forma senza deformarsi; modellizzabile come
  \[
    q(x,t) = vc(x,t)
  \]
  \item \emph{Diffusione} Molto simile al modello di diffusione del calore, la sostanza inquinante si diffonde nel corso d'acqua secondo la legge di Fick (molto simile alla legge di Fourier)
  \[
    q(x,t) = -Dc_x(x,t)
  \]
  con \(D\) solita costante di diffusione con dimensione \(lunghezza^2 \times tempo^{-1}\)
\end{enumerate}
Poiché nel caso della sostanza inquinante sono presenti entrambi gli effetti, vanno sovrapposti, ottenendo
\[
  q(x,t) = vc(x,t) - Dc_x(x,t)
\]
La (2.63) permette di ottenere
\begin{equation}
  c_t = Dc_{xx}-vc_x
\end{equation}
Dal momento che sia \(D\) e \(v\) sono due costanti, determinare l'evoluzione della massa inquinante è semplice. Si supponga una massa \(Q\) di sostanza inquinante e la condizione iniziale
\[
  c(x,0) = Q\delta(x)
\]
Il termine \(-vc_x\) si può eliminare con un semplice cambio di variabili, ponendo
\[
  w(x,t) = c(x,t)e^{hx+kt}
\]
dove \(h, k\) sono da determinarsi in modo opportuno. Si ha allora
\[
\begin{array}{cc}
  w_t = [c_t + kc]e^{hx + kt} & \\
  w_x = [c_x + hc]e^{hx+kt}, & w_{xx} = [c_{xx} + 2hc_x + h^2c]e^{hx+kt} 
\end{array}  
\]
che, grazie all'uguaglianza \(c_t = Dc_{xx - vc_x}\), diventa
\begin{align*}
  w_t -Dw_{xx} = e^{hx+kt}[c_t Dc_{xx} - 2Dhc_x + (k-Dh^2)c] = \\
  = e^{hx+kt}[(-v-2Dh)c_x + (k-Dh^2)c]
\end{align*}
per cui, posti
\[
  h=-\frac{v}{2D}, \qquad k = -\frac{v^2}{4D}
\]
la funzione \(w\) è soluzione dell'equazione del calore \(w_t -Dw_{xx} = 0\), con condizione iniziale 
\[
  w(x,t) = c(x,0)e^{-\frac{v}{2D}x}=Q\delta(x)e^{-\frac{v}{2D}x}
\]
In una situazione reale, l'inquinante è soggetto a decadimento naturale, per cui
\begin{equation}
  c_t = Dc_{xx}-vc_x-\gamma c
\end{equation}
Ipotizzando che la particella scompaia per decadimento, dato da \(\gamma > 0\), allora in un intervallo di tempo \([t, t+\tau]\), scompare una quantità di massa pari a
\[
  Q(x,t) = \tau \gamma p(x,t)
\]
Allora l'equazione alle differenze per \(p\) diventa
\[
  p(x, t+\tau) = p_0 [p(x-h, t) - Q(x-h, t)] + q_0[p(x+h,t) - Q(x+h,t)]
\]
Poiché\footnote{Si intende con \(O(x)\) una quantità dell'ordine di grandezza di \(x\)}
\begin{align*}
  p_0Q(x-h, t) + q_0Q(x+h, t) = q(x,t) + (q_0 -p_0)hQ_x(x,t)+ \ldots = \\
  = \tau \gamma p(x,t) + O(\tau h)
\end{align*}
da cui si giunge a 
\[
  p_t \tau + o(\tau) = \frac{1}{2}p_{xx}h^2 - (q_0-p_0)hp_x- \tau \gamma p + O(\tau h) + o(h^2)
\]
Dividendo tutto per \(\tau\) e, come prima, passando al limite per \(h, \tau \to 0\), si ha l'equazione di diffusione, trasporto e reazione
\[
  p_t = Dp_{xx} + bp_x - \gamma p, \qquad (b = 2D\beta)
\]
\subsection{Il problema di Cauchy globale}
Questa sezione si occuperà di studiare il problema di Cauchy globale nel caso omogeneo \(n=1\).
Il problema si pone come 
\begin{equation}
  \begin{cases}
  u_t -Du_{xx} = 0 & \mbox{in } \mathbb{R} \times (0, \infty) \\
  u(x, 0) = g(x) & \mbox{in } \mathbb{R}
 \end{cases}
\end{equation}
dove \(g\) rappresenta il dato iniziale assegnato. Tale problema si presenta quando si cerca di studiare l'evoluzione della temperatura, o della concentrazione di massa lungo un filo infinito, conoscendo il valore al tempo \(t = 0\).
Se \(u(x,t\) rappresenta la concentrazione della massa, allora \(u(x,t)dx\) assegna al tempo \(t\) una quantità di massa che si trova nell'intervallo \((x, x+dx)\).
La quantità \(g(y)dy\) indica la massa concentrata in \((y, y+dy)\) al tempo \(t=0\). In precedenza si è parlato della \emph{unit source solution}, che rappresenta la diffusione di una massa inizialmente concentrata in \(y\), descritta dalla funzione \(\Gamma_D(x-y,t)\).
La concentrazione in \(x\) al tempo \(t\) viene descritta da 
\[
  \Gamma_D(x-y, t)g(y)dy
\]
La linearità dell'equazione permette di utilizzare il principio di sovrapposizione, sommando i singoli contributi. Si ottiene così
\begin{equation}
  u(x,t)= \int_{\mathbb{R}} \Gamma_D(x-y,t)g(y,t)dy = \frac{1}{\sqrt{4\pi Dt}}\int_{\mathbb{R}}g(y)e^{-\frac{(x-y)^2}{4Dt}}dy
\end{equation}
La (2.67) rappresenta la convoluzione del dato iniziale con la Gaussiana per ogni \(t>0\). Sia, per semplicità, \(D=\frac{1}{2}\) e \(B^x(t)\) la posizione di una particella Browniana partita dal punto \(x\), con \(g(y)\) il \emph{guadagno acquisito} al passaggio per \(y\).\\
Si può allora calcolare il valore atteso rispetto alla probabilità \(P^x\) con densità \(\Gamma(x-y,t)\) come 
\[
  u(x,t) = E[g(B^x(t))]
\]
per cui per calcolare \(u\) nel punto \((x,t)\) si considera una particella Browniana che parta dal punto \(x\), si calcola la sua posizione \(B^x(t)\) al tempo \(t\) e si calcola il valore atteso del guadagno \(g(B^x(t))\).
Affinché la (2.67) sia effettivamente soluzione al problema di Cauchy si utilizza il seguente Teorema
\begin{theorem}
  Sia \(g\) una funzione con un numero finito di punti di discontinuità in \(\mathbb{R}\) tale che 
  \[
    [g(x) \leq ce^{ax^2}], \qquad \forall x \in \mathbb{R}
  \]
  con \(a\) e \(c\) numeri positivi e sia \(u\) definita dal problema di Cauchy, allora:
  \begin{enumerate}
    \item \(u\) è ben definita ed è differenziabile fino a qualunque ordine in \(\mathbb{R} \times (0, T)\) con \(T < \frac{1}{4Da}\) e in questo intervallo 
    \[
    u_t - Du_{xx} = 0  
    \]
    \item se \(x_0\) è un punto in cui \(g\) è continua, allora
    \[
     u(y,t) \to g(x_0) \qquad \mbox{per }(y,t) \to (x_0,0), t>0 
    \]
    \item esistono due costanti \(c_1, A\) tali che 
    \[
      \abs*{u(y,t)} \leq c_1e^{Ax^2}, \qquad \forall x,t \in \mathbb{R} \times (0, T)
    \]
  \end{enumerate}
\end{theorem}
Il teorema indica che, con un dato iniziale che abbia crescita esponenziale, la (2.67) è soluzione del problema di Cauchy. Di fatto è anche l'unica soluzione in quanto il dato temporale \(T < \frac{1}{4Da}\) ha un valore arbitrario e la costante \(a\) può avere valori estremamente piccoli.
Inoltre dalla proprietà (1) si evince una informazione piuttosto importante, ossia che la diffusione è un processo regolarizzante.
Inoltre se il dato iniziale \(g\) è continuo in \(\mathbb{R}\), allora la soluzione è continua in \(\mathbb{R} \times (0,T)\). Conseguenza di questo fatto è il poter approssimare ogni funzione continua in un intervallo \([a,b]\) con una somma di polinomi.
Più precisamente
\begin{theorem}[Teorema di Approssimazione di Weierstrass]
  Sia \(g \in \mathcal{C}([a,b])\). Allora, per ogni \(\epsilon > 0\) esiste un polinomio \(p = p(x)\) tale che 
  \begin{equation}
    \max_{x\in [a,b]} \abs*{g(x)-p(x)} \leq \epsilon
  \end{equation}
\end{theorem}
\begin{proof}
  Si estenda \(g\) con continuità su tutto \(\mathbb{R}\), in modo che risulti nulla al di fuori di un intervallo che contenga \([a,b]\), tipo \([-L,L]\). In tal modo, \(g\) risulta anche limitata su \(\mathbb{R}\). Posto \(M = \max(g)\) si ha (\(\epsilon > 0\)):
  \[
    u(x,t) = \frac{1}{2\sqrt{\pi t}} \int_{-L}^L g(y) \, dy e^{-\frac{(x-y)^2}{4t}\, dy}
  \]
  che è soluzione di \(u_t - u_{xx} = 0\) in \(\mathbb{R} \times (0,T)\), e per ogni \(\epsilon'>0\) sufficientemente piccolo, si ha
  \begin{equation}
    \max_{x \in [a,b]} \abs*{g(x) - u(x, t_0)} \leq \epsilon'
  \end{equation}
  D'altronde, avvalendosi della formula di Taylor di ordine \(N\) per la funzione esponenziale, si ha
  \[
  \left|e^{-\frac{(x-y)^2}{4t_0}} - \sum_{k = 0}^N \frac{(-1)^k}{k!} \left[\frac{(x-y)^2}{4t_0}\right]^k\right| \leq \epsilon'\sqrt{t_0}
  \]
Per ogni \(x \in [a,b]\) e \(y \in [-L, L]\). Definito il polinomio come 
\[
 p_N(x) = \frac{1}{2\sqrt{\pi t_0}} \int_{-L}^L g(y) \sum_{k=0} \frac{(-1)^k}{k!} \left[\frac{(x-y)^2}{4t_0}\right]^k dy 
\]
\(p_N(x)\) è un polinomio di grado \(2N\) e si ricava dalle ultime due equazioni
\begin{equation}
  \abs*{u(x, t_0) - p_N(x)} \leq \frac{\epsilon'}{2\sqrt{\pi}}\int_{-L}^L \abs*{g(y)}dy \leq \frac{\epsilon' LM}{\sqrt{\pi}}
\end{equation} 
per ogni \(x\in [a,b] \). Si ha quindi, dalle (2.69) e (2.70)
\begin{flalign*}
\max_{x\in[a,b]}\abs*{g(x)-p_N(x)} \leq \max_{x \in [a,b]} \abs*{g(x)-u(x, t_0)} + \max_{x \in [a,b]} \abs*{u(x,t_0 - p_N(x))} \leq \\
\leq \epsilon' \left(1+\frac{LM}{\sqrt{\pi}}\right)
\end{flalign*}
È necessario dunque che \(\epsilon' = \epsilon\left(1+\frac{LM}{\sqrt{\pi}}\right)\) per ottenere la (2.68)
\end{proof}
\section{Equazione di Laplace}
\subsection{Introduzione}
L'equazione di Laplace appare frequentemente nello studio di varie scienze applicate, un esmpio sono i fenomeni stazionari, le cui soluzioni vengono definite \emph{funzioni armoniche}. Si può scrivere come 
\begin{eqnarray}
  \Delta u = 0  & (\mbox{Equazione di Laplace}) \label{Laplace} \\
  \Delta u = f & (\mbox{Equazione di Poisson}) \label{Poisson}
\end{eqnarray}
Nella sua versione non omogenea si definisce \emph{Equazione di Poisson}, che ha un ruolo fondamnetale nella teoria dei campi conservativi, dove il vettore campo è il gradiente di un potenziale.
Dato un campo elettrostatico \textbf{E} generato da una distribuzione di cariche in un dominio \(\Omega\) di \(\mathbb{R}^3\). Si trova \(div\bm{E} = \frac{4 \pi \rho}{\epsilon}\), con \(\rho\) densità di carica e \(\epsilon\) costante dielettrica del mezzo. Quando esiste un potenziale \(u\) tale che \(\nabla u = -\bm{E}\), allora \(\Delta u = div \nabla u = -\frac{4 \pi \rho}{\epsilon}\), che restituisce la \eqref{Poisson}. Se lo spazio è privo di cariche, si ha \(\rho = 0\) e \(u\) è funzione armonica in quella regione.
In dimensione \(n = 2\), si ha uno stretto legame con la teoria delle funzioni olomorfe\footnote{Una funzione \(f = f(x)\) si può dire olomorfa in un aperto \(\Omega\) del piano complesso se in esso è derivabile, ossia se in ogni punto \(z_0 \in \Omega\) il limite 
\[
  \lim_{z \to z_0} \frac{f(z)-f(z_0)}{z-z_0} = f'(z_0)
\]}
poiché le parti reale e immaginaria di una funzione olomorfa sono armoniche. Per esempio
\[
  z^m = \rho^m(\cos{m\theta} + i \sin{m\theta}), \qquad m \in \mathbb{N}
\]
con \(\rho, \theta\) coordinate polari, sono olomorfe in tutto \(\mathbb{C}\). Di conseguenza, le funzioni
\[
\begin{array}{c}
  u(\rho, \theta) = \rho^m \cos(m\theta) \\
  v(\rho, \theta) = \rho^m \sin(m\theta)
\end{array}  
\]
sono funzioni armoniche in \(\mathbb{R}^2\).
\subsection{Problemi ben posti}
Considerata l'equazione di Poisson
\[
  \Delta u = f \qquad \mbox{ in } \Omega
\]
con \(\Omega \subset \mathbb{R}^n\) dominio limitato. 
Per i problemi ben posti si devono assegnare nuove condizioni al bordo, per cui si hanno sulla frontiera \(\partial \Omega\):
\begin{itemize}
  \item \emph{Condizione di Dirichlet}. Si assegnano i valori di \(u\):
  \begin{equation}
    u = g
  \end{equation}
  \item \emph{Condizione di Neumann}. Si assegna la derivata normale di \(u\):
  \begin{equation}
    \partial_{\bm\nu} u = h
  \end{equation}
  \item \emph{Condizione di Robin}. Si assegna 
  \begin{equation}
    \partial_{\bm{\nu}}u+\alpha u = h \qquad (\alpha > 0)
  \end{equation}
  \item \emph{Condizioni miste}. Si trovano due o più sottoinsiemi disgiunti e non vuoti la cui unione formi l'intera frontiera di \(\Omega\) e si assegna \((\overline{\Gamma}_D \cup \Gamma_N = \partial \Omega)\)
  \begin{equation}
    \begin{array}{cc}
      u=g & \mbox{su } \overline{\Gamma}_D \\
      \partial_{\bm{\nu}}u=  h & \mbox{su }\Gamma_N
    \end{array}
  \end{equation}
\end{itemize}
Nel caso si abbia \(g = h = 0\) le condizioni sono omogenee. Si immagini \(u\) come la posizione di una membrana perfettamente flessibile e \(f\) sia un carico esterno, allora la \eqref{Poisson} modella lo stato di equilibrio. In tal caso la condizione di Dirichlet descriverebbe la posizione esatta del bordo della membrana, Robin descriverebbe un attacco elastico al bordo della membrana e la condizione di Neumann rappresenterebbe la capacità della membrana di scorrere verticalmente senza attrito. \\
Grazie all'identità di Green \eqref{Identità di Green} si può dimostrare il seguente teorema di unicità:
\begin{theorem}
  Sia \(\Omega \subset \mathbb{R}^n\) un dominio limitato e regolare. Esiste al più una funzione di classe \(\mathcal{C}^2(\Omega)\cap\mathcal{C}^1(\overline{\Omega})\) soluzione di \(\Delta u = f\) in \(\Omega\) tale che, su \(\partial\Omega\)
  \[
  \begin{array}{cccc}
    u = g & \mbox{oppure} & \partial_{\nu}u +\alpha u = h & (\alpha > 0)
  \end{array}  
  \]
  oppure 
  \[
  \begin{array}{ccccc}
    u=g & \mbox{su }\overline{\Gamma}_D\subset \partial\Omega & \mbox{ e } & \partial_{\bm{\nu}}u = h & \mbox{su }\Gamma_N
  \end{array}  
  \]
  con \(f, g \mbox{ e } h\) funzioni continue assegnate. Nel caso delle condizioni di Neumann, ossia
  \[
    \partial_{\bm{\nu}}u = h \qquad \mbox{su }\partial\Omega
  \]
  due soluzioni differiscono per una costante.
\end{theorem}
\begin{proof}
  Siano \(u\) e \(v\) soluzioni dello stesso problema. Posto \(w = u-v\), allora \(\Delta w = 0\) e soddisfa una delle quattro condizioni al bordo. Sostituendolo nella \eqref{Identità di Green} si ottiene
  \[
    \int_{\Omega} \abs*{\nabla w}^2 \, d\bm{x} = \int_{\partial\Omega} w\partial_{\bm{\nu}} w\, d\sigma
  \]
  Ma nel caso di Dirichlet, Neumann e condizioni miste si ha
  \[
   \int_{\partial\Omega} w\partial_{\bm{\nu}} w \, d\sigma 
  \]
  mentre nel caso di Robin 
  \[
  \int_{\partial\Omega} w\partial_{\bm{\nu}}  w \, d\sigma = -\int_{\partial\Omega} \alpha w^2 \, d\sigma \leq 0
  \]
  da cui si può dedurre, in ogni caso, che 
  \[
    \int_{\Omega}\abs*{\nabla w}^2 \, d\bm{x} \leq 0
  \]
  che implica \(\nabla w = 0\) e dunque che \(w = u-v\) sia costante poiché \(\Omega\) è connesso. Negli altri casi la costante deve essere nulla, da cui si ha \(u = v\)
\end{proof}
\subsection{Funzioni armoniche}
Anche con le funzioni armoniche esiste una stretta correlazione con la passeggiata aleatoria e il moto Browniano. Fissata una dimensione \(n = 2\) (si può estendere il ragionamento a ogni dimensione), siano \(\tau > 0\) il passo temporale e \(h > 0\) quello nello spazio. Sia a sua volta \(h\mathbb{Z}^2\) il reticolo di punti \(\bm{x} = (x_1, x_2)\), con coordinate multipli interi di \(h\). Con \(p(\bm{x}, t) =  p(x_1, x_2, t)\) che rappresenta la probabilità di trovare la particella in un punto \(\bm{x}\) al tempo \(t\). L'equazione alle differenze per \(p\) in dimensione due si scrive come
\[
  p(\bm{x}, t+ \tau) = \frac{1}{4} \{p(\bm{x}+h\bm{e}_1, t) + p(\bm{x}-h\bm{e}_1, t) + p(\bm{x}+h\bm{e}_2, t) + p(\bm{x}-h\bm{e}_2, t)\}
\]
Per riscrivere tutto ciò si può introdurre l'operatore media \(M_h\) che si applica su generiche funzioni \(u =  
u(\bm{x})\) come
\begin{flalign*}
  M_hu(\bm{x}) &= \frac{1}{4}\{u(\bm{x}+h\bm{e}_1, t) + u(\bm{x}-h\bm{e}_1, t) + u(\bm{x}+h\bm{e}_2, t) + u(\bm{x}-h\bm{e}_2, t)\} = \\
  & = \frac{1}{4}\sum_{\abs*{\bm{x}- \bm{y}} = h}u(\bm{y})
\end{flalign*}
Si noti che \(M_hu(\bm{x})\) è la media aritmetica dei valori di \(u\) nei punti del reticolo \(h\mathbb{Z}^2\), posti a distanza \(h\) da \(\bm{x}\).
L'equazione alle differenze allora prende la forma
\begin{equation}
  p(\bm{x}, t + \tau) = M_hp(\bm{x}, t)
\end{equation}
La probabilità al tempo \(t + \tau\) è quindi determinata dall'azione di \(M_h\) sulla funzione \(p\) al tempo precedente. \(M_h\) è quindi il \emph{generatore della passeggiata aleatoria}.\\
Inoltre, se \(u\) è una funzione di classe \(\mathcal{C}^2\), grazie alla formula di Taylor\footnote{La formula di Taylor al secondo ordine, dopo l'elisione dei termini opposti al primo ordine, è:
\[
Mu(\bm{x}) = u(\bm{x}) + \frac{h^2}{4}\{u_{x_1x_1}(\bm{x})+ u_{x_2x_2}(\bm{x}) + o(h^2)\} 
\]} si ha
\begin{equation}
\lim_{h \to 0} \frac{M_h u(\bm{x}) - u(\bm{x})}{h^2} \to \frac{1}{4} \Delta u(\bm{x})  
\end{equation}
Dalla (3.8) si può definire l'operatore di Laplace discreto, per ogni \(h > 0\) fissato, come
\[
  \Delta_h^* = M_h - I
\]
dove \(I\) indica l'operatore identità (\(Iu = u\)). \(\Delta_h^*\) è ben definito in tutte le funzioni \(u\) del reticolo \(h\mathbb{Z}^2\) e la funzione è \emph{d-armonica} (con \emph{d} discreto) se \(\Delta_h^* = 0\).
Una funzione \emph{d-armonica} è una funzione che in ogni punto \(\bm{x}\) coincide con la media dei valori nei punti in un intorno discreto di \(\bm{x}\) di raggio \(h\).
Per definire un problema di Dirichlet discreto, sia \(A\) un sottoinsieme limitato di \(h\mathbb{Z}^2\) e \(\bm{x} \in A\):
\begin{itemize}
  \item \(\bm{x}\) è un punto interno di \(A\) se il suo intorno discreto di raggio \(h\) è contenuto in \(A\)
  \item $\bm{x}$ è un punto di frontiera se non è interno ma il suo intorno discreto contiene almeno un punto interno. L'insieme dei punti di frontiera si indica come \(\partial A\)
\end{itemize}
Il \textbf{problema di Dirichlet discreto} si definisce così allora: \\
Sia \(A\) un sottoinsieme limitato e connesso di \(h\mathbb{Z}^2\) e \(g\) una funzione definita sulla frontiera \(\partial A\). Si determini \(u\) in \(A\) tale che 
\begin{equation}
  \begin{cases}
    \Delta_h^* u= 0 & \mbox{nei punti interni di }A \\
    u = g & \mbox{su }\partial A
  \end{cases}
\end{equation}
Sia \(u\) soluzione della (3.9), allora ne derivano due importanti proprietà:
\begin{enumerate}
  \item Principio di massimo: se \(u\) assume il suo massimo (o minimo) in un punto interno allora \(u\) è costante. Si immagini che \(\bm{x} \in A\) sia punto interno e che \(u(\bm{x}) = M \geq u(\bm{y})\) per ogni \(\bm{y} \in A\). Poiché \(u(\bm{x})\) è la media aritmetica dei valori assunti nei quattro punti posti a distanza \(h\) da \(\bm{x}\), in ognuno di questi punti \(u\) deve avere lo stesso valore di \(M\). Allo stesso modo, sia 8\(\bm{x}_1 \not = \bm{x}\) uno dei quattro punti, \(u(\bm{y}) = M\) per ogni \(\bm{y}\) nell'intorno di raggio \(h\) di \(\bm{x}_1\). Il fatto che \(A\) sia un insieme connesso e finito, permette di mostrare che \(u(\bm{y}) = M\) in ogni punto di \(A\). \\
  Per questo motivo il massimo (o minimo) di \(u\) è assunto sulla frontiera di \(A\).
  \item La soluzione del problema di Dirichlet è unica, essendo la soluzione \(u\) una funzione d-armonica, si immagini di avere una funzione \(v\) anche essa soluzione del problema di Dirichlet. Allora anche \(v\) deve essere una funzione d-armonica che rispetti il principio di massimo sopra enunciato. Ma poiché la frontiera di \(A\) è sempre la stessa \((u-v)(\bm{x} = 0 \, \forall \bm{x} \in A)\), quindi il massimo (o minimo) di \(v\) coincide con quello di \(u\), ossia le due funzioni coincidono.
\end{enumerate}
Dal problema (3.9) sorge una interessante interpretazione probabilistica, che è di grande aiuto per la costruzione di una soluzione. La funzione \(g\) della passeggiata aleatoria della particella rappresenta un \emph{guadagno}, ossia, con una particella che parte da \(\bm{x}\) e termina la sua passeggiata sulla frontiera di \(A\) in \(\bm{y}\), allora il guadagno è pari a \(g(\bm{y})\). \\
Si vuole mostrare che la particella, indipendentemente dal punto di partenza, raggiunge sempre la frontiera \(\partial A\), e che il valore \(u(\bm{x})\) rappresenta il valore atteso del guadagno \(g\) rispetto a una opportuna distribuzione di probabilità su \(\partial A\). Sia \(\Gamma \subseteq \partial A\), allora 
\[
  P(\bm{x}, \Gamma)
\]
indica la probabilità che la particella, partendo da \(\bm{x}\), giunga per la prima volta in un punto \(\bm{y} \in \Gamma\) sulla frontiera. Si vuole mostrare che \(P(\bm{x}, \partial A) = 1 \quad \forall \bm{x} \in A\).
Nel caso in cui \(\bm{x} \in \Gamma\), si ottiene \(P(\bm{x}, \Gamma) = 1\), mentre con \(\bm{x} \in \partial A\backslash \Gamma\) si ha \(P(\bm{x}, \Gamma) = 0\). \\
Fissato l'insieme \(\Gamma\) si ha che 
\[
  \bm{x} \longrightarrow w_{\Gamma}(\bm{x}) \equiv P(\bm{x}, \Gamma)
\]
è una funzione d-armonica nei punti interni di \(A\), ossia l'operatore di Laplace discreto \(\Delta^*_h w_{\Gamma} = 0\). Inoltre indicata come
\[
p(1, \bm{x}, \bm{y})  
\]     
la probabilità di transizione, ossia la probabilià di passare dal punto \(\bm{x} \mbox{ a } \bm{y}\) in un solo passo. La simmetria del moto permette di sapere che \(p(1, \bm{x}, \bm{y}) =  \frac{1}{4}\) se \(\abs*{\bm{x} -\bm{y}} = 1\), altrimenti \(p(1, \bm{x}, \bm{y}) = 0\). Poiché \(w_{\Gamma}(\bm{x})\) può essere ottenuta come somma di eventi disgiunti ed esaustivi (ossia la cui somma è l'evento certo), si ottiene così:
\[
  w_{\Gamma}(\bm{x}) = \sum_{\bm{y} \in h\mathbb{Z}^2}p(1, \bm{x}, \bm{y})w_{\Gamma}(\bm{y}) = M_hw_{\Gamma}(\bm{x})
\]
che è, di fatto, l'equivalente di 
\[
  (I - M_h)w_{\Gamma} = \Delta^*_h w_{\Gamma} = 0
\]
da cui si deduce che la funzione \(w_{\Gamma}\) è d-armonica in \(A\). Nel caso in cui \(\Gamma \equiv \partial A\), la funzione \(w_{\partial A}\) è sempre d-armonica e assume valore \(1\) al bordo. Inoltre, poiché la soluzione del problema di Dirichlet è unica, si ha \(w_{\partial A} \equiv 1\) in tutto \(A\). Pertanto raggiungere \(\partial A\) partendo da un punto \(\bm{x}\) è un evento certo, per cui si nota che la funzione 
\[
\Gamma \longrightarrow P(\bm{x}, \Gamma)  
\]
è additiva e definisce una misura di probabilità su \(\partial A\). \\
La soluzione \(u\) della (3.9) diventa facile da comporre:
\begin{theorem}
  Il valore della soluzione del problema di Dirichlet discreto nel punto \(\bm{x}\) è dato dal valore atteso del guadagno \(g(\cdot)\) rispetto alla probabilità \(P(\bm{x}, \cdot)\), ossia 
  \begin{equation}
    u(\bm{x}) = \sum_{\bm{y}\in \partial A} g(\bm{y})P(\bm{x}, \{\bm{y}\})
  \end{equation}
\end{theorem}
\begin{proof}
  Ogni addendo
  \[
  g(\bm{y})P(\bm{x}, \{\bm{y}\}) = g(\bm{y}) w_{(\bm{y})}(\bm{x})
  \]
  è d-armonico in \(A\), e quindi lo è anche \(u\). \\
  Se \(\bm{x} \in \partial A\) allora \(u(\bm{x}) = g(\bm{x})\) dal momento che ogni termine della somma è pari a \(g(\bm{x})\) se \(\bm{x} = \bm{y}\) o è nullo se \(\bm{x} \not = \bm{y}\).
\end{proof}
Il caso discreto permette di stabilire alcune proprietà fondamentali delle funzioni armoniche. Una funzione è armonica in un dominio \(\Omega \subseteq \mathbb{R}^n\) se \(u \in \mathcal{C}^2(\Omega) \mbox{ e }\Delta u = 0 \mbox{ in } \Omega\). Dal momento che le funzioni d-armoniche hanno una definizione in termini di media, ci si può aspettare che anche le funzioni armoniche godano di proprietà simili. Si immagini una sfera \(B_r(\bm{x})\)\footnote{Con questa dicitura si intende una sfera di raggio \(r\) centrata nel punto \(\bm{x}\).}, che sia \(\subset \subset\)\footnote{Il simbolo \(\subset \subset\) indica una \emph{chiusura compatta contenuta}, ossia il sottoinsieme contenuto all'interno non ha punti di contatto con l'insieme principale.}. Nel caso di una sfera \(B_r \subset \subset \Omega\) il valore al centro della sfera uguaglierà la media aritmetica dei valori al bordo \(\partial B_r\). Sapendo che \(\omega_n\) indica la misura superficiale di \(\partial B_1\) e \(\abs*{B_1} = \frac{\omega_n}{n}\) rappresenta il volume.
\begin{theorem}
  Sia \(u\) funzione armonica in \(\Omega \subset \mathbb{R}^n\). Per ogni sfera \(B_r(\bm{x}) \subset \subset \Omega\), valgono le formule
  \begin{eqnarray}
    u(\bm{x}) = \frac{n}{\omega_n R^n} \int_{B_R(\bm{x})u(\bm{y})} \, d\bm{y} \\
    u(\bm{x}) = \frac{1}{\omega_n R^{n-1}} \int_{\partial B_R(\bm{x})} u(\bm{\sigma}) \, d\sigma
  \end{eqnarray}
  con \(d\sigma\) che rappresenta l'elemento di superficie su \(\partial B_R(\bm{x})\).
\end{theorem}
\begin{proof}
  La seconda formula si può scrivere, ponendo \(r < R\)
  \[
    g(r) = \frac{1}{\omega_n R^{n-1}}\int_{\partial B_r(\bm{x})} u(\bm{\sigma}) \, d\sigma
  \]
  Attuando un cambio di variabili e ponendo \(\bm{\sigma} = \bm{x} + r\bm{\sigma}'\) si avranno come estremi di integrazione \(\bm{\sigma}' \in \partial B_1(\bm{0}), \, d\sigma = r^{n-1}d\sigma'\) e quindi
  \[
    g(r) = \frac{1}{\omega_n} \int_{\partial B_1(\bm{\sigma})} u(\bm{x}+r\bm{\sigma}') \, d\sigma'
  \] 
  Posta una funzione \(v(\bm{y})\) in modo che \(v(\bm{y}) = u(\bm{x} + r\bm{y})\). 
  Questo permette di ottenere: 

  \begin{eqnarray*}
    \nabla v(\bm{y}) = r\nabla u(\bm{x} + r\bm{y}) \\
  \Delta v(\bm{y}) = r^2\Delta u (\bm{x} + r\bm{y})
  \end{eqnarray*}
  Si ha, allora, 
  \begin{eqnarray*}
  g'(r) & = & \frac{1}{\omega_n} \int_{\partial B_1(\bm(0))} \frac{d}{dr}u(\bm{x} + r\bm{\sigma}') \, d\sigma' = \frac{1}{\omega_n} \int_{\partial B_1(\bm{0})} \nabla u(\bm{x} + r\sigma') \cdot \bm{\sigma}' \, d\sigma' \\
  & = & \frac{1}{\omega_n r} \int_{\partial B_1 (\bm{0})} \nabla v(\bm{\sigma}') \cdot \bm{\sigma}' \, d\sigma' = (\mbox{Teorema della Divergenza}) \\
  & = & \frac{1}{\omega_n r} \int_{B_1 (\bm{0})} \Delta v(\bm{y}) \, d\bm{y} = \frac{r}{\omega_n} \int_{B_1(\bm{0})} \Delta u(\bm{x} + r\bm{y}) \, d\bm{y} = 0
  \end{eqnarray*}
  Per questo motivo \(g\) è costante, poiché \(g(r) \to u(\bm{x})\) con \(r \to 0\) si ottiene la (3.12). \\
  La (3.11) si ottiene moltiplicando la (3.12) per \(r^{n-1}\) e integrando entrmabi i membri tra \(0 \mbox{ e } R\) si ottiene
  \[
    \frac{R^n}{n} u(\bm{x}) = \frac{1}{\omega_n} \int_0^Rdr \int_{\partial B_r(\mathbf{0})} u(\bm{\sigma}) \, d\sigma = \frac{1}{\omega_n} \int_{B_R(\bm{x}}) u(\bm{y}) \, d\bm{y}
  \]
  che restituisce la (3.11)
\end{proof}
L'inverso del Teorema (3.3) permette di affermare che una funzione continua \(u\) soddisfa la proprietà di media in \(\Omega\) se la (3.11) o la (3.12) valgono per ogni sfera \(B_R(\bm{x}) \subset \subset \Omega\).
Da questa affermazione si ricava una informazione fondamentale, ossia che tale funzione risulta necessariamente armonica in \(\Omega\). Inoltre si apprende che una funzione armonica in \(\Omega\) è dotata di derivate di ogni ordine, dunque è di classe \(\mathcal{C}^{\infty}(\Omega)\).
\begin{theorem}
  Sia \(u \in \mathcal{C}(\Omega).\) Se \(u\) ha la proprietà di media, allora si tratta di una funzione armonica e \(\mathcal{C}^{\infty}\) in \(\Omega\).
\end{theorem}
\begin{proof}
  Si osservi che, due funzioni che hanno la proprietà di media in un dominio \(\Omega\) trasmettono la stessa proprietà alla loro differenza. Sia \(u \in \mathcal{C}(\Omega)\), con la proprietà di media e si consideri una sfera \(B \subset \subset \Omega\) e una funzione \(v\) soluzione del problema 
  \[
    \begin{array}{cccc}
      \Delta v = 0 & \mbox{in }B, & v = u & \mbox{su }\partial B
    \end{array}
  \]
  Come verrà mostrato più avanti, \(v \in \mathcal{C}^{\infty}(B)\cap \mathcal{C}(\overline{B})\) ed è una funzione armonica con proprietà di media in \(B\). Allora anche una funzione \(w  = u - v\) ha proprietà di media in \(B\) e assume il suo massimo e minimo su \(\partial B\). Essendo \(w = 0\) su \(\partial B\) si deduce che \(u = v\) e allora \(u \in \mathcal{C}(B)\)

\end{proof}
Se una funzione possiede proprietà di media in un dominio \(\Omega\), non può assumere massimi (o minimi) in punti interni al dominio, eccetto nel caso in cui sia costante. Se \(\Omega\) è limitato. Nel caso di \(\Omega\) limitato e \(u\) non costante e continua in \(\overline{\Omega}\), allora \(u\) assume il suo massimo (o minimo) esclusivamente su \(\partial \Omega\).
\begin{theorem}[Principio di massimo (o minimo)]
  Se \(u \in \mathcal{C}(\Omega)\) ha la proprietà di media nel dominio \(\Omega \subseteq \mathbb{R}^n\) e \(\bm{p} \in \Omega\) è un punto di massimo (o minimo) globale per \(u\), allora \(u\) è costante. In particolare, nel caso \(\Omega\) sia limitato e \(u \in \mathcal{C}(\overline{\Omega})\) non sia costante, allora \(\forall \bm{x} \in \Omega\):
  \[
  u(\bm{x}) < \max_{\partial \Omega} u \qquad (u(\bm{x}) > \min_{\partial \Omega} u) 
  \]
\end{theorem}
\begin{proof}
  Sia \(u\) non costante e \(\bm{p}\) un punto di minimo:
  \[
    m = u(\bm{p}) \leq u(\bm{y}) \qquad \forall \bm{y} \in \Omega
  \]
  Si prenda un ulteriore punto \(\bm{q}\) all'interno di \(\Omega\). Per le proprietà di \(\Omega\)\footnote{Insieme aperto e connesso} si può determinare una sequenza finita di sfere \(B(\bm{x}_j) \subset \subset \Omega, j = 0, \ldots, N\) tali che 
  \begin{itemize}
    \item \(\bm{x}_j \in B(\bm{x}_{j-1})\) per ogni \(j = 1, \ldots, N\)
    \item \(x_0 = \mathbf{p}, x_N = \mathbf{q}\)
  \end{itemize}
  Per la proprietà di media (\(\abs*{B(\mathbf{p})}\) indica il volume della sfera \(B(\mathbf{p})\)):
  \[
    m = u(\bm{p}) = \frac{1}{\abs*{B(\bm{p})}} \int_{B(\bm{p})} u(\bm{y}) \, d\bm{y}
  \]
Se esiste \(\bm{z} \in B(\bm{p})\) tale che \(u(\bm{z}) > m\), allora, presa una sfera \(B_r(\bm{z}) \subset B(\bm{p})\), si può scrivere
\begin{eqnarray*}
  m & = & \frac{1}{\abs*{B(\bm{p})}} \int_{B(\bm{p})u(\bm{y})} \, d\bm{y} \\
  & = & \frac{1}{\abs*{B(\bm{p})}} \left\lbrace \int_{B(\bm{p})\backslash B_r(\bm{z})} u(\bm{y}) \, d\bm{y} + \int_{B_r(\bm{z})} u(\bm{y}) \, d\bm{y} \right\rbrace
\end{eqnarray*}
Grazie alla proprietà di media si ha
\begin{equation}
  \int_{B_r(\bm{z})} u(\bm{y}) \, d\bm{y} = u(\bm{z})\abs*{B_r(\bm{z})} > m\abs*{B_r(\bm{z})}
\end{equation}
Poiché \(u(\bm{y}) \geq m\) per ogni punto \(\bm{y}\) dalle equazioni precedenti si ottiene la contraddizione
\[
  m > \frac{1}{\abs*{B(\bm{p})}} \{m\abs*{B(\bm{p)}\backslash B_r(\bm{z})} + m\abs*{B_r(\bm{z})}\} = m
\]
Dunque in tutta \(B(\bm{p})\) si ha \(u = m\), in particolare in \(\bm{x}_1\). Tale ragionamento si può iterare, deducendo che \(u = m\) in \(B(\bm{x}_1)\), in particolare in \(\bm{x}_2\), e ancora fino a \(\bm{x}_N = \bm{q}\). Dal momento che \(\bm{q}\) è un punto arbitrario, permette di affermare che \(u = m\) in tutto \(\Omega\)
\end{proof}.
Si ricava un corollario per l'unicità della soluzione di Dirichlet. Definita, per ogni funzione \(g\) su \(\partial \Omega\), una soluzione \(u_g\) di 
\begin{equation}
  \begin{cases}
    \Delta u = 0 & \mbox{in }\Omega \\
    u = g & \mbox{su }\partial \Omega
  \end{cases}
\end{equation}
\begin{corollary}
  Siano \(\Omega\) un dominio limitato in \(\mathbb{R}^n\) e \(g \in \mathcal{C}(\partial\Omega)\). Il problema (3.14) ha, al massimo, una soluzione \(\in \mathcal{C}^2(\Omega) \cap \mathcal{C}(\overline{\Omega})\). Siano \(g_1, g_2 \in \mathcal{C}(\partial \Omega)\)
\begin{itemize}
  \item \emph{Confronto}: se \(g_1 \geq g_2\) su \(\partial \Omega\) e \(g_1 \not = g_2\) in almeno un punto della frontiera di \(\Omega\), allora 
  \begin{equation}
  u_{g_1} > u_{g_2} \qquad \mbox{in } \Omega  
  \end{equation}
  \item \emph{Stabilità}:
  \begin{equation}
    \max_{\overline{\Omega}}\abs*{u_{g_1} - u_{g_2}} = \max_{\partial \Omega}\abs*{g_1 - g_2}
  \end{equation} 
\end{itemize}
\end{corollary}
\begin{proof}
  La funzione \(w = u_{g_1} - u_{g_2}\) è armonica e uguale a \(g_1 - g_2\) su \(\partial \Omega\). Dal momento che in almeno un punto di \(\partial\Omega\) \(g_1\) e \(g_2\) differiscono, la funzione \(w\) non è costante, e, grazie al teorema (3.5), si deduce che 
  \[
    w(\bm{x}) > \min_{\partial \Omega}(g_1 - g_2) \geq 0 \qquad \mbox{per ogni } \bm{x} \in \Omega
  \]
  che è esattamente la (3.15). Applicando lo stesso teorema a \(w \mbox{ e } -w\) si deducono le seguenti disuguaglianze
  \[
    \pm w(\bm{x}) \leq \max_{\partial \Omega}\abs*{g_1 - g_2} \qquad \mbox{per ogni }\bm{x} \in \Omega
  \]
  da cui la (3.16). Nel caso in cui \(g_1 = g_2\), la (3.16) implicherebbe che 
  \[
    \max_{\overline{\Omega}}\abs*{u_1 - u_2} = 0
  \]
  ossia che \(u_1  = u_2\), confermando l'unicità della soluzione per il problema di Dirichlet.
\end{proof}
In caso di geometrie particolari si possono utilizzare metodi speciali per risolvere il problema di Dirichlet, come il metodo di separazione delle variabili. Nel caso di un cerchio nel piano. Siano \(B_R(\bm{p})\) il cerchio di raggio \(R\) con centro \(\bm{p} = (p_1, p_2)\) e \(g \in \mathcal{C}(\partial B_R(\bm{p}))\). Per determinare la soluzione \(u \in \mathcal{C}^2(B_R(\bm{p})) \cap \mathcal{C}(\overline{B}_R(\bm{p}))\) del problema
\begin{equation}
  \begin{cases}
    \Delta u = 0 & \mbox{in }B_R(\bm{p}) \\
    u = g  & \mbox{su } \partial B_R(\bm{p})
  \end{cases}
\end{equation}
\begin{theorem}
  L'unica soluzione \(u \in \mathcal{C}^2(B_R(\bm{p})) \cap \mathcal{C}(\overline{B}_R(\bm{p}))\) del problema (3.17) è data dalla seguente formula
  \begin{equation}
    u(\bm{x}) = \frac{R^2 - \abs*{\bm{x}- \bm{p}}^2}{2\pi R}\int_{\partial B_R(\bm{p})} \frac{g(\bm{\sigma})}{\abs*{\bm{x}-\bm{\sigma}}^2} \, d\sigma
  \end{equation}
  In particolare, si ha \(u \in \mathcal{C}^{\infty}(B_R(\bm{p}))\).
\end{theorem}
\begin{proof}
  Si fissi \(\bm{p} = \bm{0}\), allora si avrà \(B_R = B_R(\bm{0})\). La simmetria del dominio suggerisce l'utilizzo di coordinate polari. Siano allora 
  \[
  x_1 = r\cos\theta, \qquad x_2 = r \sin\theta
  \]
  e 
  \[
    U(r, \theta) = u(r\cos\theta, r\sin\theta), \quad G(\theta) = g(R \cos \theta, R \sin \theta)
  \]
  L'operatore di Laplace si riscrive in coordinate polari\footnote{{\everymath = {\displaystyle}\(\Delta f = \frac{\partial^2 f}{\partial r^2} + \frac{1}{r}\frac{\partial f}{\partial r} + \frac{1}{r^2}\frac{\partial^2 f}{\partial \theta^2}\)}} e si ottiene
  \begin{equation}
    U_{rr} + \frac{1}{r} U_r + \frac{1}{r^2}U_{\theta\theta} = 0, \qquad 0 < r < R, 0 \leq \theta \leq 2\pi
  \end{equation}
con la seguente condizione di Dirichlet
\[
U(R, \theta) = G(\theta), \qquad 0 \leq \theta \leq 2\pi
\]
La soluzione deve essere continua, dunque \(U\) e \(G\) saranno continue rispettivamente in \([0,R] \times [0, 2\pi]\) e \([0,2\pi]\) e periodiche rispetto a \(\theta\) con un periodo \(2\pi\).
Con il metodo di separazione delle variabili si trovano soluzioni del tipo 
\[
  U(r, \theta) = v(r)w(\theta)
\]
con le funzioni \(v,w\) limitate e \(w\) periodica con periodo \(2\pi\). Effettuando la sostituzione nella (3.19) si ricava 
\[
  v''(r)w(\theta) + \frac{1}{r} v'(r)w(\theta)+\frac{1}{r^2} v(r)w''(\theta) = 0\]
  che diventa, separando le due variabili
  \[
  -\frac{r^2v''(r)+rv'(r)}{v(r)} = \frac{w''(\theta)}{w(\theta)}  
  \] 
  che è un'identità possibile solo quando i due quozienti sono accomunati da una costante \(\lambda\). I due membri dell'equazione costituiscono una equazione differenziale ordinaria
  \begin{equation}
    r^2v''(r) + rv'(r) + \lambda v(r) = 0
  \end{equation}
  e un problema di autovalori
  \begin{equation}
    \begin{cases}
      w''(\theta) - \lambda w(\theta) = 0 \\
      w \mbox{ funzione periodica }(2\pi) 
    \end{cases}
  \end{equation}
  Il problema nella (3.21) ha soluzione nulla se \(\lambda \geq 0\). Con \(\lambda = -\mu^2, \mu \geq 0\) si ha come integrale generale della \((3.21)\)
  \[
    w(\theta) = a \cos{\mu\theta} + b \sin{\mu\theta} \qquad (a,b \in \mathbb{R})
  \]
  Dal momento che \(w\) è periodica, si ha \(\mu = m\), che inserito nella (3.20), come \(\lambda = -m^2\), restituisce, poiché si tratta di una equazione di Eulero
  \[
    v(r) = d_1r^{-m} + d_2r^{m}, \qquad (d_1, d_2 \in \mathbb{R})
  \]
  Dal momento che \(v\) è, per definizione, limitata, si può escludere \(r^{-m}\), per cui \(d_1 = 0\). Da queste informazioni si ricavano le infinite armoniche elementari
  \[
    r^m\{a_m \cos{m\theta} + b_m \sin{m\theta}\} \qquad m = 0, 1, 2, \ldots
  \] 
Poiché l'equazione di Laplace è lineare, si possono sovrapporre queste soluzioni, ottenendo una soluzione possibile
\begin{equation}
  U(r, \theta) = a_0 + \sum_{m=1}^{\infty} r^m \{a_m \cos{m\theta} + b_m \sin{m\theta}\}
\end{equation}
con i coefficienti \(a, b\) scelti opportunamente in modo da rispettare la condizione al bordo
\begin{equation}
  \lim_{(r,\theta) \to (R, \xi)} U(r, \theta) = G(\xi) \qquad \forall \xi \in [0, 2\pi]
\end{equation}
Si distinguono ora due casistiche principali:
\begin{itemize}
  \item \textbf{Caso} \(\bm{G \in \mathcal{C}^{1}([0, 2\pi])}\)
\end{itemize}
Il primo caso implica che la funzione \(G\) sia regolare e dotata almeno di derivata \(G'\) continua in \([0, 2\pi]\). In tal caso si può sviluppare la serie di Fourier
\[
  G(\xi) = \frac{\alpha_0}{2} + \sum_{m = 1}^{\infty} \{\alpha_m \cos{m\xi} + \beta_m \sin{m\xi} \}
\]
che ha convergenza uniforme e si hanno
\begin{eqnarray*}
  \alpha_m & = & \frac{1}{\pi} \int_0^{2\pi} G(\phi) \cos{m\phi} \, d\phi \\
  \beta_m & = & \frac{1}{\pi} \int_0^{2\pi} G(\phi) \sin{m\phi} \, d\phi
\end{eqnarray*}
Allora per soddisfare la condizione (3.23) si scelgono i valori
\[
  \begin{array}{ccc}
    a_0 = \frac{\alpha_0}{2}, & a_m = R^{-m}\alpha_m, b_m = R^{-m} \beta_m
  \end{array}
\]
Questi valori all'interno della (3.22) permettono di ottenere:
\[
\begin{array}{cl}
  U(r, \theta) = & \\
  = & \frac{\alpha_0}{2} + \frac{1}{\pi} \sum_{m=1}^{\infty} (\frac{r}{R})^m \int_0^{2\pi} G(\phi) \{\cos{m\phi}\cos{m\theta} + \sin{m \phi} \sin{m\theta} \, d\phi\} \\
  = & \frac{1}{\pi} \int_0^{2\pi} G(\phi) \left[\frac{1}{2} + \sum_{m=1}^{\infty} \left(\frac{r}{R}\right)^m \{\cos{m\phi} \cos{m\theta} + \sin{m\phi} \sin{m\theta}\}\right] \, d\phi \\
  = & \frac{1}{\pi} \int_0^{2\pi} G(\phi) \left[\frac{1}{2}+ \sum_{m=1}^{\infty} \left(\frac{r}{R}\right)^m \cos{m(\phi - \theta)}\right] \, d\phi
\end{array}
\]
Per \(r < R\) la serie nell'ultimo passaggio converge uniformemente insieme alle derivate di ogni ordine, inoltre, essendo somma di funzioni armoniche, anche \(U(r, \theta)\) è funzione armonica e \(\mathcal{C}^{\infty}(B_R)\). \\
Tra le parentesi quadre dell'ultimo termine appare la parte reale di una serie geometrica, più precisamente
\[
  \sum_{m=1}^{\infty} \left(\frac{r}{R}\right) \cos{m(\phi - \theta)} = \Re\left[\sum_{m=1}^{\infty}\left(e^{i(\phi -\theta)}\frac{r}{R}\right)^m\right]
\]
Dal momento che 
\[
\begin{array}{lcl}
  \Re\sum_{m=1}^{\infty} \left(e^{i(\phi - \theta)}\frac{r}{R}\right)^m & = & \Re\frac{1}{1-e^{i(\phi - \theta)}\frac{r}{R}} - 1 \\
  & = & \frac{R^2 - rR\cos{(\phi - \theta)}}{R^2 + r^2 - 2rR\cos{(\phi -\theta)}} - 1 \\
  & = & \frac{rR\cos{(\phi -\theta)}-r^2}{R^2 +r^2 - 2rR\cos{(\phi - \theta)}}
\end{array}  
\]
permette di ottenere 
\begin{equation}
  \frac{1}{2} + \sum_{m=1}^{\infty} \left(\frac{r}{R}\right)^m \cos{m(\phi - \theta)} = \frac{1}{2}\frac{R^2 - r^2}{R^2 + r^2 - 2rR\cos{(\phi - \theta)}}
\end{equation}
che permette di ricavare nella \(U\) la formula di Poisson in coordinate polari
\begin{equation}
  U(r, \theta) = \frac{R^2 - r^2}{2\pi}\int_0^{2\pi} \frac{g(\phi)}{R^2 + r^2 - 2rR \cos{(\theta - \phi)}} \, d\phi
\end{equation}
Che in variabili cartesiane torna a essere
\begin{equation}
  u(\bm{x}) = \frac{R^2 - \abs*{\bm{x}}^2}{2\pi R} \int_{\partial B_R} \frac{g(\bm{\sigma})}{\abs*{\bm{x}-\bm{\sigma}}}\, d\sigma
\end{equation}
che è esattamente la (3.18) con \(\bm{p} = \bm{0}\).
Dal corollario (3.1) si può affermare che la (3.26) è soluzione unica del problema di Dirichlet (3.17). Inoltre, essendo \(u(\bm{x}) \equiv 1\) la soluzione del problema di Dirichlet con \(g \equiv 1\) si ricava
\begin{equation}
  \frac{R^2 - \abs*{\bm{x}}^2}{2\pi R} \int_{\partial B_R} \frac{1)}{\abs*{\bm{x}-\bm{\sigma}}}\, d\sigma = 1
\end{equation}
\begin{itemize}
  \item \textbf{Caso} \(\bm{g \in \mathcal{C}(\partial B_R)}\)
\end{itemize}
Nel caso più generale in cui l'unica informazione è che la funzione \(g\) è continua, la formula (3.26) continua ad avere senso e a definire una funzione armonica e \(\mathcal{C}^{\infty}(B_R)\). Il problema ora sta nel mostrare 
\[
  \lim_{\bm{x} \to \bm{\xi}} u(\bm{x}) = g(\bm{\xi}), \qquad \forall \bm{\xi} \in \partial B_R
\]
Fissato \(\bm{\xi} \in \partial B_R, \epsilon > 0\). La continuità di \(g\) permette di scegliere un arco \(\Gamma_{\delta} \subset \partial B_R\) di lunghezza \(\delta\) e centrato nel punto \(\xi\) in modo da ottenere
\[
  \abs*{g(\bm{\sigma}) - g(\bm{\sigma})} < \epsilon \mbox{ su }\Gamma_{\delta}
\]
Grazie alla (3.27) si può riscrivere
\begin{flalign*}
    u(\bm{x}) - g(\bm{\xi}) = \frac{R^2 - \abs*{\bm{x}}^2}{2\pi R} \int_{\partial B_R} \frac{g(\bm{\sigma}) - g(\bm{\xi})}{\abs*{\bm{x}-\bm{\sigma}}}\, d\sigma = \\
    = \frac{R^2 - \abs*{\bm{x}}^2}{2\pi R} \int_{\Gamma_{\delta}} (\ldots) \, d\sigma + \frac{R^2 - \abs*{\bm{x}}^2}{2\pi R} \int_{\partial B_R \backslash \Gamma_{\delta}} (\ldots) \, d\sigma \equiv I + II
\end{flalign*}
Poiché \(\abs*{u(\bm{x}) - g(\bm{\xi})} \leq \abs*{I} + \abs*{II}\), basta mostrare che \(\abs*{I} < \epsilon\) e che \(\abs*{II} \to 0\) se \(\bm{x} \to \bm{\xi}\).
Grazie alla (3.29) e (3.27) si ha la soluzione del primo punto, infatti
\begin{equation}
  \abs*{I} \leq \frac{R^2 - \abs*{\bm{x}}^2}{2\pi R} \int_{\partial B_R} \frac{g(\bm{\sigma}) - g(\bm{\xi})}{\abs*{\bm{x}-\bm{\sigma}}}\, d\sigma < \epsilon \frac{R^2 - \abs*{\bm{x}}^2}{2\pi R} \int_{\partial B_R} \frac{1}{\abs*{\bm{x}-\bm{\sigma}}}\, d\sigma < \epsilon
\end{equation}
E, siccome \(\bm{x} \to \bm{\xi}\) e \(\bm{\sigma} \in \partial B_R\backslash \Gamma_{\delta}\), si deduce direttamente \(R^2 - \abs*{\bm{x}}^2 \to 0, \abs*{\bm{\sigma} - \bm{x}} \geq \frac{\delta}{2}\)
Che permette di ottenere
\[
  \abs*{II} \leq \frac{R^2 - \abs*{\bm{x}}^2}{2\pi R} \int_{\partial B_R \backslash \Gamma_{\delta}} \frac{g(\bm{\sigma}) - g(\bm{\xi})}{\abs*{\bm{x}-\bm{\sigma}}}\, d\sigma \leq \frac{4 \max{\abs*{g}}}{\delta^2} (R^2 - \abs*{x}^2) \to 0
\]
Per cui anche in questo caso la (3.26) è l'unica soluzione del problema di Dirichlet.
\end{proof}
Una conseguenza immediata di questo teorema è che se \(u\) è una funzione armonica in un dominio, allora è anche una funzione di classe \(\mathcal{C}^{\infty}\) in quel dominio. Dunque ogni derivata di una funzione amonica è anche essa armonica. Inoltre è possibile controllare le derivate di ogni ordine di una funzione armonica in un punto \(\bm{p}\) tramite il massimo della funzione.
\begin{corollary}
  Siano \(u\) funzione armonica in \(\Omega \subseteq \mathbb{R}^n\) e \(B_R(\bm{p}) \subset \subset \Omega\). Allora si ha, per ogni \(j, k = 1, \ldots, n\)
  \begin{equation}
   \abs*{u_{x_j}(\bm{p})} \leq \frac{n}{R}\max_{\partial B_R(\bm{p})} \abs*{u}, \qquad \abs*{u_{x_j x_k}(\bm{p})} \leq \frac{(2n)^2}{R^2} \max_{\partial B_R(\bm{p})} \abs*{u} 
  \end{equation}
\end{corollary}
\begin{proof}
  Poiché \(u_{x_j} (\bm{p}) = \frac{n}{\omega_n R^n} \int_{B_R(\bm{p})} u_{x_j}(\bm{y}) \, d\bm{y} = \frac{n}{\omega_n R^n}\int_{\partial B_R(\bm{p})} u(\bm{\sigma}) \bm{\nu_j} \, d\sigma\)
Dal momento che \(\abs*{\partial B_R(\bm{p})} = \omega_n R^{n-1}\)
\begin{equation}
  \abs*{u_{x_j}(\bm{p})} \leq \frac{n}{\omega_n R^n} \int_{\partial B_R (\bm{p})} \abs*{u(\bm{\sigma})} \, d\sigma \leq \frac{n}{R} \max_{\partial B_R(\bm{p})}\abs*{u}
\end{equation}
Con la (3.33) si può (sostituendo \(u\) con \(u_{x_k}\) e \(\frac{R}{2}\) al posto di \(R\)) ottenere
\[
 \abs*{u_{x_k}(\bm{p})} \leq \frac{2n}{R} \max_{\partial B_{\frac{R}{2}} (\bm{p})} \abs*{u_{x_k}} 
\]
che, applicata \(\forall \bm{q} \in \partial B_{\frac{R}{2}}(\bm{p})\), restituisce
\[
  \abs*{u_{x_k}(\bm{q})} \leq \frac{2n}{R} \max_{\partial B_{\frac{R}{2}}(\bm{q})} \abs*{u}
\]
si deduce quindi che 
\[
  \abs*{u_{x_j}(\bm{p})} \leq \frac{2n}{R}\max_{\partial B_{\frac{R}{2}}(\bm{p})} \abs*{u_{x_k}}, \leq \frac{(2n)^2}{R^2} \max_{\partial B_R(\bm{p})} \abs*{u}  
\]
da cui \(\partial b_{\frac{R}{2}}(\bm{q}) \subset \partial B_R(\bm{p})\)
\end{proof}
\subsection{Soluzione fondamentale}
Due proprietà fondamentali che caratterizzano l'operatore di Laplace sono: \emph{invarianza per traslazioni e rotazioni dello spazio}. Nel caso \(u = u(\bm{x})\) sia una funzione armonica, la funzione \(v(\bm{x}) = u(\bm{x} - \bm{y})\) è anche essa armonica, per ogni \(\bm{y}\) fissato. Nel caso di rotazioni nello spazio, si utilizza una rotazione in \(\mathbb{R}^n\), rappresentata da una matrice ortogonale \(\bm{M}\), allora anche \(v(\bm{x}) = u(\bm{Mx})\) è armonica in \(\mathbb{R}^n\). 
La dimostrazione deriva, indicata con \(D^2 u\) la matrice Hessiana di \(u\), dalla possibilità di riscrivere il Laplaciano di \(u\) come
\[
  \Delta u = \Tr{D^2u} = \mbox{ traccia della Hessiana di }u 
\]
Dal momento che 
\[
  D^2v(\bm{x}) = \bm{M}^T D^2u(\bm{Mx})\bm{M}
\]
e la matrice \(\bm{M}\) è ortogonale, si ha 
\[
  \Delta v(\bm{x}) = \Tr[\bm{M}^T D^2u(\bm{Mx})\bm{M}] = \Tr{D^2u(\bm{Mx})} = \delta u(\bm{Mx}) = 0
\]
che conferma il fatto che \(v\) sia armonica. \\
La distanza di un punto dall'origine è una tipica espressione invariante per rotazioni nello spazio, ossia preso un raggio \(r = \abs*{\bm{x}}\), si cercano soluzioni che dipendano solo da \(r\), quindi \emph{soluzioni a simmetria radiale}.
Per fare questo si utilizza l'operatore di Laplace in coordinate sferiche (\(r, \psi, \theta\)):
\[
  \Delta = \underbrace{\frac{\partial^2}{\partial r^2} + \frac{2}{r} \frac{\partial}{\partial r}}_{\text{parte radiale}} + \frac{1}{r^2} \underbrace{\left\{ \frac{1}{(\sin\psi)^2} \frac{\partial^2}{\partial \theta^2} + \frac{\partial^2}{\partial \psi^2} + \cot{\psi \frac{\partial}{\partial \psi}}\right\}}_{\text{parte sferica (Laplace-Beltrami)}}
\]
che riduce l'equazione di Laplace per \(u = u(r)\) a 
\[
  \frac{\partial^2 u}{\partial r^2} + \frac{1}{r} \frac{\partial u}{\partial r} = 0
\]
da cui si ricava l'integrale generale (con \(C, C_1\) costanti arbitrarie)
\[
u(r) \frac{C}{r}+ C_1  
\]
Nel caso bidimensionale, per cui con coordinate polari, si ha 
\[
  \frac{\partial^2 u}{\partial r^2} + \frac{1}{r} \frac{\partial u}{\partial r} = 0
\]
che, integrata, restituisce
\[
  u(r) = C\log{r} + C_1
\]
Nel caso tridimensionale una scelta di \(C\) sarà \(\frac{1}{4\pi}\), mentre si due dimensioni sarà ottimale definre \(C = -\frac{1}{2\pi}\), mentre \(C_1\) sarà sempre nulla.
Si può definire allora una funzione \(\bm{\Phi}(\bm{x})\) come
\begin{equation}
  \bm{\Phi}(\bm{x}) = \begin{cases}
    -\frac{1}{2\pi} \log{\abs*{\bm{x}}} & n = 2 \\
    \frac{1}{4\pi \abs*{\bm{x}}} & n = 3
  \end{cases}
\end{equation}
che è la \emph{soluzione fondamentale} per l'operatore di Laplace. \(\bm{\Phi}\) è definita per \(\bm{x} \not = \bm{0}\) e la scelta della costante \(C\) permette di avere 
\[
  \Delta \bm{\Phi} = -\delta_n \qquad \mbox{in }\mathbb{R}^n
\]
con \(\delta_n\) distribuzione di Dirac nell'origine. \\
In termini fisici, la funzione \(\bm{\Phi}\) è di notevole importanza. Infatti in tre dimensioni rappresenta il potenziale elettrostatico generato da una carica nell'origine che si annulla all'infinito, mentre in due dimensioni rappresenta il potenziale di una carica con densità totale unitaria distribuita lungo un'asse. \\
In caso non si trovi nell'origine si ha 
\[
  \Delta_{\bm{x}} \bm{\Phi}(\bm{x} - \bm{y}) = -\delta_n (\bm{x} - \bm{y})
\]
Supponendo che la densità di carica posta in un sottoinsieme compatto di \(\mathbb{R}^3\) sia \((4\pi)^{-1} f(\bm{x})\). Allora il potenziale sarà \(\bm{\Phi}(\bm{x} - \bm{y}) f(\bm{y}) \, d\bm{y}\), che è generato in \(\bm{x}\) da una carica presente in una regione di volume \(d\bm{y}\). La somma di tutte le cariche presenti nella regione in esame permette di ottenere
\begin{equation}
  \mathcal{N}_f (\bm{x}) = \int_{\mathbb{R}^3} \bm{\Phi} (\bm{x} - \bm{y}) \, d\bm{y} = \frac{1}{4\pi} \int_{\mathbb{R}^3} \delta_3 \frac{f(\bm{y})}{\abs*{\bm{x}-\bm{y}}}\, d\bm{y}
\end{equation}
definito come \emph{potenziale Newtoniano} di \(f\). Si ha allora
\begin{equation}
  \Delta \mathcal{N}_f (\bm{x}) = \int_{\mathbb{R}^3} \Delta_{\bm{x}}\bm{\Phi} (\bm{x} - \bm{y}) \, d\bm{y} = \frac{1}{4\pi} \int_{\mathbb{R}^3} \delta_3 (\bm{x}- \bm{y}) f(\bm{y}) \, d\bm{y} = -f(\bm{x})
\end{equation}
Si può enunciare un comodo teorema per verificare la veridicità della (3.33):
\begin{theorem}
  Sia \(f \in \mathcal{C}^2 (\mathbb{R}^3)\) a supporto compatto\footnote{Il supporto di una funzione è la \emph{chiusura dell'insieme} dove essa non è nulla.}. Allora \(\mathcal{N}_f \in \mathcal{C}^2 (\mathbb{R}^3)\) ed è unica soluzione in \(\mathbb{R}^3\) dell'equazione di Poisson
  \[
    \Delta u = -f
  \]
  che si annulla \(\to \infty\)
\end{theorem}
\subsection{Funzione di Green} 
In domini limitati, ogni formula di rappresentazione tiene conto dei valori di \(u\) e della sua derivata normale al bordo. Si consideri la soluzione fondamentale
\[
  \bm{\Phi} (\bm{x}-\bm{y}) = \frac{1}{4\pi r_{\bm{xy}}} \qquad r_{\bm{xy}} = \abs*{\bm{x} - \bm{y}}
\]
Con \(\bm{x} \in \Omega\) fissato, il simbolo \(\bm{\Phi}(\bm{x} - \bm{\cdot})\) indica una funzione \(\bm{y} \to \bm{\Phi}(\bm{x}-\bm{y})\). La derivata normale al bordo di questa funzione si può scrivere come 
\[
\partial_{\bm{\nu}}\bm{\Phi}(\bm{x} - \bm{\sigma}) = \nabla_{\bm{y}}\bm{\Phi} (\bm{x}-\bm{\sigma}) \cdot \bm{\nu_{\sigma}}
\]
\begin{theorem}
  Siano \(\Omega \subset \mathbb{R}^3\) un dominio limitato e regolare e \(u \in \mathcal{C}^2(\overline{\Omega})\). Si ha 
  \begin{equation}
    \begin{array}{lcl}
      u(\bm{x}) & = & -\int_{\Omega} \bm{\Phi} (\bm{x} - \bm{y}) \Delta u(\bm{y}) \, d\bm{y} + \\
      & & \\
      &  & + \int_{\partial \Omega} \bm{\Phi} (\bm{x} - \bm{\sigma}) \partial_{\bm{\nu}}u(\bm{\sigma}) \, d\sigma - \int_{\partial\Omega} \partial_{\bm{\nu}}\bm{\Phi}(\bm{x} - \bm{\sigma}) u(\bm{\sigma}) \, d\sigma
    \end{array}
  \end{equation}
Il primo integrale è il potenziale Newtoniano di \(-\Delta u\) in \(\Omega\), mentre i due integrali di superficie si chiamano, rispettivamente, \emph{potenziale di strato semplice con densità} \(\partial_{\bm{\nu}}\) e \emph{doppio strato con momento} \(u\). 
\end{theorem}
\begin{proof}
  Per la dimostrazione si applicherà l'identità di Green \eqref{Identità di Green}
  \begin{equation}
    \int_{\Omega} (v\Delta u - u\Delta v) \, d\bm{x} = \int_{\partial \Omega} (v \partial_{\bm{\nu}}u - u\partial_{\bm{\nu}}v) \, d\sigma 
  \end{equation}
  a \(u\) e \(\bm{\Phi}(\bm{x}-\bm{\cdot})\). Tuttavia \(\bm{\Phi}(\bm{x}-\bm{\cdot})\) ha una singolarità in \(\bm{x}\) che non permette di utilizzare direttamente la (3.35). Considerata una sfera di raggio \(\epsilon\) molto piccolo \(B_{\epsilon}(\bm{x})\) e definendo un insieme \(\Omega_{\epsilon} = \Omega \backslash \overline{B}_{\epsilon}(\bm{x})\). All'interno di questo insieme \(\bm{\Phi}(\bm{x} - \bm{\cdot})\) è una funzione regolare e armonica. Dal momento che 
  \[
    \partial\Omega_{\epsilon} = \partial\Omega \cup \partial B_{\epsilon}(\bm{x})
  \]
  e \(\Delta_{\bm{y}}\bm{\Phi}(\bm{x} - \bm{y}) = 0\), si ha
  \begin{equation}
    \begin{array}{l}
      \int_{\Omega_{\epsilon}} \frac{1}{r_{\bm{xy}}} \Delta u \, d\bm{y} = \int_{\partial B_{\epsilon}} \left(\frac{1}{r_{\bm{xy}}} \frac{\partial u}{\partial \bm{\nu}} - u \frac{\partial}{\partial \bm{\nu}} \frac{1}{r_{\bm{x\sigma}}}\right) \, d\sigma = \\
      \\
    = \int_{\partial \Omega} (\ldots) \, d\sigma + \int_{\partial B_{\epsilon}(\bm{x})} \frac{1}{r_{\bm{xy}}} \frac{\partial u}{\partial \bm{\nu}} \, d\sigma - \int_{\partial B_{\epsilon}(\bm{x})} u\frac{\partial}{\partial \bm{\nu}} \frac{1}{r_{\bm{xy}}} \, d\sigma
    \end{array}
  \end{equation}
Con \(\epsilon\) tendente a zero i tre integrali diventano
\begin{equation}
  \int_{\Omega_{\epsilon}} \frac{1}{r_{\bm{xy}}} \Delta u \, d\bm{y} \to \int_{\Omega} \frac{1}{r_{\bm{xy}}} \Delta u \, d\bm{y} \qquad \mbox{per }\epsilon \to 0
\end{equation}
poiché \(\frac{1}{r_{\bm{xy}}}\) è positiva e integrabile in \(\Omega\) e \(\Delta u \in \mathcal{C}(\overline{\Omega})\). \\
Su \(\partial B_{\epsilon}(\bm{x})\) si ha \(r_{\bm{xy}} = \epsilon\) e \(\abs*{\partial_{\bm{\nu}}} \leq M\), e sapendo che \(\abs*{\nabla u}\) è limitato, si ottiene 
\begin{equation}
\left|\int_{\partial B_{\epsilon}(\bm{x})}\frac{1}{r_{\bm{x\sigma}}} \partial_{\bm{\nu}}u \, d\sigma\right| \leq 4\pi \epsilon M \to 0 \qquad \mbox{per } \epsilon \to 0
\end{equation}
La questione più delicata riguarda l'ultimo integrale
\[
  \int_{\partial B_{\epsilon}(\bm{x})} u\frac{\partial}{\partial \bm{\nu}} \frac{1}{r_{\bm{xy}}} \, d\sigma
\]
Al bordo della sfera \(B_{\epsilon}(\bm{x})\), il versore normale esterno a \(\Omega_{\epsilon}\) nel punto \(\bm{\sigma}\) è \(\bm{\nu_{\sigma}} = \frac{\bm{x}-\bm{\sigma}}{\epsilon}\), per cui
\[
  \frac{\partial}{\partial \bm{\nu}} \frac{1}{r_{\bm{x\sigma}}} = \nabla_{\bm{y}}\frac{1}{r_{\bm{x\sigma}}} \cdot \bm{\nu_{\sigma}} = \frac{\bm{x} - \bm{\sigma}}{\epsilon^3} \frac{\bm{x} - \bm{\sigma}}{\epsilon} = \frac{1}{\epsilon^2}
\]
Dalla quale segue
\begin{equation}
  \int_{\partial B_{\epsilon}(\bm{x})} u \frac{\partial}{\partial \bm{\nu}} \frac{1}{r_{\bm{x\sigma}}} \, d\sigma = \frac{1}{\epsilon^2} \int_{\partial B_{\epsilon}(\bm{x})} u \, d\sigma \to 4\pi u(\bm{x})
\end{equation}
Che, assieme agli altri termini permette di ottenere la (3.34)
\end{proof}
La funzione \(\bm{\Phi}\) è la soluzione fondamentale di \(\Delta\) in tutto \(\mathbb{R}^n\). Si può immaginare una funzione \(G(\bm{x,y})\) come la rappresentazione del potenziale generato da una carica posta in \(\bm{x}\) dentro una regione formata da un conduttore messo a terra al bordo della regione. Ossia, fissato \(\bm{x}\in \Omega\)
si ha:
\[
  \begin{array}{ll}
    \Delta_{\bm{y}} G(\bm{x,y}) = -\delta_n (\bm{x} - \bm{y}) & \mbox{in } \Omega \\
    G(\bm{x, \sigma})= 0 & \sigma \in \partial \Omega
  \end{array}
\]
Vale allora la formula 
\[
  G(\bm{x,y}) = \bm{\Phi}(\bm{x} - \bm{y}) - \phi(\bm{x,y})
\]
con \(\phi\), come funzione di \(\bm{y}\), per \(\bm{x}\) fissato, soluzione del problema di Dirichlet
\begin{equation}
  \begin{cases}
    \Delta_{\bm{y}} \phi(\bm{x,y}) = 0 & \mbox{in } \Omega \\
    \phi(\bm{x, \sigma}) = \bm{\Phi}(\bm{x}-\bm{\sigma}) & \mbox{su } \partial \Omega
  \end{cases}
\end{equation} 
Due proprietà importanti della funzione di Green sono:
\begin{itemize}
  \item[a)] Positività: \(G(\bm{x,y}) > 0\), per ogni \(bm{x,y} \in \Omega\) e \(G(\bm{x,y}) \to +\infty\), se \(\bm{x} - \bm{y} \to \bm{0}\)
  \item[b)] Simmetria: \(G(\bm{x,y})\) = \(G(\bm{y,x})\)  
\end{itemize}
Le funzioni di Green esistono se il problema di Dirichlet è risolvibile in un determinato dominio. Se la funzione di Green esiste, in caso di domini specifici si possono utilizzare formule particolari, grazie a una tecnica nota come \emph{metodo delle immagini}. In questo metodo, considerata una funzione \(\phi(\bm{x, \cdot})\) pari al potenziale generato da una carica in \(\bm{x}\). 
\begin{itemize}
  \item La funzione di Green per il semispazio superiore in \(\mathbb{R}^3\). 
\end{itemize}
Definito \(\mathbb{R}^3_+\) il semispazio
  \[
    \mathbb{R}^3_+ = \{(x_1, x_2, x_3): x_3 > 0\}
  \] 
  Sia \(\bm{x} = (x_1, x_2, x_3)\) e \(\bm{x}^+ = (x_1, x_2 -x_3)\) su \(y_3 = 0\) si hanno
  \[
    \abs*{\bm{x}^* - \bm{y}} = \abs*{\bm{x} - \bm{y}}
  \]  
Se \(\bm{x} \in \mathbb{R}^3_+\), allora \(\bm{x}^*\) appartiene al complementare di \(\mathbb{R}^3_+\) e la funzione 
\[
  \phi(\bm{x, y}) = \bm{\Phi} (\bm{x}^* - \bm{y}) = \frac{1}{4\pi\abs*{bm{x}^* - \bm{x}}} 
\]
risulta armonica in \(\mathbb{R}^3_+\) con \(\phi(\bm{x, y}) = \bm{\Phi} (\bm{x}^* - \bm{y})\) sul piano \(y_3 = 0\). Dunque 
\begin{equation}
  G(\bm{x, y}) = \frac{1}{4\pi\abs*{bm{x} - \bm{x}}} = \frac{1}{4\pi\abs*{bm{x}^* - \bm{x}}} 
\end{equation}
è la funzione di Green per il semispazio superiore di \(\mathbb{R}^3_+\)
\begin{itemize}
  \item La funzione di Green per la sfera.
\end{itemize}
Sia \(\Omega = B_R = B_R(\bm{0}) \subset \mathbb{R}^3\). Siano 
\[
  \phi(\bm{x, y}) = \frac{q}{4\pi \abs*{x}^* - \bm{y}}
\]
con \(\bm{x}\) fissato all'interno di \(B_R\). Per determinare \(\bm{x}\) nel complementare di \(B_R\), sapendo che \(q\) si può riscrivere come 
\begin{equation}
  \frac{q}{4\pi\abs*{\bm{x}^* - \bm{y}}} = \frac{1}{4\pi \abs*{\bm{x} - \bm{y}}}
\end{equation}
quando \(\abs*{\bm{y}} = R\). Dalla (3.42) si ha 
\begin{equation}
  \abs*{\bm{x}^* - \bm{y}}^2 = q^2 \abs*{\bm{x} - \bm{y}}^2
\end{equation}
che per \(\abs*{\bm{y}} = R\) darà 
\[
  \abs*{\bm{x}^*}^2 + 2\bm{x}^*\cdot\bm{y} + R^2 = q^2(\abs*{\bm{x}}^2 - 2\bm{x} \cdot \bm{y} + R^2)
\]
che si riordina come
\[
  \abs*{\bm{x}^*}^2 - R^2 - q^2(R^2 + \abs*{\bm{x}}^2) = 2\bm{y} \cdot (\bm{x}^* - q^2\bm{x})
\]
Dal momento che il primo membro è indipendente da \(\bm{y}\), deve essere \(\bm{x}^* = q^2\bm{y}\) e quindi
\[
  q^4\abs*{\bm{x}}^4 - R^2 - q^2(R^2 + \abs*{\bm{x}}^2) = 0
\]
da cui si ricava \(q =\frac{R}{\abs*{\bm{x}}}\). Per \(\bm{x} \not = \bm{0}\)
\begin{equation}
  G(\bm{x, y}) = \frac{1}{4\pi} \left[ \frac{1}{\abs*{\bm{x} - \bm{y}}} - \frac{R}{\abs*{\bm{x}} \abs{\bm{x}^* - \bm{y}}}\right] = \bm{\phi}(\bm{x} - \bm{y}) - \bm{\phi}\left(\frac{\abs*{\bm{x}}}{R} (\bm{x}^* - \bm{y})\right) 
\end{equation}
dove \(\bm{x}^* = \frac{R^2}{\abs*{\bm{x}}^2 }\bm{x}, \bm{x} \not = \bm{0}\). Poiché
\[
  \abs*{\bm{x}^* - \bm{y}} = \abs*{\bm{x}}^{-1} \left( R^4 - 2R^2\bm{x} \cdot \bm{y} + \abs*{\bm{y}}^2 \abs*{\bm{x}}^2\right)^{\frac{1}{2}}
\]
e con \(\bm{x} \to \bm{0}\) si ha
\[
  \phi(\bm{x,y}) = \frac{1}{4\pi}\frac{R}{\abs*{\bm{x}} \abs*{\bm{x}^* - \bm{y}}} \to \frac{1}{4\pi R}
\]
da cui la funzione di Green:
\begin{equation}
  G(\bm{0, y}) = \frac{1}{4\pi} \left[\frac{1}{\abs*{\bm{y}}} - \frac{1}{R}\right]
\end{equation}
Dal teorema (3.8) si evince che ogni funzione regolare \(u\) può essere riscritta come somma di un potenziale di volume con densità \(-\Delta u\), di un potenziale di strato demplice con densità \(\partial_{\bm{\nu}}\) e di un potenziale di doppio strato di momento \(u\). 
Sia \(u\) la soluzione del problema di Dirichlet 
\begin{equation}
  \begin{cases}
    \Delta u = f & \mbox{in }\Omega \\
    u = g & \mbox{su } \partial\Omega
  \end{cases}
\end{equation}
Inoltre, per \(\bm{x} \in \Omega\) fissato, si ha
\begin{equation}
  \begin{array}{c}
    u(\bm{x}) = - \int_{\Omega} \bm{\Phi}(\bm{x} - \bm{y})f(\bm{y}) \, d\bm{y} + \\
    + \int_{\partial\Omega} \bm{\Phi}(\bm{x} - \bm{\sigma})\partial_{\bm{\nu}}u(\bm{\sigma}) \, d\sigma - \int_{\partial\Omega} g(\bm{\sigma}) \partial_{\bm{\nu}} \bm{\Phi}(\bm{x} -\bm{\sigma}) \, d\sigma
  \end{array}
\end{equation}
Questa formula di rappresentazione esprime \(u\) in termini dei dati \(f \mbox{ e }g\), ma introduce anche \(\partial_{\bm{\nu})}\), sulla quale non si hanno informazioni. Ci si può liberare di tale termine considerando la funzione di Green \(G(\bm{x, y}) = \bm{\Phi} (\bm{x} - \bm{y}) - \phi(\bm{x,y})\) in \(\Omega\). Dal momento che \(\phi(\bm{x,\cdot})\) è armonica in \(\Omega\), grazie alla (3.35) applicata a \(u \mbox{ e }\phi(\bm{x, \cdot})\), si ha
\begin{equation}
  \begin{array}{c}
    0 = - \int_{\Omega} \phi(\bm{x, y})f(\bm{y}) \, d\bm{y} + \\
    + \int_{\partial\Omega} \phi(\bm{x, \sigma})\partial_{\bm{\nu}}u(\bm{\sigma}) \, d\sigma - \int_{\partial\Omega} g(\bm{\sigma}) \partial_{\bm{\nu}} \bm{\Phi}(\bm{x} -\bm{\sigma}) \, d\sigma
  \end{array}
\end{equation}
Dalla somma di (3.47) e (3.48), sapendo che \(\phi(\bm{x}, \sigma)\) su tutto \(\partial\Omega\) si ottiene il seguente teorema
\begin{theorem}
  Sia \(\Omega\) un dominio regolare e \(u\) una funzione regolare del problema (3.46). Allora per ogni \(\bm{x} \in \Omega\):
  \begin{equation}
    u(\bm{x}) = -\int_{\Omega} f(\bm{y}) G(\bm{x,y}) \, d\bm{y} - \int_{\partial\Omega} g(\bm{\sigma}) \partial_{\bm{\nu}} G(\bm{x, \sigma}) \, d\sigma
  \end{equation}
\end{theorem}
Pertanto, la soluzione del problema di Dirichlet, può essere riscritta come somma di due potenziali di Green, che permettono di utilizzare soltanto i dati del problema. Se \(u\) è armonica, allora
\begin{equation}
  u(\bm{x}) = -\int_{\partial\Omega} g(\bm{\sigma}) \partial_{\bm{\nu}} G(\bm{x, \sigma}) \, d\sigma
\end{equation}
da cui si deduce che
\[
  -\partial_{\bm{\nu}} G(\bm{x, \sigma}) \, d\sigma
\] 
rappresenta la misura armonica in \(\Omega\). 
La funzione 
\[
  P(\bm{x, \sigma}) = -\partial_{\bm{\nu}} G(\bm{x, \sigma})
\]
è definita \emph{nucleo di Poisson}. Poiché \(G(\bm{\cdot, x}) > 0\) in \(\Omega\) e si annulla su \(\Omega\), \(P\) è nonnegativo. Inoltre la formula 
\[
  u(\bm{x}) = -\int_{\Omega} f(\bm{y}) G(\bm{x,y}) \, d\bm{y}
\]
che dà la soluzione dell'equazione di Poisson \(\Delta u = f\) in \(\Omega\), che si annulla su \(\partial\Omega\). Si ha inoltre dalla positività di \(G\) che 
\[
 f \geq 0 \mbox{ in }\Omega \mbox{ implica }u \leq 0 \mbox{ in } \Omega 
\]
che è un altro modo di definire il principio di massimo.
\begin{itemize}
  \item Nucleo di Poisson e formula di Poisson per la sfera.
\end{itemize}
Dalla (3.44) si può calcolare il nucleo di Poisson per la sfera \(B = B_R(\bm{0} \subset \mathbb{R}^3)\). Si ha allora (poiché \(\bm{x}^* = \frac{R^2}{\abs*{\bm{x}}^2}\bm{x}\), se \(\bm{x} \not = \bm{0}\))
\[
\nabla_{\bm{y}}\left[ \frac{1}{\abs*{\bm{x} - \bm{y}}} - \frac{R}{\abs*{\bm{x}} \abs*{\bm{x}^* - \bm{y}}}\right] = \frac{\bm{x} - \bm{y}}{\abs*{\bm{x} -\bm{y}}^3} - \frac{R}{\abs*{\bm{x}}} \frac{\bm{x}^* - \bm{y}}{\abs*{\bm{x}^* - \bm{y}}^3}
\]
Se \(\sigma \in \partial B_R\), dalla (3.43) si ha \(\abs*{\bm{x}^* - \bm{\sigma}} = \frac{R}{\abs*{x}}\abs*{\bm{x}- \bm{\sigma}}\), per cui 
\[
  \nabla_{\bm{y}} G(\bm{x, \sigma}) = \frac{1}{4\pi} \left[ \frac{\bm{x} - \bm{\sigma}}{\abs*{\bm{x} - \bm{\sigma}}^3} - \frac{\abs*{\bm{x}}^2}{R^2} \frac{\bm{x}^* - \sigma}{\abs*{\bm{x} - \bm{\sigma}}^3} \right] = \frac{-\bm{\sigma}}{4\pi \abs*{\bm{x} - \bm{\sigma}}^3} \left[1 - \frac{\abs*{\bm{x}}^2}{R^2}\right]
\]
La normale esterna su \(\partial B_R\) è \(\bm{\nu}_{\Omega} = \frac{\bm{\sigma}}{R}\), che restituisce
\[
  P(\bm{x, \sigma}) = -\partial_{\bm{\nu}}G(\bm{x, \sigma}) = -\nabla_{\bm{y}}G(\bm{x, \sigma}) \cdot \bm{\nu}_{\sigma} = \frac{R^2 - \abs*{\bm{x}}^2}{4\pi R} \frac{1}{\abs*{\bm{x} - \bm{\sigma}}^3}
\]
Per cui si ritrova la formula di Poisson per \(n = 3\)
\begin{equation}
  u(\bm{x}) = \frac{R^2 - \abs*{\bm{x}}^2}{4\pi R} \int_{\partial B_R(\bm{0})} \frac{g(\bm{\sigma})}{\abs*{\bm{x} - \bm{\sigma}}^3} \, d\sigma
\end{equation}
per l'unica soluzione del problema di Dirichlet \(\Delta u = 0\) in \(B_R\) e \(u = g\) su \(\partial B_R\)
\section{Leggi di conservazioni scalari ed equazioni del prim'ordine} 
\subsection{Leggi di conservazione}
Questa sezione si occupa di equazioni a derivate parziali del primo ordine tipo
\begin{equation}
  u_t + q(u)_x = 0, \qquad x \in \mathbb{R}, t > 0
\end{equation}
In generale, \(u = u(x,t)\) indica la densità o la concentrazione di una quantità fisica \(Q\) e \(q(u)\) indica il flusso. La (4.1) rappresenta la \emph{legge di conservazione} di \(u\). Sia \([x_1, x_2]\) un intervallo arbitrario, allora 
\[
  \int_{x_1}^{x_2} u(x,t) \, dx
\]
raèèresenta la quantità presente tra \(x_1 \mbox{ e }x_2\) al tempo \(t\). Tale legge afferma che, in assenza di sorgenti esterne, il tasso di variazione di \(Q\) all'interno di \([x_1, x_2]\) è determinato dal flusso netto attraverso gli estremi dell'intervallo. Se è modellato da da una funzione \(q = q(u)\), la legge di conservazione si esprime come
\begin{equation}
  \frac{d}{dt} \int_{x_1}^{x_2} u(x,t) \, dx = -q(u(x_2, t)) + q(u(x_1, t))
\end{equation} 
dove si ha \(q > 0\) (risp. \(< 0\)) se il flusso avviene in direzione positiva (risp. negativa) dell'asse \(x\). In ipotesi di regolarità di \(u\) e \(q\), la (4.2) si può riscrivere nella forma 
\[
  \int_{x_1}^{x_2} [u(x,t) + q(u(x,t))_x] \, dx = 0 
\]
che implica la (4.1), dall'arbitrarietà dell'intervallo \([x_1, x_2]\). A questo punto è necessario stabilire una \emph{legge costitutiva} per \(q\). Un esempio può essere una legge lineare in \(u\) in cui la funzione flusso è proporzionale a \(u\)
\[
  q(u) = vu
\]
dove \(v\) è una costante. Si tratta di un modello di convezione o trasporto, con \(v\bm{i}\) che rappresenta la velocità di deriva. 
La (4.1) sta alla base di molti modelli unidimensionali e spesso è utilizzata per descrivere la propagazione delle onde d'urto (\emph{shock waves}). In questo ultimo caso sono presenti discontinuità a salto, per cui è necessario interpretare la (4.1) in modo da avere come funzione una funzione discontinua. \\
Un tipico problema è quello \emph{ai valori iniziali}:
\begin{equation}
  \begin{cases}
    u_t + q(u)_x = 0 \\
    u(x,0) = g(x)
  \end{cases}
  \qquad x \in \mathbb{R}
\end{equation}
La legge di conservazione è un caso particolare di equazione quasilineare del primo ordine del tipo:
\[
  a(x,y,u)u_x + b(x,y,z)u_z = c(x,y,u)
\]
\subsection{Equazione lineare del trasporto}
Nel caso dell'inquinante dentro un corso d'acqua, si ricava l'equazione
\[
  c_t = Dc_{xx} -vc_x
\]
dove \(c\) è la concentrazione della sostanza e \(v\bm{i}\) la velocità di trasporto della corrente. Nel caso in cui \(D = 0\) si riduce l'equazione a quella di puro trasporto senza diffusione:
\begin{equation}
  c_t + vc_x = 0
\end{equation}
che, introdotto il vettore
\[
  \bm{v} = v\bm{i} + \bm{j}
\]
si può riscrivere come 
\[
  vc_x + c_t = \nabla c \cdot \bm{v} = 0
\]
che evidenzia la perpendicolarità tra il gradiente di \(c\) e il vettore \(\bm{v}\). Inoltre \(\nabla c\) è ortogonale alle linee di livello di \(c\), lungo le quali \(c\) è costante. Allora le linee di livello di \(c\) sono parallele al vettore \(\bm{v}\) descritte dall'equazione:
\[
x=vt+x_0  
\]
Tali rette sono definite \emph{caratteristiche}. Conoscendo il profilo iniziale della concentrazione \(c\) si cerca di studiarne l'evoluzione
\begin{equation}
c(x, 0) = g(x)  
\end{equation}
Posto un punto generico \((\overline{x}, \overline{t}, \overline{t}>0)\), il calcolo della soluzione risulta semplice: sia \(x = vt + x_0\) l'equazione della caratteristica che passa per tale punto. Seguendo la retta dal punto scelto fino al punto in cui essa interseca l'asse \(x\) (\(x_0, 0\)), poiché \(c\) è costante lungo tutta la caratteristica e \(x_0 = \overline{x} - v\overline{t}\), si avrà 
\[
  c(\overline{x}, \overline{t}) = g(x_0) = g(\overline{x} -v\overline{t})  
\]
Se \(g \in \mathcal{C}^1(\mathbb{R})\), la soluzione del problema di Cauchy (4.4), la (4.5) è data da 
\begin{equation}
  c(x,t) = g(x -vt)
\end{equation}
La (4.6) è l'equazione di una onda progressiva che si muove con velocità \(v\) in direzione positiva sull'asse \(x\). Si immagini la presenza, all'interno del canale, di una sorgente (o pozzo) di una sostanza inquinante di intensità \(f = f(x,t)\). La funzione \(f\) ha dimensione concentrazione per tempo. Al posto della (4.2) si ha 
\[
  \frac{d}{dt}\int_{x_1}^{x_2} c(x,t) \, dx = -q(c(x_2,t)) + q(c(x_1, t)) + \int_{x_1}^{x_2}f(x,t) \, dx
\] 
che permette di ottenere il modello 
\begin{equation}
  c_t + vc_x = f(x,t)
\end{equation}
con condizione iniziale 
\begin{equation}
  c(x, 0) = g(x)
\end{equation}
Come sopra, il calcolo della soluzione \(u\) in un generico punto \((\overline{x}, \overline{t})\) non presenta particolari difficoltà. Sia \(x = x_0 + vt\) l'equazione della caratteristica passante per \((\overline{x}, \overbrace{t})\), il calcolo di \(u\) lungo tale retta si attua ponendo \(w(t) = c(x_0 + vt)\). Dalla (4.7) si può osservare come \(w\) sia soluzione dell'equazione differenziale ordinaria 
\[
\dot{w}(t) = vc_x(x_0 + vt, t) + c_t(x_0 + vt, t) = f(x_0 + vt, t) 
\]
con condizione iniziale 
\[
  w(0) = g(x_0)
\]
che integrata tra \([0, \overline{t}]\) permette di trovare
\[
  w(\overline{t}) = g(x_0) + \int_0^{\overline{t}} f(x_0 +vs,s) \, ds  
\]
Sapendo che \(x_0 = \overline{x} - v\overline{t}\), si ha 
\begin{equation}
  c(\overline{x}, \overline{t}) = w(\overline{t}) = g(\overline{x - v\overline{t}}) + \int_0^{\overline{t}} f(\overline{x} - v(\overline{t} -s), s) \, ds
\end{equation}
E, nel caso di \(g \mbox{ e } f\) sufficientemente regolari, la (4.9) è la formula della soluzione.
\begin{theorem}
  Siano \(g \in \mathcal{C}^1 (\mathbb{R})\) e \(f, f_x \in \mathcal{C}(\mathbb{R} \times [0, +\infty))\). La soluzione di 
  \[
    \begin{cases}
      c_t + vc_x = f(x,t) & x \in \mathbb{R}, t > 0 \\
      C(x, 0) = g(x) & x \in \mathbb{R}
    \end{cases}
\]
appartiene a \(\mathcal{C}^1(\mathbb{R} \times [0, +\infty))\) e si ottiene dalla formula
\begin{equation}
  c(x,t) = g(x -vt) + \int_0^t f(x-v(t-s), s) \, ds
\end{equation}
\end{theorem}
Nel caso in cui la sostanza inquinante dovesse estinguersi seguendo un tasso
\[
  r(x, t) = -\gamma c(x,t) \qquad \gamma > 0
\]
Nel caso in cui \(D = 0\), ossia in assenza di diffusione, il modello da utilizzare è 
\[
c_t + vc_x = -\gamma c  
\]
con condizione iniziale
\[
  c(x, 0) = g(x)
\]
Posto 
\begin{equation}
  u(x,t) = c(x,t)e^{\frac{\gamma}{v} x}
\end{equation}
si ha allora
\[
u_x = \left(c_x + \frac{\gamma}{v} c\right)e^{\frac{\gamma}{v} x} \mbox{ e } u_t = c_t e^{\frac{\gamma}{v} x}
\]
da cui si ottiene l'equazione per \(u\) 
\[
  u_t + v u_x = 0
\]
con la condizione iniziale
\[
  u(x, 0) = g(x)e^{\frac{\gamma}{v} x}
\] 
Dal teorema (4.1) si ha 
\[
  u(x,t) = g(x-vt)e^{\frac{\gamma}{v}(x-vt)}
\]
e dalla (4.11):
\[
  c(x,t) = g(x-vt) e^{\gamma t}
\]
a rappresentare una onda progressiva smorzata. \\
Una sorgente inquinante posta in \(x = 0\) si muoverà all'interno del canale, con l'assunzione che la concentrazione \(\beta > 0\) rimanga costante. Grazie alla funzione di Heaviside 
\[
  \mathcal{H}(t) =
\begin{cases}
1 & t\geq 0 \\
0 & t < 0
\end{cases}  
\]
con condizione al bordo
\[
c(0, t) = \beta\mathcal{H}(t) 
\]
dove \(\mathcal{H}\) è adimensionale e la condizione iniziale pari a
\[
c(x,0) = 0 \qquad \mbox{per }x>0
\]
Posto \(u(x,t) = c(x,t)e^{\frac{\gamma}{v} x}\), che è soluzione di \(u_t + vu_x = 0\), con le condizioni:
\begin{eqnarray*}
  u(x,0) = c(x,0)e^{\frac{\gamma}{v} x} = 0 & x > 0 \\
  u(0,t) = c(0,t) = \beta\mathcal{H}(t) & t \in \mathcal{R}
\end{eqnarray*}
Poiché \(u\) è costante lungo le rette caratteristiche, si ha una soluzione del tipo
\begin{equation}
  u(x,t) = u_0 (x-vt)
\end{equation}
con \(u_0\) da determinarsi utilizzando sia le condizioni al bordo che quelle iniziali. \\
Per trovare il valore di \(u\) all'interno di \(0 < x < vt\), si può notare come le caratteristiche uscenti da un punto $(0,t)$ sull'asse temporale trasportano il dato \(\beta\mathcal{H}(t)\). Si ha allora (posto \(s = -vt\))
\[
  u_0(s) = \beta\mathcal{H}\left(-\frac{s}{v}\right)  
\]
e dalla (4.12)si ottiene 
\[
  u(x,t) = \beta\mathcal{H}\left(t - \frac{x}{v}\right)
\]
che permette di ottenere la soluzione anche nel settore
\[
x > vt \qquad t > 0  
\]
Dal momento che le caratteristiche uscenti dall'asse \(x\) trasportano dati nulli, si deduce che \(u = c = 0\), per cui l'inquinante non ha ancora raggiunto \(x\) al tempo \(t\), se \(x > vt\). 
Dalla (4.11) si ha inoltre
\(
  c(x, t) = \beta\mathcal{H}\left(t - \frac{x}{v}\right)e^{\frac{\gamma}{v} x}
\)
che presenta in \((0,0)\) una discontinuità che prosegue lungo la caratteristica \(x = vt\). \\
Le caratteristiche \(x = vt\) operano nel quadrante \(x > 0, t > 0\). Inoltre, conoscendo il segno di \(v\) è possibile determinare la direzione in cui vengono trasportati i dati. In questo caso, l'aumento del tempo \(t\) permette che i dati vengano trasportati verso l'interno del quadrante (si parla di caratteristiche \emph{inflow}). Più in generale, per una equazione del tipo 
\[
  u_t + au_x = f(x,t)
\]
all'interno del quadrante \(x>0, t>0\), nel caso di \(a\) non nulla e costante. Le caratteristiche sono definite
\(x -at = \mbox{ costante}\).
Nel caso di \(a < 0\) le linee caratteristiche avranno un duplice comportamento, quelle che partono dall'asse \(x\) saranno entranti nel dominio (inflow), mentre quelle uscenti dall'asse \(t\) saranno dirette all'esterno del dominio (outflow). In entrambi i casi citati i dati iniziali sono sufficienti a determinare la soluzione, per cui non è necessario assegnare il valore su \(x = 0, t > 0\). \\
Sia ora un problema nella striscia \(x \in [0, R], t > 0\), in cui è necessario assegnare anche i sseguenti dati 
\[
\begin{cases}
  u(0,t) = h_0(t) & \mbox{se } a > 0 \\
  u(R,t) = h_R(t) & \mbox{se } a < 0
\end{cases}  
\]
che risulta ben posto, dal momento che la soluzione si può determinare univocamente in ogni punto della striscia dai valori lungo le caratteristiche. Per garantire la stabilità della soluzione rispetto ai dati si utilizza il seguente calcolo (siano \(a > 0\) e \(u\) soluzione del problema):
\begin{equation}
  \begin{cases}
    u_t +au_x = 0 & 0 < x < R, t > 0 \\
    u(0, t) = h(t) & t > 0 \\
    u(x, 0) = g(x) & 0 < x < R
  \end{cases}
\end{equation}
Che, moltiplicato tutto per \(u\), diventa
\[
  uu_t + auu_x = \frac{1}{2} \frac{d}{dt}u^2 + \frac{a}{2}\frac{d}{dx}u^2 = 0
\]
Integrando rispetto ad \(x\) nell'intervallo \((0, R)\) si ha
\[
\frac{d}{dr} \int_0^R u^2(x,t) \, dx + a[u^2(R,t) - u^2(0,t)] = 0  
\]
Grazie al dato \(u(0,t) = h(t)\) e la positività di \(a\) si ottiene
\[
  \frac{d}{dt} \int_0^R u^2(x,t) \, dx \leq ah^2(t)
\]
Integrando in \(t\) con condizione iniziale \(u(x,0) = g(x)\) si ottiene:
\begin{equation}
  \int_0^R u^2(x,t) \, dx \leq \int_0^R g^2(x) \, dx + a\int_0^t h^2(s) \, ds
\end{equation}
Siano \(u_1\) e \(u_2\) soluzioni del problema con i dati iniziali \(g_1\) e \(g_2\), e su \(x= 0\) i dati laterali sono \(h_1 \mbox{ e } h_2\). Trattandosi di un problema lineare, \(w = u_1 - u_2\) è ancora soluzione del problema (4.13) con dato iniziale \(g_1 - g_2\) e dato laterale \(h_1 - h_2\). Applicando a \(w\) la (4.14) si ottiene
\[
  \int_0^R [u_1(x,t) - u_2(x,t)]^2 \, dx \leq \int_0^R (g_1 - g_2)^2 \, dx + a\int_0^t(h_1 - h_2)^2 \, ds
\]
che mostra come lo scarto quadratico tra le soluzioni sia mantenuto controllato da quello presente tra i dati. La soluzione del problema allora dipende solo dai dati iniziali e non da quelli laterali.
\subsection{Traffico su strada}
In un tratto rettilineo di strada il traffico si può assimilare al flusso di un fluido descritto da variabili macroscopiche come la densità di auto \(\rho\), la loro velocità media \(v\) e il flusso di auto \(q\). Le tre variabili sono legate dalla relazione 
\[
q = v\rho  
\]
Le ipotesi da considerare sono le seguenti
\begin{itemize}
  \item Corsia singola senza possibilità di sorpasso.
  \item Il numero di auto all'interno del tratto rimane costante.
  \item La velocità delle auto dipende dalla densità
  \[
  v = v(\rho)  
  \]
\end{itemize}
L'ultima ipotesi implica che ogni autista viaggi alla stessa velocità in presenza di una determinata densità, e che tale velocità sia variabile istantaneamente a seconda della densità del momento analizzato, decrescendo all'aumentare della densità.
\[
v'(\rho) = \frac{dv}{d\rho} \leq 0 
\]
Si ricava così la legge di conservazione 
\begin{eqnarray*}
  \rho_t + q(\rho)_x = 0 \\
  q(\rho) = v(\rho)\rho
\end{eqnarray*}
È ragionevole immaginare che nel caso \(\rho\) abbia un valore basso, allora \(v\) sia prossima alla velocità massima consentita \(v_m\). All'aumentare di \(\rho\) fino alla densità massima \(\rho_m\) (ossia quando la distanza tra le auto è minima), la velocità media diminuirà proporzionalmente allo scarto \(\frac{(\rho_m - \rho)}{\rho_m}\). 
\begin{equation}
  v(\rho) = v_m \left(1- \frac{\rho}{\rho_m}\right)
\end{equation}
Quindi 
\begin{eqnarray*}
  q(\rho) = v_m \rho\left(1 -\frac{\rho}{\rho_m}\right) \\
  q(\rho_m)_x = q'(\rho)\rho_m = v_m\left(1-\frac{2\rho}{\rho_m}\right) \rho_x
\end{eqnarray*}
Da cui si ricava l'equazione finale
\begin{equation}
  \rho_t + \underbrace{v_m \left(1-\frac{2\rho}{\rho_m}\right)}_{q'(\rho)} \rho_x = 0
\end{equation}
Questa equazione, a causa del termine in \(\rho\rho_x\), non è lineare, ma quasilineare, ossia lineare rispetto alle derivate parziale. Inoltre
\[
  q''(\rho) = -\frac{2v_m}{\rho_m} < 0
\]
ossia \(q\) è concava. Inoltre la condizione iniziale sarà 
\begin{equation}
  \rho(x, 0) = g(x)
\end{equation}
Risolvere il problema ai valori iniziali (4.16), (4.17). Per calcolare la densità \(\rho\) nel punto \((x,t)\), si connette il punto \((x,t)\) a un punto \((x_0, t)\), mediante una curva lungo la quale \(\rho\) sia costante, detta caratteristica.
In tal modo il valore di \(\rho\) in \((x,t)\) sarà uguale a quello noto \(\rho(x_0, t) = g(x_0)\). Ripetendo tale procedimento per ogni punto \((x,t) \in \mathbb{R}, t > 0\) si riesce a calcolare il valore di \(\rho\) in ogni punto. Questo si chiama metodo \emph{delle caratteristiche}. \\
Il metodo quindi consiste nel partire da un punto noto \((x_0, 0)\) e muoversi lungo una determinata curva caratteristica, come può essere l'equazione \(x = x(t)\), in modo da poter osservare sempre la stessa densità iniziale \(g(x_0)\).
Matematicamente diventa 
\begin{equation}
  \rho(x(t), t) = g(x_0) \qquad \forall t > 0
\end{equation}
che derivata diventa 
\[
\frac{d}{dt}\rho(x(t), t) = \rho_x(x(t), t) \dot{x}(t) +\rho_t(x(t), t) = 0 \qquad (t > 0)  
\]
Del resto, dalla (4.16) si ha
\[
  \rho_t(x(t), t) + q'(g(x_0))\rho_x(x(t), t) = 0
\]
che, sottraendo le due ultime equazioni, si ha 
\[
  \rho_x(x(t), t)[\dot{x}(t) - q'(g(x_0))] = 0
\]
Si assuma \(\rho_x(x(t), t) \not = 0\) in modo da ottenere
\[
  \dot{x}(t) = q'(g(x_0))
\]
con condizione iniziale \(x(0) = x_0\). Integrando si ottiene
\begin{equation}
  x(t) = q'(g(x_0))t + x_0
\end{equation}
Le rette caratteristiche hanno quindi pendenza \(q'(g(x_0))\), che varia al variare di \(x_0\). Ricavare la formula per \(\rho\) implica il metodo delle caratteristiche. Si ha, avendo \(x(t) = t\):
\[
  x_0 = x - q'(g(x_0))t
\]
da cui
\begin{equation}
  \rho(x,t) = g(x-q'(g(x_0)))
\end{equation}
che rappresenta l'equazione di una onda progressiva, diretta sull'asse \(x\) con velocità \(q'g(x_0))\). 
Dalla (4.20) si ricava \(\rho\) in forma implicita 
\[
  \rho = g(x - q'(g(x_0)))
\]
Il termine \(q'(g(x_0))\) indica la velocità locale dell'onda, da non confondersi con la velocità del traffico.
Infatti
\[
  \frac{dq}{d\rho} = \frac{d(\rho v)}{d\rho} = v + \rho\frac{dv}{d\rho} \leq v \qquad \rho \geq 0, \frac{dv}{d\rho} \leq 0
\]
Il problema sembra essere risolto, tuttavia anche se il dato \(g\) è regolare, può dare vita a delle singolarità nella soluzione in grado di rendere inefficace il metodo utilizzato. Se \(g(x_1) \not = g(x_2)\), il valore in \((x,t)\) non è univocamente determinato, in quanto dovrebbe assumere simultaneamente entrambi i valori. \\
Una strada rappresentata dall'asse \(x\) ha un semaforo rosso posto in \(x = 0\) dove si è formata una coda. In \(x > 0\) la strada è libera. Il profilo iniziale della densità sarà 
\[
g(x) = \begin{cases}
  \rho_m & x < 0 \\
  0 & x > 0
\end{cases}  
\]
Il valore di \(g(0)\) non è rilevante. Il semaforo diventa verde al tempo \(t\) e il comportamento delle macchine diventa, data \(q'(\rho) = v_m\left(1-\frac{2\rho}{\rho_m}\right)\) la velocità locale dell'onda sarà 
\[
q'(g(x_0)) = \begin{cases}
  -v_m & x_0 < 0 \\
  v_m & x_0 > 0
\end{cases} 
\]
da cui le rette caratteristiche
\begin{eqnarray*}
  x = -v_m t + x_0 & \mbox{se } x_0 < 0 \\
  x = v_m t + x_0 & \mbox{se } x_0 > 0
\end{eqnarray*}
Le rette \(x = \pm v_m t\) dividono il piano in tre regioni distinte. 
Nella regione più a sinistra si avrà \(\rho(x,t) = \rho_m\), mentre in quella più a destra \(\rho(x,t) = 0\). Il segnale di partenza si propaga verso sinistra con velocità \(v_m\). Nel settore centrale che densità ci si può aspettare? Dal momento che nessuna caratteristica lo attraversa, è necessario attuare una nuova strategia
\begin{itemize}
  \item Approssimare il dato iniziale con una funzione continua \(g_{\epsilon}\) convergente a \(g\) per \(\epsilon \to 0\) in ogni punto eccetto l'origine.
  \item Costruire la soluzione \(\rho_{\epsilon}\) del problema approssimato con il metodo delle caratteristiche.
  \item Passando al limite per \(\epsilon \to 0\) e controllando che il limite di \(\rho_{\epsilon}\) sia effettivamente soluzione originale.
\end{itemize}
Il rischio che si corre è quello di costruire soluzioni che dipendano solamente dal modo di regolarizzare il dato iniziale, tuttavia questo metodo va bene per trovare \emph{almeno una soluzione}
\begin{itemize}
  \item Sia \(g_{\epsilon}\)  la funzione 
  \[
  g_{\epsilon} (x) = \begin{cases}
    \rho_m & x \leq 0 \\
    \rho_m(1-\frac{x}{\epsilon}) & 0 < x < \epsilon \\
    0 x \geq \epsilon
  \end{cases}  
  \]
  Se \(\epsilon \to 0\), allora \(g_{\epsilon}(x) \to g(x)\)
  \item Le caratteristiche del problema approssimato sono
  \begin{eqnarray*}
    x = - v_m t + x_0 & \mbox{se } x_0 < 0 \\
    x = -v_m \left(1 - 2\frac{x_0}{\epsilon}\right)t + x_0 & \mbox{se }0 \leq x_0 < \epsilon \\
    x = v_m t + x_0 & \mbox{se } x_0 \geq \epsilon
  \end{eqnarray*}
  essendo, per \(0 \leq x_0 < \epsilon\),
  \[
    q'(g_{\epsilon}(x_0)) = v_m \left(1 - \frac{2g_{\epsilon}(x_0)}{\rho_m}\right) = -v_m\left(1 - 2\frac{x_0}{\epsilon}\right)
  \]
Le caratteristiche della regione compresa tra \(-v_m t < x < v_m t + \epsilon\), si distribuiscono come un ventaglio. Fuori da tale regione si ha \(\rho_{\epsilon}(x, t) = 0\) per \(x \geq v_m t + \epsilon\), mentre in \(x < -v_mt\) si ha \(\rho_m (x, t) = \rho_m\). All'interno della regione invece si ha, ricavando \(x_0\) dall'equazione della caratteristica \(x = -v_m\left(1 - 2\frac{x_0}{\epsilon}\right)t + x_0\):
\[
  x_0 = \epsilon \frac{x + v_m t}{2v_m t + \epsilon}
\] 
Di conseguenza
\begin{equation}
  \rho_m (x,t) = g_x{\epsilon} (x_0) \rho_m \left(1- \frac{x_0}{\epsilon}\right) = \rho_m \left( 1 - \frac{x + v_m t}{2 v_m t + \epsilon}\right)
\end{equation}
\item Passando al limite per \(\epsilon \to 0\) nella (4.21) si ha 
\begin{equation}
  \rho(x,t) = \begin{cases}
    \rho_m & \mbox{per }x \leq -v_mt \\
    \frac{\rho_m}{2} \left(1 - \frac{x}{v_m t}\right) & \mbox{per } -v_m t < x < v_m t \\
    0 & \mbox{per } x \geq v_m t
  \end{cases}
\end{equation}
\end{itemize}
In tutte le regioni \(\rho\) è soluzione della (4.16), inoltre fissato \(t\), \(\rho\) decresce in maniera lineare da \(\rho_m\) fino a \(0\). Nel ventaglio di rette definito tra \(-v_m \mbox{ e } v_m\) \(\rho\) è costante. Questo genere di soluzioni si chiamano \emph{onde di rarefazione.} \\ 
Si può lavorare anche a posteriori per ottenere una soluzione, infatti essendo l'equazione delle caratteristiche riscrivibile come (\(g(x_0) = \rho(x,t)\)):
\[
  x = v_m \left(1 - \frac{2g_{\epsilon}(x_0)}{\rho_m}\right)t + x_0 = v_m \left(\frac{2\rho(x, t)}{\rho_m}\right)t + x_0 
\]
Inserendo \(x_0 = 0\) si ha:
\[
  x = v_m \left( 1 - \frac{2\rho(x,t)}{\rho_m}\right)t
\]
Da cu si trova, ricavando \(\rho\) 
\begin{equation}
  \rho(x,t) = \frac{\rho_m}{2} \left(1 - \frac{x}{v_m t}\right) \qquad (t > 0)
\end{equation}
Poiché \(v_m \left(1 - \frac{2\rho}{\rho_m}\right) = q'(\rho)\), si ottiene che la (4.23) equivale a 
\[
  \rho(x, t) = r\left(\frac{x}{t}\right)
\]
dove \(r = (q')^{-1}\) è la funzione inversa di \(q'\). Si ha così una soluzione continua su tutto il piano in grado di raccordare i due estremi \(0 \mbox{ e } \rho_m\) con un'onda di rarefazione. \\
Si supponga di avere un dato iniziale
\[
g(x) = \begin{cases}
  \frac{1}{8} \rho_m & x < 0 \\
  \rho_m & x > 0
\end{cases}  
\]
In questo caso le auto sono ferme per \(x > 0\), mentre prima le auto si muoveranno a velocità \(v = \frac{7}{8}v_m\), rendendo una collisione inevitabile. Infatti
\[
  q'(g(x_0)) = \begin{cases}
    \frac{3}{4}v_m \mbox{se } g(x_0) = \frac{\rho_m}{8} \\
    -v_m & \mbox{se }g(x_0) = \rho_m 
  \end{cases}
\]
Poiché le caratteristiche hanno coefficiente differente, in un tempo finito si dovranno intersecare. In questo istante occorre ammettere una discontinuità a salto nella soluzione, per cui va rivista tutta la differenziazione dell'equazione di conservazione, venendo meno l'ipotesi di regolarità della soluzione.
La legge 
\begin{equation}
  \frac{d}{dt} \int_{x_1}^{x_2} \rho(x,t) \, dx = q[\rho(x_1, t) - q(x_2, t)]
\end{equation}
valida in ogni intervallo [\(x_1, x_2\)], e sia \(\rho\) una soluzione che presenti una discontinuità a salto in \(x = s(t)\). \\
Se ciò avviene per tutti i \(t \in [t_1, t_2]\), allora \(x = s(t)\) prende il nome di \emph{linea d'urto}. L'idea è che una discontinuità segnali un brusco cambiamento, e lo propaghi lungo una linea del piano \((x,t)\). \\
Si cerchi un'equazione per la funzione \(s(t)\), supponendola differenziabile. Al di fuori della linea d'urto si può supporre che sia regolare e dotata di derivate continue. Si consideri invece un intervallo \([x_1, x_2]\) per \(t\) fissato che contenga la discontinuità \(s(t)\). Dalla (4.24) si ha
\begin{equation}
    \frac{d}{dt} \left\lbrace \int_{x_1}^{s(t)} \rho(y,t) \, dy + \int_{s(t)}^{x_2} \rho(y,t) \, dy\right\rbrace = -q[\rho(x_2, t)] + q[\rho(x_1, t)]
\end{equation}
Dato che 
\[
  \frac{d}{dt} \int_{x_1}^{s(t)} \rho(y,t) \, dy = \int_{x_1}^{s(t)} \rho_t(y, t) \, dy + \rho^{-}(s(t), t)\dot{s}(t)
\]
e
\[
  \frac{d}{dt} \int_{s(t)}^{x_2} \rho(y,t) \, dy = \int_{s(t)}^{x_2} \rho_t(y, t) \, dy - \rho^{+}(s(t), t)\dot{s}(t)
\]
dove 
\[
  \rho^- (s(t), t) = \lim_{y \to s(t)} \rho(y, t), \rho^+ (s(t), t) = \lim_{y \to s(t)} \rho(y,t)
\]
che trasforma la (4.25) in 
\[
\int_{x_1}^{x_2} \rho_t (y,t) \, dy + [\rho^- (s(t), t) - \rho^+ (s(t), t)] \dot{s}(t) = q[\rho(x_1, t)] - q[\rho(x_2,t)]
\]
Con il passaggio al limite \(x_1 \to s(t)\) e \(x_2 \to s(t)\) si ottiene
\[
  [\rho^- (s(t), t) - \rho^+ (s(t), t)] \dot{s}(t) = q[\rho^- (s(t), t)] - q[\rho^+(s(t), t)]
\]
ossia 
\begin{equation}
  \dot{s}(t) = \frac{q[\rho^+(s(t), t)] - q[\rho^+(s(t) ,t)]}{\rho^+(s(t) ,t) - \rho^- (s(t), t)}
\end{equation}
sintetizzabile come
\[
  \dot{s} = \frac{[q(\rho)]^+_-}{[\rho]^+_-}
\]
con la notazione \([\cdot]^+_-\) a indicare un salto a sinistra e a destra dell'urto. \\
L'equazione differenziale per \(s = s(t)\) prende il nome di condizione di Rankine-Hugoniot, e indica la velocità di propagazione dello shock, conoscendo i valori della densità da entrambi i lati della linea d'urto e il punto iniziale di quest'ultima. Una soluzione in grado di soddisfare questa condizione prende il nome di onda d'urto.
Applicando tali condizioni al problema del traffico si ha
\begin{eqnarray*}
  \rho^+ = \rho_m  & \rho^- = \frac{\rho_m}{8}    
  q(\rho^+) = 0 & q(\rho^-) = \frac{7}{64}v_m\rho_m
\end{eqnarray*}
per cui la (4.26) 
\[
  \dot{s}(t) = \frac{q(\rho^+) - q(\rho^+)}{\rho^+ - \rho^-} = -\frac{1}{8}v_m
\]
Inoltre, dato che, \(s(0) = 0\), si trova la retta che rappresenta la linea d'urto come 
\[
  x = -\frac{1}{8}v_m t
\]
Lo shock si propaga all'indietro, come si può rilevare empiricamente nel mondo reale osservando un'auto che frena all'improvviso.
La formula per la densità si ottiene come
\[
\rho(x,t) = \begin{cases}
  \frac{1}{8} \rho_m & x < -\frac{1}{8} v_m t \\
  \rho_m & x > - \frac{1}{8} v_m t
\end{cases}  
\]
\subsection{Soluzioni integrali}
Il metodo delle caratteristiche più in generale funziona per il problema 
\begin{equation}
  \begin{cases}
    u_t + q(u)_x = 0 \\
    u(x, 0) = g(x)
  \end{cases}
\end{equation}
La soluzione \(u\) è definita dalla (4.20) (con \(x_0 = \xi\)): 
\begin{equation}
  u(x,t) = g[x - q'(g(\xi))t] \qquad \left(q' = \frac{dq}{du}\right)
\end{equation}
che rappresenta una famiglia di onde progressive con velocità locale \(q'(g(\xi))\). Essendo \(u(x,t) \equiv g(\xi)\) lungo la caratteristica
\begin{equation}
x = q'(g(\xi))t + \xi
\end{equation}
uscente dal punto \((\xi, 0)\), la (4.28) indica che \(u\) è definita implicitamente da 
\begin{equation}
  G(x, t, u) = u - g[x - q'(u)t] = 0
\end{equation}
Se \(g \mbox{ e } q'\) sono funzioni regolari, il teorema delle funzioni implicite, implica che la (4.30) definisce \(u\) come funzione di \((x, t)\) finché vale la condizione 
\[
  G_u(x, t, u) = 1 + t q''(u)g'[x - q'(u)t] \not = 0
\]  
Calcolando \(G_u\) lungo le caratteristiche (4.29), si ha
\[
  u = g(\xi) \mbox{ e } \xi = x - q'(g(\xi))t
\]
per cui 
\begin{equation}
  G_u (x, t, u) = 1 + t q''(g(\xi))g'(\xi)
\end{equation}
Conseguenza immediata è che se \(q'' \circ g\) e \(g'\) hanno lo stesso segno, la soluzione è definita e regolare per ogni \(t > 0\). Non sorprendente in quanto 
\[
q''(g(\xi))g'(\xi) = \frac{d}{d\xi}q'(g(\xi)) 
\]
esprime il fatto che le caratteristiche hanno pendenza crescente con \(\xi\), cosicché non riescano a intersecarsi.
\begin{theorem}
  Sia \(q \in \mathcal{C}^2\mathbb{R}, g\in \mathcal{C}^1(\mathbb{R})\) e inoltre \(q''(g(\xi))g'(\xi) \geq 0\) in \(\mathbb{R}\). Allora la (4.30) definisce \(u = u(x, t)\) come unica soluzione del problema (4.3). Inoltre \(u \in \mathcal{C}^1(\mathbb{R} \times [0, +\infty))\).
\end{theorem}
\begin{proof}
  Sotto le ipotesi indicate, lungo ogni caratteristica \(\xi = x - q'(u)t\) e si ha 
  \[
    G_u (x, t, u) = 1 + tq''(u)g'(x - q'(u)t) \geq 1, \qquad \forall t > 0
  \]
  e inoltre, sempre dal teorema delle funzioni implicite, 
  \[
    u_t = -\frac{G_t(x, t, u)}{G_u(x, t, u)} = -\frac{g'(x-q'(u)t)q'(u)}{1+tq''(u)g'(x - q'(u)t)}
  \]
  e
  \begin{equation}
    u_x = -\frac{G_x(x,t,u)}{G_u(x,t,u)} = \frac{g'(x-q'(u)t)}{1+tq''(u)g'(x-q'(u)t)}
  \end{equation}
  e quindi \(u_t, u_x\) sono rapporti di funzioni continue, con denominatore positivo.
\end{proof}
Per esempio, nella \(\epsilon\)-approssimazione del problema al semaforo, \(q\) è concava, \(g_{\epsilon}\). Sebbene \(g_{\epsilon}\) non sia differenziabile nei due punti \(x = 0\) e \(x = \epsilon\), le caratteristiche non si intersecano e \(\rho_{\epsilon}\) è ben definita per tutti i tempi \(t > 0\). Il teorema (4.2) continua a essere valido per tempi piccoli, in quanto \(G_u \sim 1\) se \(t \sim 0\), ma al crescere del tempo è legittimo aspettarsi la formazione di uno shock. Siano \(q\) concava e \(g\) crescente, per \(q''(g(\xi))g'(\xi) < 0\). Quando \(\xi\) cresce, \(g\) cresce, mentre \(q'(g(\xi))\) decresce, quindi l'intersezione delle caratteristiche avverrà lungo la linea d'urto. Il problema che si presenta è quello di determinare l'istante \(t_s\) e il punto \(x_s\) da cui parte la linea d'urto. \\
Si osservi che, essendo \(q''(g(\xi))g'(\xi) < 0\) in \([a,b]\), l'espressione 
\[
  G_u(x,t,u) = 1 + tq''(g(\xi))g'(\xi)  
\] 
si azzera nel caso \(t(\xi) = -[q''(g(\xi))g'(\xi)]^{-1}\). L'istante \(t_s\) è il più piccolo fra questi tempi. Il punto \((x_s, t_s)\) si trova sulla caratteristica uscente dal punto \(\xi_M\), il quale minimizza \(t(\xi)\). 
Con la funzione positiva
\[
  z(\xi) = -q''(g(\xi))g'(\xi) \qquad  \xi \in [a,b]
\]
e sia il suo massimo assunto soltanto su \(\xi_M\). Allora \(z(\xi_M) > 0\) e 
\begin{equation}
  t_s = \min_{\xi \in [a,b]} \frac{1}{z(\xi)} = \frac{1}{z(\xi_M)}
\end{equation}
Poiché \(x_s\) appartiene alla caratteristica \(x = q'(g(\xi_M))t + \xi_M\), si ha 
\begin{equation}
  x_s = \frac{q'(g(\xi_M))}{z(\xi_M)} + \xi_M
\end{equation}
Il punto \((x_s, t_s)\) ha un significato geometrico interessante. Infatti se \(q''(g(\xi))g'(\xi) < 0\) in qualche intervallo, la famiglia di caratteristiche (4.29) assume un inviluppo e \((x_s, t_s)\) è il punto dell'inviluppo con la minima coordinata temporale. \\
Il problema 
\begin{equation}
  \begin{cases}
    u_t + (1-2u)u_x = 0 \\
    u(x, 0) = \arctan x
  \end{cases}
\end{equation}
Siano \(q(u) = u-u^2, q'(u) = 1- 2u, q''(u) = -2\) e \(g(\xi) = \arctan \xi, g' (\xi) = \frac{1}{(1+\xi^2)}\). La funzione 
\[
  z(\xi) = -q''(g(\xi))g'(\xi) = \frac{2}{(1+\xi^2)}
\]
assume il suo massimo nel punto \(\xi_M = 0\) e \(z(0) = 2\). Il momento in cui parte la linea d'urto allora è \((x_s, t_s) = (\frac{1}{2}, \frac{1}{2})\). La soluzione \(u\) è regolare e definita per \(0 \leq t < \frac{1}{2}\) dall'equazione
\begin{equation}
  u - \arctan [x-(1 - 2u)t] = 0
\end{equation} 
Dopo \(t = \frac{1}{2}\), la (4.36) permette di definire \(u\) come una funzione di \((x, t)\) a più valori, che non assume più alcun significato fisico. \\
Il metodo delle caratteristiche non è sufficiente a determinare il valore della soluzione di (4.1) in tutto il semipiano \(t > 0\), e non è applicabile in presenza di discontinuità. Sebbene siano possibili delle soluzioni per determinati casi, alcuni dubbi sorgono spontaneamente:
\begin{itemize}
  \item In che senso l'equazoine differenziale è soddisfatta attraverso una linea d'urto, dove l'equazione non è differenziabile?
  \item La soluzione costruita è l'unica possibile?
  \item Se non è l'unica, esiste un criterio per selezionare la soluzione più `adatta'?
\end{itemize}
A tale domanda si risponde introducendo una nozione di soluzione più `flessibile'
\begin{equation}
  \begin{cases}
    u_t + q(u)_x = 0 & x \in \mathbb{R}, t> 0 \\
    u(x, 0) = g(x) & x \in \mathbb{R}
  \end{cases}
\end{equation}
Sia \(u\) una soluzione regolare, almeno di classe \(\mathcal{C}^1\) in \(\mathbb{R} \times [0, +\infty)\). Si può dire che \(u\) sia una soluzione classica. Scelta ora una funzione \(v \in \mathcal{C}^1(\mathbb{R} \times [0, +\infty))\), che abbia supporto compatto, definita come \emph{funzione test}. Moltiplicando l'equazione differenziale per \(v\) e integrandola su \(\mathbb{R} \times (0, \infty)\) si ottiene
\begin{equation}
  \int_0^{\infty} \int_{\mathbb{R}} [u_t + q(u)_x]v \, dxdt = 0
\end{equation}
Grazie all'integrazione per parti del primo termine rispetto a \(t\) si ha
\begin{eqnarray*}
  \int_0^{\infty} \int_{\mathbb{R}} u_tv \, dxdt & = & -\int_0^{\infty} \int_{\mathbb{R}} uv_t -\int_{\mathbb{R}} u(x,0)v(x,0) \, dx \\
  & = & -\int_0^{\infty} \int_{\mathbb{R}} uv_t -\int_{\mathbb{R}} g(x)v(x,0) \, dx
\end{eqnarray*}
Integrando per parti rispetto a \(x\) il secondo termine si trova
\[
  \int_0^{\infty} \int_{\mathbb{R}} q(u)_x v \, dxdt = -\int_0^{\infty}\int_{\mathbb{R}} q(u)v_x \, dxdt
\]
La (4.38) diventa
\begin{equation}
  \int_0^{\infty} \int_{\mathbb{R}} q(u)_x v \, dxdt = - \int_0^{\infty} \int_{\mathbb{R}} q(u) v_x \, dxdt
\end{equation}
Si ottiene così una equazione integrale valida per qualsiasi funzione \(v\). Nella (4.39) non compaiono derivate di \(u\). Se \(u\) è regolare, integrando per parti, si ottiene 
\begin{equation}
  \int_0^{\infty} \int_{\mathbb{R}} [u_t + q(u)_x]v \, dxdt - \int_{\mathbb{R}} [g(x) - u(x, 0)]v(x,0) \, dx = 0
\end{equation}
che è vera per ogni funzione test \(v\). Scegliendo delle funzioni che si annullano per \(t=0\), il secondo integrale è nullo per cui si riottiene la (4.38), che implica\footnote{Sarà usato spesso il \emph{lemma di annullamento}: Sia \(f:\Omega \to \mathbb{R}, \Omega\) aperto di \(\mathbb{R}^n\) e continua. Se 
\[
\int_{\Omega} fv \, dx = 0  
\]
per ogni \(v \in \mathcal{C}^1(\Omega)\) a supporto compatto, allora \(f \equiv 0\)}
\[
u_t + q(u)_x = 0 \qquad \mbox{in }  \mathbb{R} \times (0, +\infty)
\]
Si riduce la (4.40) a 
\[
  \int_{\mathbb{R}} [g(x) - u(x,0)]v(x,0) \, dx = 0
\]
che, sempre per l'arbitrarietà di \(v\), implica
\[
  u(x, 0) = g(x) \qquad \mbox{in }\mathbb{R}
\]
Allora, per funzioni regolari, il problema (4.37) equivale a richiedere che la (4.39) sia valida per ogni funzione test.
Poiché la (4.39) ha senso anche per funzioni non derivabili, si parla di formulazione \emph{integrale o debole} del problema (4.37), da cui
\begin{definition}
  Una funzione \(u\), limitata in \(\mathbb{R} \times [0, +\infty)\), si dice soluzione integrale (o debole) del problema (4.37) se la (4.39) vale per ogni funzione di test \(v\) in \(\mathbb{R} \times [0, +\infty)\), a supporto compatto.
\end{definition}
Poiché la soluzione integrale deve essere solo limitata, può ammettere discontinuità. La definizione (4.1) esprime in modo abbastanza soddisfacente tale soluzione. In alcuni casi tuttavia occorre capire quali informazioni sul comèprtamento di una soluzione debole siano nascoste nella formulazione integrale. \\
Si consideri un aperto \(V\) contenuto nel semipiano \(t > 0\), diviso in due domini disgiunti \(V^+, V^-\), separati da una curva regolare \(\Gamma\) di equazione \(x = s(t)\). Si immagini ora una soluzione integrale \(u\) di classe \(\mathcal{C}^1\) in \(\overline{V}^+, \overline{V}^-\) e che presenti, lungo \(\Gamma\) una discontinuità a salto. In entrambi i domini, \(u\) è soluzione classica dell'equazione \(u_t + q(u)_x = 0\). Si trovi ora una funzione test \(v\) il cui supporto sia contenuto in \(V\), ma che intersechi la curva \(\Gamma\). Allora, essendo \(v(x, 0) = 0\):
\begin{eqnarray*}
  0 & = & \int_0^{\infty} \int_{\mathbb{R}} [uv_t + q(u)v_x] \, dxdt \\
  & = & \int_{V^+} [uv_t + q(u)v_x] dxdt + \int_{V^-} [uv_t + q(u)v_x] \, dxdt
\end{eqnarray*} 
Utilizzando Gauss-Green e ricordando che \(v = 0\) su \(\partial V^+ \backslash \Gamma\), si ha
\begin{eqnarray*}
  \int_{V^+} [uv_t + q(u)v_x] \, dxdt = \\
  = -\int_{V^+} [u_t + q(u)v_x]v \, dxdt + \int_{\Gamma} [u^+n_2 + q(u^+)n_1]v \, dl \\
  = \int_{\Gamma} [u^+ n_2 + q(u^+)n_1] v \, dl
\end{eqnarray*}
dove \(u^+\) indica il valore a cui tende \(u\) quando ci si avvicina a \(\Gamma\) da destra, \(\bm{n} = (n_1, n_2)\) è il versore normale a \(\Gamma\) nel verso uscente da \(V^+\) e \(dl\) indica la lunghezza d'arco su \(\Gamma\). 
Analogamente:
\[
  \int_{V^-} [uv_t + q(u)v_x] \, dxdt = -\int_{\Gamma} [u^-n_2 + q(u^-)n_1]v \, dl
\]
dove \(u^-\) indica il valore a cui tende \(u\) arrivando a \(\Gamma\) da sinistra. Si deduce che 
\[
  \int_{\Gamma} \{[q(u^+) - q(u^-)]n_1 + [u^+ - u^-]n_2\} v \, dl = 0
\]
L'arbitrarietà di \(v\) implica su \(\Gamma\), vale la condizione
\begin{equation}
  [q(u^+) - q(u^-)]n_1 + [u^+ - u^-]n_2 = 0
\end{equation}
La (4.41) in modo più esplicito, se \(x = s(t)\) è l'equazione di \(\Gamma\) e \(s \in \mathcal{C}^1([0, T])\), diventa
\[
\bm{n} = (n_1, n_2) = \frac{1}{\sqrt{1 + \dot{s}(t)^2}}(-1, \dot{s}(t))  
\]
che trasforma la (4.41) con qualche sistemazione
\begin{equation}
  \dot{s} = \frac{q(u^+(s,t)) - q(u^- (s,t))}{u^+(s,t) - u^- (s,t)}
\end{equation}
Che si chiama condizione di \emph{Rankine-Hugoniot}, da cui si ha la conferma che \(u\) è una onda d'urto. \\
Tuttavia è da comprendere se la soluzione trovata è unica, e per farlo si può osservare un contro esempio basato sull'equazione di Burgers
\[
u_t + uu_x = u_t +\left(\frac{u^2}{2}\right)_x = 0  
\]
che corrisponde alla legge di conservazione
\[
q(u) = \frac{u^2}{2}  
\]
Importante notare come \(q\) sia strettamente convessa, \(q'(u) = u\) e \(q''(u) = 1\). Si esamini la soluzione del problema alle condizioni iniziali \(u(x,0) = g(x)\), dove 
\[
  g(x) = \begin{cases}
    0 & x < 0 \\
    1 & x > 1
  \end{cases}
\]
Le caratteristiche sono allora rette di equazione 
\begin{equation}
  x = g(x_0) t + x_0
\end{equation}
Pertanto, si trova \(u = 0\) se \(x < 0\) e \(u = 1\) se \(x > t\). Nel settore compreso tra \(0 < x < t\) non passano caratteristiche. Come nel caso del modello del traffico al semaforo, in tale settore si definisce \(u\) come una onda di rarefazione, che mantenga continuità tra i valori estremi \(0 \mbox{ e } 1\). Essendo \(r(s) =(q')^{-1}(s) = s\), si perviene a 
\begin{equation}
  u(x,t) = \begin{cases}
    0 & x \leq 0 \\
    \frac{x}{t} & 0 < x < t \\
    1 x \geq 1
  \end{cases}
\end{equation}
che risulta anche soluzione integrale. 
Non è tuttavia l'\emph{unica} soluzione integrale. Infatti, esiste anche un'onda d'urto che è soluzione con la curva di shock uscente dall'origine. 
\[
u^- = 0, u^+ = 1, q(u^-) = 0, q(u^+) = \frac{1}{2}  
\]
permette di ottenere una condizione di Rankine-Hugoniot 
\[
\dot{s}(t) = \frac{q(u^+) - q(u^-)}{u^+ - u^-}   = \frac{1}{2}
\]
Inoltre, sapendo che \(s(0) = 0\), la linea d'urto è la retta di equazione 
\[
x = \frac{t}{2}  
\]
Allora la funzione
\[
w(x,t) = \begin{cases}
  0 & x < \frac{t}{2} \\
  1 & x > \frac{t}{2}
\end{cases}
\]
è anch'essa soluzione integrale (shock non fisico).
Allora si può osservare come non sia garantita l'unicità di una soluzione integrale. È necessario allora stabilire un criterio che permetta di stabilire quale di queste soluzioni abbia senso dal punto di vista fisico. 
Tornando al teorema (4.2), si assumano \(g' > 0\) e \(q'' \geq q_{\text{min}}''\). La soluzione è unica e classica, e dalla (4.32) si ricava 
\[
u_x (x,t) = \frac{g'(x-q'(u)t)}{1+tq''(u)g'(x-q'(u)t)} \leq   \frac{1}{tq''(u)} \leq \frac{E}{t}  
\]
dove \(E = \frac{1}{q_{\text{min}}''}\). \\
Dal teorema del valor medio di Lagrange si ottiene la condizione di entropia, ossia: \\
Esiste \(E > 0\) tale che, per ogni \(x, z \in \mathbb{R}, z > 0\) e per ogni \(t > 0\)
\begin{equation}
  u(x+z, t) - u(x,t) \leq \frac{E}{t}z
\end{equation}
La condizione di entropia non coinvolge operazioni di derivazione ed è utilizzabile anche in caso di soluzione discontinue. Se una soluzione integrale soddisfa la (4.45), si dirà che è una soluzione entropica. Allora, sia \(u\) una soluzione integrale che soddisfi la (4.45)
\begin{itemize}
  \item La funzione 
  \[
  x \longrightarrow u(x,t) - \frac{E}{t}x  
  \]
  è non è crescente. Infatti, sia \(x+z=x_2, x = x_1\) se \(z > 0\) si ha \(x_2 > x_1\) e la (4.45) equivale a
  \begin{equation}
    u(x_2, t) -\frac{E}{t} x_2 \leq u(x_1, t)
  \end{equation}
  \item Se \((x,t)\) è un punto di discontinuità per \(u\), allora 
  \begin{equation}
    u^+(x,t) < u^- (x,t)
  \end{equation}
  dove \(u^{\pm} (x,t) = \lim_{y \to x^{\pm}}u(y,t)\). Basta scegliere \(x_1 < x < x_2\) e passare al limite nella (4.46). 
\end{itemize}
Se \(q\) è una funzione strettamente convessa, si ottiene dalla (4.47)
\begin{equation}
  q'(u^+) < \frac{q(u^+) - q'(u^-)}{u^+ - u^-} < q'(u^-)
\end{equation}
La condizione di Rankine-Hugoniot implica allora che, se \(x = s(t)\) è una linea d'urto,
\begin{equation}
  q'(u^+) < \dot{s} < q'(u^-)
\end{equation}
è definita come disuguaglianza dell'entropia. Si può definire geometricamente come la pendenza di una linea d'urto che è minore di quella delle caratteristiche che arrivano da sinistra e maggiore di quella delle caratteristiche di destra. Le caratteristiche sono quindi tutte entranti nella linea d'urto.
\begin{theorem}
  Se \(q \in \mathcal{C}^2(\mathbb{R})\) è convessa (o concava) e \(g\) è limitata, esiste una unica soluzione integrale del problema 
  \begin{equation}
    \begin{cases}
      u_t + q(u)_x = 0 & x \in \mathbb{R}, t > 0 \\
      u(x, 0) = g(x) & x \in \mathbb{R}
    \end{cases}
  \end{equation}
  che soddisfi la condizione di entropia.
\end{theorem}
Applicando il teorema (4.3) per risolvere il problema (4.50) con i seguenti dati iniziali
\[
  g(x) = \begin{cases}
    u^+ & x > 0 \\
    u^- & x < 0
  \end{cases}
\]
con \(u^+, u^-\) costanti e diversi tra loro. La funzione \(q\) può essere sia convessa che concava. Tale problema è noto come \emph{problema di Riemann} e ha una importanza particolare nei problemi in cui è necessario utilizzare l'approssimazione numerica.
\begin{theorem}
  Sia \(q\) una funzione strettamente convessa e di classe \(\mathcal{C}^2(\mathbb{R})\) con \(q'' \geq h > 0\)
  \begin{itemize}
    \item Se \(u^ < u^-\) l'unica soluzione integrale in grado di soddisfare la condizione di entropia è l'onda d'urto
    \[
     u(x,t) = \begin{cases}
       u^+ & x > s(t) \\
       u^- & x < s(t)
     \end{cases}  
    \]
    dove \(s(0) = 0 \mbox{ e }\dot{s} = \frac{q(u^+) - q(u^-)}{u^+ - u^-}\)
    \item Se \(u^+ > u^-\), l'unica soluzione integrale possibile per soddisfare la condizione di entropia si ritrova nell'onda di rarefazione
    \[
    u(x,t) = \begin{cases}
      u^- & \frac{x}{t} < q'(u^-) \\
      r(\frac{x}{t}) & q'(u^-) < \frac{x}{t} < q'(u^+) \\
      u^+ & \frac{x}{t} > q'(u^+)
    \end{cases}
    \]
    dove \(r = (q')^{-1}\) indica la funzione inversa di 
    \(q'\).
  \end{itemize}
\end{theorem}
\begin{proof}
  Nel primo caso \(u\) è ovviamente una soluzione integrale e, poiché \(u^+ < u^-\), vale certamente la condizione di entropia. Dal teorema (4.3) ne segue la conclusione.
  Nel secondo caso, poiché 
  \[
  r(q'(u^+)) = u^+ \qquad \mbox{ e } \qquad r(q'(u^-)) = u^-  
  \]
  \(u\) è continua nel semipiano \(t > 0\). Per verificare se \(u\) soddisfa \(u_t + q(u)_x = 0\) all'interno della regione
  \[
  S = \left\lbrace (x,t): q'(u^-) < \frac{x}{t} < q'(u^+)\right\rbrace  
  \]
  Posto \(u(x,t) = r(\frac{x}{t})\) si ottiene
  \[
   u_t + q(u)_x = -r'\left(\frac{x}{t}\right)\frac{x^2}{t} + q'(r)r'\left(\frac{x}{t}\right)\frac{1}{t} = r'\left(\frac{x}{t}\right)\frac{1}{t}\left[q'(r)-\frac{x}{t}\right] \equiv 0
  \]
  con \(r = (q')^{-1}\) come prima. Da questo si intuisce che \(u\) è soluzione integrale. Per la condizione di entropia si consideri il caso 
  \[
    q'(u^-)t \leq x < x + z \leq q'(u^+)t
  \]
  Poiché \(q'' \geq h > 0\) si ottiene
  \[
    r'(s) = \frac{1}{q''(r)} \leq \frac{1}{h} \qquad s = q'(r)
  \]
  e quindi, con \(z^*\) opportuno, si può ottenere
  \begin{flalign}
    u(x+z, t) - u(x,t) = r\left(\frac{x + z}{t}\right) - r\left( \frac{x}{t} \right) = \\
    = r'\left(\frac{x + z^+}{t}\right)\frac{z}{t} \leq \frac{1}{h} \frac{z}{t}
  \end{flalign}
che è esattamente la condizione di entropia per \(E = \frac{1}{h}\)
\end{proof}
\section{Onde e vibrazioni}
\subsection{Concetti generali}
Quando si parla di onde ci sono diversi concetti da considerare, perché vi sono diversi tipi di onde. Un'idea che si può seguire è che una onda è un movimento oscillatorio che si propaga in un mezzo continuo. Nel caso di onde stazionarie, come possono esserlo le onde di rarefazione appena descritte, la propagazione è di un segnale. \\
Le onde possono essere di vario tipo, per esempio, in dimensione \(n = 1\).
\begin{itemize}
  \item[a)]Onde progressive: sono onde descitte da una funzione del tipo 
  \[
    u(x,t) = g(x - ct)
  \]
  Per \(t = 0\), si ottiene \(u(x,0) = g(x)\), che è il profilo iniziale della perturbazione. Tale profilo si propaga in maniera inalterata con velocità \(\abs*{c}\).
  \item[b)] Onde armoniche: un particolare tipo di onde progressive sono le onde armoniche, che hanno forma
  \begin{equation}
    u(x,t) = A e^{i(kx - \omega t)} \qquad A, k , \omega \in \mathbb{R}
  \end{equation}
  doi cui generalmente si considera solo la parte reale
  \[
    A \cos(kx - \omega t)
  \]
Si considerino \(\omega \mbox{ e } k\) positivi, allora si avranno
\begin{itemize}
  \item l'ampiezza dell'onda \(\abs*{A}\)
  \item il numero di onde \(k\) (numero completo di oscillazioni in \([0, 2\pi]\)) e la lunghezza d'onda \(\lambda = \frac{2\pi}{k}\) che è la distanza tra successive creste d'onda
  \item la frequenza angolare \(\omega \mbox{ e la frequenza } f = \frac{\omega}{2\pi}\)
  \item la velocità dell'onda o velocità di fase \(c_p = \frac{\omega}{k}\)
\end{itemize}
\item[c)] Onde stazionarie: sono onde descritte da espressioni tipo 
\[
  u(x,t) = B\cos kx \cos \omega t
\] 
tali onde presentano un'onda base sinusoidale \(\cos kx\), modulata nel tempo da \(B \cos \omega t\). Si ottiene un'onda stazionaria sovrapponendo due onde armoniche con ampiezza identica che si propagano in direzioni opposte:
\begin{equation}
  A\cos(kx-\omega t) + A\cos(kx-\omega t) = 2A\cos kx \cos \omega t
\end{equation}
\end{itemize}
In dimensione spaziale \(n > 1\) si ha:
\begin{itemize}
  \item[d)] Onde piane: le onde progressive scalari sono della forma
  \[
    u(\bm{x}, t) = f(\bm{k}\cdot\bm{x} - \omega t) 
  \] 
  La perturbazione si propaga in direzione \(\bm{k}\) con velocità \(c_p = \frac{\omega}{\abs*{\bm{k}}}\). I piani ortogonali a \(\bm{k}\) di equazioni 
  \[
    \theta (\bm{x}, \bm{t}) = \bm{k} \cdot \bm{x} - \omega t = \mbox{ costante}
  \]
  costituiscono i fronti d'onda. Il caso particolare
  \[
    u(\bm{x}, t) = A e^{e(\bm{k}\cdot\bm{x} - \omega t)}
  \]
corrisponde alle onde piane armoniche o monocromatiche. Qui \(\bm{k}\) è il vettore numero d'onde e \(\omega\) è il frequenza angolare. Gli scalari \(\frac{\abs*{\bm{k}}}{2\pi}\) e \(\frac{\omega}{2\pi}\), rispettivamente, numero d'onde per unità di lunghezza e numero di oscillazioni al secondo.
\item[e)] Le onde sferiche hanno forma del tipo
\[
  u(\bm{x}, t) = v(r,t)
\]
dove \(r = \abs*{\bm{x} - \bm{x}_0}\) e \(\bm{x}_0 \in \mathbb{R}^n\) è un punto fisso. \(u(\bm{x}, t) = e^{i\omega t}v(r)\) rappresenta una onda stazionaria sferica mentre \(u(\bm{x}, t) = v(r - ct)\) è l'equazione di una onda progressiva i cui fronti d'onda appartengono alle sfere di equazione \(r - ct = \text{costante}\), con velocità \(\abs*{c}\).
\end{itemize}
Molti sistemi fisici possono essere modellati da una serie di equazioni che hanno onde armoniche come soluzioni, con la frequenza angolare nota del numero delle onde, in generale una equazione non lineare
\begin{equation}
  \omega = \omega(k)
\end{equation}
Si può osservare tale effetto in un sasso che cade in uno stagno. Nel caso lineare, se cioè \(\omega(k) = ck\), \(c\) costante, le creste si muovono con velocità \(c\) indipendente dal numero di onde. Se \(\omega(k)\) non è proporzionale a \(k\), le creste hanno velocità \(c_p = \omega(k)\) che dipende dal numero di onde. In altri termini, se le creste hanno diverse lunghezze d'onda, avranno differenti velocità. Allora la relazione \(\omega = \omega(k)\) è detta anche relazione di dispersione. La velocità di gruppo di un insieme di onde è data da 
\[
  c_g = \omega'(k)
\]
da cui si ottengono dei risultati importanti
\begin{itemize}
  \item[1)] È la velocità alla quale viaggia un pacchetto di onde isolato. Per pacchetto di onde si intende una sovrapposizione di onde armoniche dispersive, utilizzando, ad esempio, un integrale di Fourier del tipo
  \begin{equation}
    u(x,t) = \int_{-\infty}^{+\infty} a(k)e^{i[kx-\omega(k)t]} \, dk
  \end{equation}
  dove si considera solamente la parte reale. Considerato un pacchetto di onde localizzato, con un numero di onde quasi costante \(k \approx k_0\) e con ampiezze variabili di poco rispetto a \(x\). Allora il numero di creste del pacchetto di onde sarà sicuramente elevato, ma avranno tutte ampiezze minime, eccetto che in un intorno di \(k_0\). Si può allora approssimare la \emph{relazione di dispersione} come 
  \[
    \omega(k) \approx \omega(k_0) + \omega'(k_0)(k - k_0) = \omega(k_0) + c_g (k - k_0)
  \]
  per cui
  \begin{equation}
    u(x,t) \approx e^{i[k_0x - \omega(k_0)t]}\int_{k_0 - \delta}^{k_0 + \delta} a(k)e^{i(k-k_0)(x - c_g t)}\, dk
  \end{equation}
  che permette di ottenere \(u\) dal prodotto di due onde. La prima onda è armonica di lunghezza \(\frac{2\pi}{k_0}\), mentre la seconda dipende da \(x,t\) grazie alla combinazione \((x - c_g t)\) ed è la sovrapposizione di onde con numero d'onda \(k - k_0\).
  \item[2)] Tolto l'effetto di una perturbazione iniziale, si ha a regime che \(c_g\) è la velocità alla quale un osservatore deve viaggiare per osservare della lunghezza \(\frac{2\pi}{k_0}\). 
Nel caso del sasso nello stagno, appena dopo il lancio, la perturbazione è molto complicata, ma dopo un tempo sufficientemente lungo si disperdono le componenti di Fourier e la perturbazione prende la forma di un treno di onde lentamente modulato, quasi ad avere un aspetto sinusoidale in prossimità di ogni punto, con un numero di onde locale \(k(x,t)\) e una frequenza locale \(\omega(x,t)\) che cambiano gradualmente assiema a \(x \mbox{ e } t\) Ci si aspetta che idealmente la lunghezza dell'onda aumenti con l'aumentare della distanza di quest'ultima dal punto di origine, mentre tenderà a diminuire con il tempo. Allora le caratteristiche essenziali possono essere osservate solo dopo un periodo transitorio e a grande distanza dalla perturbazione iniziale. \\
Si assuma che il profilo della superficie libera \(u\) sia dato da un integrale di Fourier come (5.4), allora per un tempo \(t \gg 1\). Un importante strumento è dato dal metodo della fase stazionaria che permette di avere una formula asintotica per \(t \to +\infty\), per integrali del tipo
\begin{equation}
  I(t) = \int_{-\infty}^{+\infty} f(k)e^{it\phi(k)}\, dk
\end{equation}
che, utilizzata per \(u\), restituisce
\[
  u(x,t) = \int_{-\infty}^{+\infty} a(k)e^{it[k\frac{x}{t} - \omega(k)]}
\]
muovendosi dall'origine con velocità \(V\) \((x = Vt)\) e definita \(\phi\) come 
\[
  \phi(k) = kV - \omega(k)
\]
Utilizzando l'idea che in \(\phi\) ci sia un solo punto stazionario in \(k_0\), ossia
\[
  \omega'(k_0) = V
\]
e \(\omega''(k_0) \not = 0\). Allora si ha con il metodo della fase stazionaria 
\begin{equation}
  u(Vt, t) = \sqrt{\frac{\pi}{\abs*{\omega''(k_0)}}} \frac{a(k_0)}{\sqrt{t}}e^{it[k_0V - \omega(k_0)]} + O(t^{-1})
\end{equation}
Allora, muovendosi con velocità \(V = \omega'(k_0) = c_g\), in \(x = c_gt\) si osserverà sempre lo stesso numero \(k_0\) di onde. All'aumentare di \(t \to \infty\) l'ampiezza di \(u\) decrescerà fino a \(t^{-\frac{1}{2}}\).
\item[3)] La velocità alla quale l'energia viene trasportata da onde di lunghezza \(\frac{2\pi}{k}\) è pari a \(c_g\). Nel caso del pacchetto (5.5) l'energia sarà proporzionale a 
\[
\int_{k_0 - \delta}^{k_0 + \delta} \abs*{a(k)}^2 \, dk \simeq 2\delta\abs*{a(k_0)}^2  
\]
cosicché la velocità di propagazione sia la stessa di \(k_0\), \(c_g\).
\end{itemize}
Un osservatore di onde d'acqua di superficie tende a concentrare l'attenzione sul movimento delle creste, che si muovono con velocità di fase. Dalla velocità di arrivo dell'energia si può determinare il danno provocato da esplosioni o terremoti. Poiché l'energia viaggia alla velocità di gruppo, vi sono significative differenze nel moto delle onde a seconda che la velocità del gruppo sia maggiore o minore di quella di fase. Nel primo caso l'energia viaggia nella stessa direzione del sistema di creste, nel secondo in quella opposta. Dal momento che 
\[
  \frac{\partial}{\partial k} \frac{\omega (k)}{k} = \frac{k\omega'(k) - \omega(k)}{k^2} = \frac{1}{k}(c_g - c_p)
\]
si osserva che, per \(k > 0\), \(c_g < c_p\) se e solo se la velocità di fase è una funzione decrescente del numero d'onde. \\
Nel caso di onde d'acqua in superficie, esse vengono richiamate all'equilibrio dalla forza di gravità e dalla tensione superficiale. Nel primo caso, si ha \(c_g < c_p\) e le onde aumentano la loro velocità all'aumentare della lunghezza d'onda, mentre nel secondo caso, ossia \(c_g > c_p\) le onde corte tendono a essere le più rapide. 
\subsection{Onde trasversali in una corda}
Nel caso di una corda di violino, si può ricavare un modello per le vibrazioni trasversali che la attraversano, assumendo una serie di ipotesi
\begin{enumerate}
  \item Le vibrazioni sono piccole, dunque la corda viaggia poco rispetto alla sua condizione iniziale.
  \item Lo spostamento di un singolo punto sulla corda si considera lungo una retta.
  \item Lo spostamento di un punto dipende dal tempo e dalla sua posizione lungo la corda; indicando con \(u\) lo spostamento verticale di un punto che si trova in \(x\) quando la corda è a riposo, si ha \(u = u(x,t)\) e, per la prima condizione, \(\abs*{u_x(x,t)} \ll 1\).
  \item La corda non offre nessuna resistenza alla flessione, e si può modellare lo sforzo come una forza \(\bm{T}\) diretta lungo di essa, detta \emph{tensione}.
  \item Si possono trascurare gli attriti.
\end{enumerate}
Con le ipotesi elencate, si può ricavare l'equazione del modo dalla legge di conservazione della massa e dal bilancio dei momenti lineari. Siano \(\rho_0 = \rho_0(x)\) la densità lineare della corda all'equilibrio e \(\rho = \rho(x,t)\) la densità al tempo \(t\). Si consideri un tratto di corda corrispondente a \([x, x+\Delta x]\) e, indicato con \(\Delta s\) l'elemento di lunghezza corrispondente al tempo \(t\). Dalla legge di conservazione della massa si ha 
\begin{equation}
  \rho_0 (x) = \Delta x = \rho(x,t) \Delta s \qquad t \geq 0
\end{equation}
Eguagliando la forza totale agente sul tratto selezionato al tasso di variazione del momento di lineare si ottiene il bilanciamento dei momenti. Dal momento che il moto avviene lungo una retta le componenti devono bilanciarsi. Se \(\tau(x,t)\) indica la tensione in \(x\) si avrà
\[
  \tau(x+\Delta x, t) \cos \alpha (x+\Delta x, t) - \tau(x,t) \cos \alpha (x,t) = 0
\]
che, diviso per \(\Delta x\) e portato al limite \(\Delta x \to 0\) si ha 
\[
  \frac{\partial}{\partial x} [\tau(x,t) \cos \alpha (x,t)] = 0
\]
da cui 
\begin{equation}
  \tau(x,t) \cos \alpha(x,t) = \tau_0(t)
\end{equation}
dove \(\tau_0(t)\) è positiva, essendo l'intensità della componente orizzontale della tensione. \\
La componente verticale della tensione si calcola con la (5.9):
\[
  \tau_{\text{vert}}(x,t) = \tau(x,t) \sin \alpha (x,t) = \tau_0(t) \tan \alpha (x,t) = \tau_0(t) u_x (x,t)
\]
\[
  \tau_{\text{vert}} (x + \Delta x, t) - \tau_{\text{vert}}(x,t) = \tau_0(t) [u_x(x+\Delta x, t) - u_x(x,t)]
\]
Si può considerare \(f(x,t)\) come la risultante di tutte le altre forze verticali presenti. Dalla (5.8) si ottiene la forza agente sul tratto di corda come 
\[
  \rho(x,t)f(x,t)\Delta s = \rho_0(x)f(x,t)\Delta x
\]
La legge di Newton, dalla (5.8), dà:
\[
\rho_0(x)\Delta x u_{tt} = \tau_0(t)[u_x(x+\Delta x) - u_x(x)] + \rho_0 (x)f(x,t) \Delta x
\]
Dividendo per \(\Delta x\) e passando al limite \(\Delta x \to 0\):
\begin{equation}
  u_{tt} - c^2u_{xx} = f
\end{equation} 
 Dove \(c^2(x,t) = \frac{\tau_0(t)}{\rho_0(x)}\). In caso la corda sia omogenea. allora \(\rho_0\) è costante. Può essere costante anche \(\tau_0\) se la corda è perfettamente elastica, ossia la tensione orizzontale è quasi la stessa della corda a riposo. \\
Una corda perfettamente elastica e flessibile si trova a riposo al tempo \(t = 0\) in posizione orizzontale e occupi un segmento \([0, L]\) sull'asse \(x\). Poiché \(u_t(x,t)\) è la velocità di vibrazione del punto \(x\), l'energia cinetica totale della vibrazione si rappresenta come 
\[
  E_{\text{cin}}(t) = \frac{1}{2}\int_0^L \rho_0 u^2_t \, dx
\]
Trattandosi di piccole vibrazioni, la tensione \(\tau\) non dipende da \(x\). La corda inoltre immagazina dell'energia potenziale dovuta al lavoro delle forze elastiche. In un elemento della corda di lunghezza \(\Delta x\), queste forze provocano un allungamento pari a:
\[
  \int_x^{x+\Delta x} \sqrt{1+u^2_x} \, dx - \Delta x = \int_x^{x + \Delta x} \left(\sqrt{1 + u_x^2} - 1\right) \approx \frac{1}{2} u_x^2 \Delta x
\]
Da cui si ottiene il lavoro delle forze elastiche
\[
  dW = \frac{1}{2} \tau_0u^2_x \Delta x
\]
L'energia potenziale si ottiene sommando tutti i contributi degli elementi della corda 
\begin{equation}
  E_{\text{pot}}(t) = \frac{1}{2} \int_0^2 \tau_0 u^2_x \, dx
\end{equation}
Ossia l'energia meccanica totale
\begin{equation}
  E(t) = E_{\text{cin}}(t) + E_{\text{pot}} = \frac{1}{2}\int_0^L [\rho_0 u^2_t + \tau_0 u^2_x] \, dx
\end{equation}
La variazione di energia si calcola derivando sotto il segno di integrale
\[
  \dot{E}(t) = \int_0^L [\rho_0 u_t u_{tt} + \tau_0 u_x u_{xt}] \, dx
\]
Il secondo termine si può integrare per parti, ottenendo
\[
  \int_0^L \tau_0 u_x u_{xt} = \tau_0[u_x(L, t)u_t(L, t) - u_x(0,t)u_t(0,t)] -\tau_0 \int_0^L u_t u_{xx} \, dx
\]
per cui 
\[
  \dot{E}(t) = \int_0^L [\rho_0 u_{tt} - \tau_0 u_{xx}] u_t \, dx + \tau_0[u_x(L, t)u_t(L, t) - u_x(0,t)u_t(0,t)]
\]
Utilizzando la (5.10) si trova
\begin{equation}
  \dot{E}(t) = \int_0^L \rho_0 f u_t \, dx + \tau_0[u_x(L, t)u_t(L, t) - u_x(0,t)u_t(0,t)]
\end{equation}
In particolare, se \(f\) è nulla e agli estremi \(u\) è costante, si deduce che \(\dot{E}(t) = 0\) per cui \(E(t) = E(0)\), che esprime la conservazione dell'energia.
\subsection{L'equazione delle onde unidimensionale}
La (5.10) si chiama equazione delle onde unidimensionale. Il coefficiente \(c\) rappresenta la velocità di perturbazione. Se \(f \equiv 0\), si definisce omogenea l'equazione. Nell'equazione (5.10) appare una derivata seconda rispetto al tempo, quindi è appropriato assegnare,oltre alla posizione della corda, anche una velocità iniziale. Quindi, data una corda che occupa un segmento \([0, L]\) dell'asse \(x\) con condizioni iniziali
\begin{eqnarray*}
  u(x,0) = g(x), & u_t(x,0) = h(x), & x \in [0, L]
\end{eqnarray*}
Per le condizioni al bordo si hanno sempre le stesse opzioni
\begin{itemize}
  \item Condizioni di Dirichlet. Si bloccano gli estremi della corda:
  \[
  u(0,t) = u(L,t) = 0, \qquad t>0  
  \]
  o si descrive il loro movimento verticale
  \[
    u(0,t) = a(t), \quad u(L,t) = b(t), \qquad t > 0
  \]
  \item Condizioni di Neumann. Si descrive la tensione eesercitata agli estremi della corda, come \(\tau_0u_x\), da cui
  \[
    \tau_0u_x(0,t) = a(t), \quad -\tau_0u_x(L,t) = b(t), \qquad t > 0
  \]
  \item Condizioni di Robin. Descrivono la possibilità di avere un attacco elastico agli estremi della corda (per esempio una molla di costante \(k\)), che si traduce in 
  \[
    \tau_0u_x(0,t) = ku_(0,t), \quad \tau_0u_x(L,t) = -ku(L,t), \qquad t > 0
  \]
  \item Condizioni miste. In problemi reali si tende ad assegnare due condizioni diverse ai due estremi.
\end{itemize}
Si può quindi affrontare un problema di Cauchy globale pensando a una corda di lunghezza infinita, e assegnare solo i dati iniziali
\[
  u(x,0) = g(x), \quad u_t(x,0) = h(x), \qquad x \in \mathbb{R}
\]
Anche se si tratta di una situazione puramente teorica, è di vitale importanza la risoluzione del problema di Cauchy globale, come si vedrà in seguito. \\
Risolvendo prima un problema classico si ha il seguente problema di Cauchy-Dirichlet
\begin{equation}
  \begin{cases}
    u_{tt} - c^2u_{xx} = 0 & 0 < x < L, t > 0 \\
    u(0,t) = u(L,t) = 0 & t \geq 0 \\
    u(x,0) = g(x), \, u_t(x,0)=h(x) & 0 \leq x \leq L
  \end{cases}
\end{equation}
con \(c^2 = \frac{\tau_0}{\rho_0}\) costante. \\
Per capire se il problema è ben posto sono necessarie una serie di verifiche:
\begin{itemize}
  \item Esistenza. 
\end{itemize}
Avendo condizioni di Dirichlet omogenee, una soluzione si può ricavare dal metodo di separazione delle variabili. 
\begin{itemize}
  \item[Passo 1.] Si cercano soluzioni della forma 
  \[
  U(x,t) = w(t)v(x) 
  \] 
  con \(v(0) = v(L) = 0\). Sostituendola nell'equazione delle onde 
  \[
  U_{tt}-c^2U_{xx} = w''(t)v(x)-c^2w(t)v''(x) = 0
  \]
  che permette di ottenere, separando le variabili,
  \begin{equation}
    \frac{1}{c^2}\frac{w''(t)}{w(t)} = \frac{v''(x)}{v(x)}
  \end{equation}
  La (5.15) è una identità tra una funzione in variabile \(x\) e una in variabile \(t\). Come sempre avviene se i membri sono uguali a una costante comune \(\lambda\), da cui 
  \begin{equation}
    w''(t)-\lambda c^2 w(t) = 0
  \end{equation}
  da cui si ha il problema agli autovalori 
  \begin{eqnarray}
    v''(x) - \lambda v(x)= 0 \\
    v(0) = v(L) = 0
  \end{eqnarray}
  \item[Passo 2.] Soluzione del problema agli autovalori. Vi sono tre possibili forme di integrale generale per la (5.17).
  \begin{itemize}
    \item[a)] Se \(\lambda = 0, v(x) = A + Bx\) e le condizioni (5.18) implicano che sia \(A\) che \(B\) siano nulle.
    \item[b)] Se \(\lambda = \mu^2 > 0, v(x) = Ae^{-\mu x} + Be^{\mu x}\) e le condizioni (5.18) ancora implicano la nullità di \(A, B\).
    \item[c)] Se \(\lambda = -\mu^2 < 0, v(x) = A\sin \mu x + B\cos \mu x\) e, imponendo (5.18) si ottiene
    \begin{eqnarray*}
      v(0) =  B = 0 \\
      v(L) = A \sin \mu L + B \cos \mu L = 0
    \end{eqnarray*}  
    da cui 
    \[
      A \mbox{ arbitrario,} \, B = 0, \, \mu L = m\pi, ,\ m = 1, 2, \ldots
    \]
    Il terzo caso è l'unico che può produrre soluzioni non nulle del tipo 
  \begin{equation}
    v_m = A_m \sin \mu_m x, \qquad \mu_m = \frac{m\pi}{L}
  \end{equation}  
  \end{itemize}
  \item[Passo 3.] Con valori come \(\lambda = -\mu_m^2 = -\frac{m^2\pi^2}{L^2}\). Come integrale generale della (5.16) si ha 
  \begin{equation}
    u_m(t) = C_m \cos(\mu_m ct) + D_m \sin(\mu_m ct)
  \end{equation}
  Si ottiene così, dalle (5.19) e (5.20), la famiglia di soluzioni 
  \[
    U_m(x,t) = [a_m \cos(\mu_m ct) + b_m \sin(\mu_m ct)] \sin \mu_m x \qquad m= 1, 2, \ldots
  \]
  Ogni \(U_m\) rappresenta un possibile moto della corda e rappresenta un'onda stazionaria di frequenza \(\frac{mc}{2L}\). La prima armonica e la sua frequenza \(\frac{c}{2L}\) si dice fondamentale, mentre le altre sono multipli interi della fondamentale. 
  \item[Passo 4.] Con condizioni inziali del tipo
  \[
    u(x,0) = a_m \sin \mu_m x \qquad u_t(x,0) = cb_m \mu_m \sin \mu_m x
  \] 
  allora \(U_m\) coincide esattamente con la soluzione. L'idea alla base è quella di sovrapporre le infinite armoniche con la formula 
  \begin{equation}
    u(x,t) = \sum_{m=1}^{\infty} [a_m\cos(\mu_m ct) + b_m \sin(\mu_m ct)]\sin \mu_m x
  \end{equation}
  dove \(a_m \mbox{ e } b_m\) devono soddisfare le condizioni in \(0 \leq 0 \leq L\)
  \begin{eqnarray}
    u(x,0) = \sum_{m=1}^{\infty} a_m \sin \mu_m x = g(x) \\
    u_t (x,0) = \sum_{m=1}^{\infty} c\mu_m b_m \sin \mu_m x= h(x)
  \end{eqnarray}
\end{itemize}
Dalle (5.22) e (5.23) si può assumere che le funzioni \(g\) e \(h\) siano sviluppabili in serie di Fourier di soli seni in \([0, L]\). Siano i coefficienti di Fourier
\[
\hat{g}_m = \frac{2}{L} \int_0^L g(x) \sin \left(\frac{m\pi}{L}x\right) \,dx \qquad \hat{h}_m = \frac{2}{L} \int_0^L h(x) \sin \left(\frac{m\pi}{L}x\right) \,dx 
\]
Siano inoltre 
\begin{equation}
  a_m = \hat{g}_m \qquad b_m = \frac{\hat{h}_m}{c\mu_m}
\end{equation}
che trasforma la (5.21) in 
\begin{equation}
  u(x,t) = \sum_{m=1}^{\infty} \left[\hat{g}_m\cos(\mu_m ct) + \frac{\hat{h}_m}{c\mu_m} \sin(\mu_m ct)\right] \sin \mu_m x
\end{equation}
che soddisfa sia la (5.22) che (5.23). \\
Nonostante \(U_m\) sia soluzione regolare dell'equazione delle onde, la (5.25) è una soluzione formale, a meno che non sia possibile derivare due volte rispetto a entrambe le variabili. In tal caso si avrebbe
\begin{equation}
  (\partial_{tt} - c^2\partial^2_{xx})u(x,t) = \sum_{m=1}^{\infty} (\partial_{tt} - c^2\partial_{xx})U_m(x,t) = 0
\end{equation}
Chiaramente ciò può avvenire se \(\hat{g}_m\) e \(\hat{h}_m\) si annullano abbastanza rapidamente per \(m \to \infty\). Derivando due volte si ha infatti
\begin{eqnarray}
  u_{xx}(x,t) - \sum_{m=1}^{\infty} \left[\mu^2_m \hat{g}_m \cos (\mu_m ct) + \frac{\mu_m \hat{h}_m}{c} \sin (\mu_m ct)\right] \sin \mu_m x \\
  u_{tt}(x,t) - \sum_{m=1}^{\infty} \left[\mu^2_m \hat{g}_m c^2\cos (\mu_m ct) + \mu_m \hat{h}_m c \sin (\mu_m ct)\right] \sin \mu_m x
\end{eqnarray}
Per esempio, avendo
\begin{equation}
  \abs*{\hat{g}_m}\leq \frac{K}{m^4}, \qquad \abs*{\hat{h}_m} \leq \frac{K}{m^3}
\end{equation}
si può, per il test di Weierstrass, stabilire che le serie (5.27) e (5.28) convergono uniformemente in \([0, L] \times [0, +\infty)\). Poiché nello stesso intervallo converge uniformemente anche la (5.25) è permessa la derivazione termine a termine.
Dalle stesse ipotesi si può facilmente verificare
\begin{equation}
  u(y,t) \to g(x), \, u_t(y,t) \to h(x), \qquad \mbox{ per } (y,t) \to (x,0)
\end{equation}
per ogni \(x \in [0,L]\) da cui si conclude che \(u\) è soluzione regolare del problema (5.14). 
\begin{itemize}
  \item Unicità.
\end{itemize} 
Per mostrare che la (5.25) sia l'unica soluzione di (5.14) si utilizza la formula dell'energia (5.13). Siano \(u \mbox{ e } v\) soluzioni del problema, allora anche \(w = u - v\) è soluzione con dati iniziali e di Dirichlet nulli. Per mostrrare che \(w \equiv 0\) si utilizza la formula dell'energia meccanica, ricordando la formula
\[
  E(t) = E_{\text{cin}}(t)+ E_{\text{pot}}(t) = \frac{1}{2}\int_0^L [\rho_0 w^2_t + \tau_0 w^2_x] \, dx
\]
Dal momento che \(f\) è nulla e \(w_t(0,t) = w_t(L,t) = 0\) si deduce che \(\dot{E}(t) = 0\), ossia si ha una conservazione dell'energia totale
\begin{equation}
  E(t) = E(0) \qquad \forall t \geq 0
\end{equation}
Inoltre, essendo \(w_t(x,0) = w_x(x, 0) = 0\) si deduce che 
\[
  E(t) = E(0) = 0 \qquad \forall t > 0
\]
che quindi implica \(w_t = w_x = 0\), da cui si è sicuri che la soluzione trovata è l'unica (\(u = v\)).
\begin{itemize}
  \item Dipendenza continua.
\end{itemize}
Stabilire la dipendenza della soluzione dai dati necessita prima di definire il metodo di calcolo della distanza dei dati dalla soluzione corrispondente. Per fare ciò ci sono varie possibilità, come la distanza in media quadratica\footnote{Il simbolo \(\norm*{g}_0\) si legge norma di \(g\) in \(L^2(0, L)\)}:
\[
  \norm*{g_1 - g_2}_0 = \left(\int_0^L \abs*{g_1(x) - g_2(x)}^2 \, dx\right)^{\frac{1}{2}}
\]
Nel caso di funzioni dipendenti dal tempo si può valutare il massimo al variare del tempo della distanza in media quadratica
\[
  \norm*{u - v}_{0, \infty} = \sup_{t > 0}\left(\int_0^L \abs*{u(x,t) - v(x,t)}^2 \, dx\right)^{\frac{1}{2}}
\]
Siano ora \(u_1\) e \(u_2\) soluzioni di (5.14), corrispondenti a \(g_1, g_2 \mbox{ e } h_1, h_2\). Dalla (5.25) si sa che 
\[
w(x,t) = \sum_{m=1}^{\infty} \left[\hat{g}_m \cos (\mu_m ct) + \frac{\hat{h}_m}{\mu_m c} \sin (\mu_m ct)\right]\sin \mu_m x  
\]
Dall'identità di Parseval e grazie alla disuguaglianza \((a+b)^2 \leq 2(a^2+b^")\) si ha
\begin{flalign*}
  \int_0^L \abs*{w(x,t)}^2 \, dx = \frac{L}{2} \sum_{m=1}^{\infty} \left[\hat{g}_m \cos(\mu_m ct) + \frac{\hat{h}_m}{\mu_m c}\sin(\mu_m ct)\right]^2  \\
  \leq L \sum_{m=1}^{\infty}\left[\hat{g}_m^2 + \left(\frac{\hat{h}_m}{\mu_m c}\right)^2\right]
\end{flalign*}
Dal momento che \(\mu_m \geq \frac{\pi}{L}\) si ha 
\begin{flalign*}
  \int_0^L \abs*{w(x,t)}^2 \, dx \leq L \max \left\lbrace1, \frac{L}{\pi c}\right\rbrace \sum_{m=1}^{\infty} \left[\hat{g}_m^2 + \hat{h^2_m}\right] = \\
  = 2 \max \left\lbrace 1, \left(\frac{L}{\pi c}\right)^2 \right\rbrace \left[\norm*{g}^2_0 + \norm*{h}^2_0\right]
\end{flalign*}
da cui si ricava la seguente stima di stabilità
\begin{equation}
  \norm*{u_1 - u_2}^2_{0, \infty} \leq 2 \max \left\lbrace 1, \left(\frac{L}{\pi c}\right)^2 \right\rbrace \left[\norm*{g_1 - g_2}^2_0 + \norm*{h_1 - h_2}^2_0\right]
\end{equation}
che conferma come dei dati ravvicinati producano soluzioni poco distanti tra loro.
\subsection{La formula di d'Alembert}
Per risolvere il problema di Cauchy globale formulato prima ci si avvale della formula di d'Alembert. Dato 
\begin{equation}
  \begin{cases}
    u_{tt} - c^2u_{xx}= 0 & x \in \mathbb{R}, t > 0 \\
    u(x,0) = g(x), u_t(x,0) = h(x) & x \in \mathbb{R}
  \end{cases}
\end{equation}
Fattorizzando l'equazione delle onde come
\begin{equation}
  (\partial_t - c\partial_x)(\partial_t + c\partial_x)u = 0
\end{equation}
e posto 
\begin{equation}
  v  = u_t + cu_x
\end{equation}
allora l'equazione del trasporto è soddisfatta da \(v\) come \(v_t - cv_x = 0\) e, sapendo che si può scrivere \(v(x,t) = \psi(x+ct)\), con \(\psi\) arbitraria e differenziabile. Dalla (5.35) si ha quindi
\[
u_t + cu_x = \phi(x+ct)  
\]
che ha come soluzione generale
\begin{equation}
  \begin{array}{r}
    u(x,t) = \int_0^t \psi(x-c(t-s) + cs) \, ds + \phi(x - ct) = \\
  \underset{x -ct +2cs = y}{=} \frac{1}{2c}\int_{x-ct}^{x+ct} \psi(y) \, dy + \phi(x-ct)
\end{array}
\end{equation}
con \(\psi, \phi\) da scegliersi tramite le condizioni iniziali. Si ottiene cosi
\[
  \begin{array}{c}
  u(x,0) = \phi(x) = g(x), \\
  u_t (x,0) = \psi(x) - c\phi'(x) = h(x) \\
  \Downarrow \\
  \psi(x) = h(x) + cg'(x)
\end{array}
\]
che, nella (5.36), permettono di ottenere 
\[
  \begin{array}{lcl}
    u(x, t) & = & \frac{1}{2c} \int_{x-ct}^{x+ct} [h(y) + cg'(y)] \, dy + g(x - ct) \\
    & = & \frac{1}{2c} \int_{x-ct}^{x+ct}h(y) \, dy + \frac{1}{2} [g(x+ct) - g(x-ct)] + g(x-ct)
  \end{array}
  \]
  che permette di ricavare la \emph{formula di d'Alembert}:
  \begin{equation}
    u(x,t) = \frac{1}{2}[g(x+ct) + g(x-ct)] + \frac{1}{2c}\int_{x-ct}^{x+ct} h(y) \, dy
  \end{equation}
Dalla formmula si evincono alcune informazioni importanti: se \(g\) e \(h\) sono sufficientemente regolari, allora il problema è ben posto. Inoltre non avviene nessun effetto regolarizzante sulla soluzione, che rimane al massimo di classe \(\mathcal{C}^2\) per \(t > 0\). La soluzione poi dipende con continuità dai dati \(h \mbox{ e } g\). Siano \(u_1\) e \(u_2\) le soluzioni corrispondenti a \(g_1, h_1\) e \(g_2, h_2\). Usando la distanza definita come norma in \(L^{\infty}\):
\[
  \norm*{h_1 - h_2}_{\infty} = \sup_{x \in \mathbb{R}} \abs*{h_1(x) - h_2(x)} \qquad \norm*{g_1 - g_2}_{\infty} \sup_{x \in \mathbb{R}}\abs*{g_1(x) - g_2(x)}
\]
Dalla formula di d'Alembert si ha allora
\[
\abs*{u_1(x,t) - u_2(x,t)} \leq \norm*{g_1 - g_2}_{\infty} + T\norm*{h_1 - h_2}_{\infty}  
\]
ossia che data una piccola variazione all'interno dei dati provoca una piccola variazione sulle soluzioni.
Riordinando i termini della (5.36) si ricava la possibilità di riscrivere ogni soluzione nella forma 
\begin{equation}
  u(x,t) = F(x + ct) + G(x-ct)
\end{equation}
ossia come una sovrapposizione di onde progressive che si muovono con stessa velocità in direzioni opposte. Dalla (5.38) si nota che le famiglie di rette di equazioni 
\[
x+ ct = \text{costante}  \qquad  x - ct =\text{costante}
\]
sono le caratteristiche che `trasportano i dati'. \\
Dalla formula di d'Alembert, il valore di \(u\) in \((x,t)\) è determinato dai valori di \(h\) in \([x-ct, x+ct]\) e da quelli di \(g\) agli estremi \(x-ct, x+ct\). Tale intervallo si chiama \emph{dominio di dipendenza} di \((x,t)\). Allo stesso modo, dato un punto \(z, 0\) sempre sull'asse \(x\), i valori di \(g \mbox{ e } h\) influenzano \(u\) nei punti all'interno di \(z - ct \leq x \leq z + ct\), che prende il nome di \emph{dominio di influenza}. Dal punto di vista fisico, il primo dominio indica che il segnale viaggia con velocità \(c\) lungo le due caratteristiche, mentre il secondo indica che una perturbazione inizialmente localizzata in \(z\) non viene avvertita in \(x\) prima dell'istante \(t = \frac{\abs*{x-z}}{c}\).
Derivando il secondo termine della (5.37) rispetto al tempo si ha:
\[
\begin{array}{lcl}
  \frac{\partial}{\partial t}\frac{1}{2c} \int_{x-ct}^{x+ct} h(y) \, dy & = & \frac{1}{2c} [ch(x + ct)-(-c)h(x-ct)] \\
  & = & \frac{1}{2} [h(x + ct) + h(x - ct)]
\end{array}  
\]
che ha forma del primo termine con \(h\) al posto di \(g\). Per risolvere il problema di Cauchy completo allora è sufficiente saperlo risolvere con dati \(u(x,0) = 0, u_t(x,0) = h(x)\). Se \(w_{\phi} = w_{\phi}(x,t)\) indica una soluzione del problema 
\begin{equation}
  \begin{cases}
    w_{tt} - c^2w_{xx} = 0 & x \in \mathbb{R}, t > 0 \\
    w(x,0) = 0, w_t(x,0) = \phi(x) & x \in \mathbb{R}
  \end{cases}
\end{equation}
allora si può riscrivere la (5.37) come
\[
u(x,t) = \frac{1}{2c}\frac{\partial}{\partial t} \int_{x-ct}^{x+ct} g(y) \, dy + \frac{1}{2c} \int_{x-ct}^{x+ct}h(y) \, dy = \frac{\partial}{\partial t} w_g(x,t) + w_h(x,t)  
\]
La formula di d'Alembert ha perfettamente senso per \(g\) continua e \(h\) limitata, ma non è detto sia necessariamente differenziabile. Ripetendo un processo visto in precedenza, si assuma che \(u\) sia una soluzione regolare del problema di Cauchy globale. Sia \(u\) una soluzione classica e \(v\) una funzione di test \(\mathcal{C}^2 (\mathbb{R} \times [0, +\infty))\) a supporto compatto. Moltiplicando le due funzioni e integrando su \(\mathbb{R} \times [0, +\infty)\) si ha 
\[
\int_0^{\infty}\int_{\mathbb{R}} [u_{tt} - c^2u_{xx}]v \, dxdt = 0  
\]
Integrando due volte per parti i termini e essendo \(v\) nulla fuori dal supporto compatto si ha
\[
 \int_0^{\infty} \int_{\mathbb{R}} c^2u_{xx} v \, dxdt = \int_0^{\infty}\int_{\mathbb{R}} c^2uv_{xx} \, dxdt
\]
e 
\[
  \begin{array}{lcl}
    \int_0^{\infty} \int_{\mathbb{R}} u_{tt} v \, dxdt & = & -\int_{\mathbb{R}} u(x,0)v(x,0) \, dx - \int_0^{\infty}\int_{\mathbb{R}}u_tu_v \, dxdt \\
    & = & - \int_{\mathbb{R}}[u_t(x,0)v(x,0) - u(x,0)v_t(x,0)] + \\
    & & +\int_0^{\infty}\int_{\mathbb{R}} uv_{tt} \, dxdt
  \end{array}
\]
Con i dati iniziali \(u(x,0) = g(x), u_t(x,0) = h(x)\) si ottiene 
\begin{equation}
  \int_0^{\infty} \int_{\mathbb{R}} u[v_{tt}- c^2v_{xx}] \, dxdt - \int_{\mathbb{R}} [h(x)v(x,0) - g(x)v_t(x,0)] \, dx = 0
\end{equation}
che ha senso anche per \(u \mbox{ e } g\) continue e \(h\) limitata. Se invece \(u \in \mathcal{C}^2(\mathbb{R} particolare\times [0, +\infty)\) soddisfa la (5.41) per qualsiasi funzione test, allora è soluzione classica di (5.33). 
\begin{definition}
  Siano \(g \in \mathcal{C}(\mathbb{R})\) e \(h\) funzione limitata in \(\mathbb{R}\). Allora \(u\), continua in \(\mathbb{R} \times [0, +\infty)\), è soluzione generalizzata del problema (5.33).
\end{definition}
Risolvere il problema di Cauchy con \(g \equiv 0\) e un dato \(h\) , la delta di Dirac, risulta molto utile, perché permette di ricavare la cosiddetta soluzione fondamentale. Grazie alla soluzione globale si può affrontare il problema di Cauchy globale. Sia \(K = K(x,z,t)\), con la formula di d'Alembert si ha 
\begin{equation}
  K(x,z,t) = \frac{1}{2c} \int_{x-ct}^{x+ct} \delta(y-z) \, dy
\end{equation}
Ritornando a dei concetti visti in precedenza, si può calcolare \(\int_{-\infty}^x\delta(y) \, dy\) grazie alla funzione di Heaviside
\[
\mathcal{H}(x) = \begin{cases}
  1 & \text{se }x \geq 0 \\
  0 & \text{se } x < 0
\end{cases}
\]
e 
\begin{equation}
  I_{\epsilon}(x) = \frac{\mathcal{H}(x + \epsilon) - \mathcal{H}(x - \epsilon)}{2\epsilon} = \begin{cases}
    \frac{1}{2\epsilon} &\mbox{se } -\epsilon \leq x < \epsilon \\
    0 &\mbox{altrove}  
  \end{cases}
\end{equation}
descrive un impulso unitario di durata \(\epsilon\). Si può allora calcolare \(\int_{-\infty}^x \delta(y)\, dy\) grazie a 
\[
 \int_{-\infty}^x \delta(y) \, dy =\lim_{\epsilon \to 0} \int_{-\infty}^x I_{\epsilon} (y) \, dy
\]
Se \(x < -\epsilon, \int_{-\infty}^x I_{\epsilon}(y) \, dy = 0\), mentre se \(x > \epsilon, \int_{-\infty}^x I_{\epsilon}(y) \, dy = 1\). Si ottiene quindi
\begin{equation}
  \int_{-\infty}^x \delta(y) \, dy = \mathcal{H}(x)
\end{equation}
Si può riscrivere 
\[
  \int_{x-ct}^{x+ct} \delta(y-z) \, dy = \int_{-\infty}^{x-ct} \delta(y-z) \, dy - \int_{-\infty}^{x-ct} \delta(y-z) \, dy
\]
da cui si ricava facilmente
\begin{equation}
  K(x,z,t) = \frac{1}{2c}\left\lbrace \mathcal{H}(x-z+ct) - \mathcal{H}(x-z-ct)\right\rbrace
\end{equation}
La funzione \(K\) è la soluzione fondamentale dell'equazione delle onde unidimensionale. \\
Vi è anche un'altra casistica, nel caso il problema non sia omogeneo. Per esempio
\begin{equation}
  \begin{cases}
    u_{tt} - c^2 u_{xx} = f(x,t) & x \in \mathbb{R}, t > 0 \\
    u(x,0) = 0, u_t(x,0)= 0 & x \in \mathbb{R}
  \end{cases}
\end{equation}
Tale problema si risolve con il metodo di Duhamel. \\
Ricordando che in caso si abbia un problema 
\[
  \begin{cases} 
y'(t) + ay(t) = f(t) & t > 0 \\
y(0) = 0  
\end{cases}
\]
Si risolve con 
\[
  y(t) = \int_0^t \underbrace{e^{-a(t-s)}f(s)}_{w(t;s)} \, ds
\]
trattando \(s\) come un parametro (\(0 \leq s \leq t\))
\[
  w(t;s) = e^{-a(t-s)}f(s)
\]
si ottiene che \(w\) soddisfa il problema di Cauchy omogeneo avente il secondo membro dell'ultima equazoine come dato inziale (calcolato in \(t=s\))
\[
\begin{cases}
  w_t + aw = 0 & t > s \\
  w(s;s) = f(s) & t = s
\end{cases}  
\]
allora si può risolvere il problema in \(w\) e ottenere la soluzione 
\[
  y(t) = \int_0^t w(t;s)ds
\]
Considerando il problema (5.45), fissato \(s\), sia \(w = w(x, t; s)\) soluzione del problema si ha
\[
\begin{cases}
  w_{tt} - c^2w_{xx} = f(x,t) & x \in \mathbb{R}, t > 0 \\
  w(x, s; s) = 0, w_t(x, s; s) = f(x,s) & x \in \mathbb{R}
\end{cases}  
\]
Poiché l'equazione delle onde è invariante a qualsiasi tipo di traslazione, si ha dalla formula di d'Alembert
\[
w(x,t;s) = \frac{1}{2c} \int_{x-c(t-s)}^{x+c(t-s)} f(y,s) \, dy  
\]
La soluzione di (5.45) allora è
\[
  u(x,t) = \int_0^t w(x,t;s) \, ds = \frac{1}{2c} \int_0^t \, ds \int_{x-c(t-s)}^{x+c(t-s)} f(y,s) \, dy
\]
infatti 
\begin{eqnarray*}
  u(x,0) = 0 \\
  u_t(x,t) = w(x, t; t) + \int_0^t w_t(x, t; s) \, ds = \int_0^t \int_0^t w_t(x, t; s) \, ds
\end{eqnarray*}
dal momento che \(w(x,t;t) = 0\). Di conseguenza anche \(u_t(x,0)\) è nullo. Si ha poi 
\begin{eqnarray*}
  u_{tt}(x,t) = w_{t}(x,t;t) + \int_0^t w_{tt}(x,t;s) \, ds = f(x,t) + \int_0^t w_{tt} (x,t;s) \, ds \\
  u_{xx}(x,t) = \int_0^t w_{xx}(x,t;s) \, ds
\end{eqnarray*}
e segue, dal momento che \(w_{tt} - c^2w_{xx} = 0\), 
\[
\begin{array}{c}
  u_{tt} (x,t)-c^2u_{xx} (x,t) = f(x,t) + \int_0^tw_{tt}(x,t;s) \, ds - c^2 \int_0^t w_{xx}(x,t;s) \, ds = \\
  = f(x,t)
\end{array}  
\]
che è l'unica soluzione \(\mathcal{C}^2(\mathbb{R} \times [0, +\infty))\).
\section{Analisi funzionale}
Sia \(X\) uno spazio vettoriale normato reale, allora si definisce norma un operatore \(\norm*{\cdot}:X \to \mathbb{R}\) tale che 
\begin{itemize}
  \item \(\norm*{x} \geq 0, \forall x \in X\) e \(\norm*{x} = 0 \Leftrightarrow x = 0\)
  \item \(\norm{\lambda x} = \abs*{\lambda}\norm*{x}, \forall x \in X, \forall \lambda \in \mathbb{R}\)
  \item \(\norm*{x + y} \leq \norm*{x}+\norm*{y}\)
\end{itemize}
Grazie alla norma si possono calcolare le distanze e la topologia degli insiemi (aperto, chiuso, \(\ldots\)). \\
Sia \(\{x_n\} \subset X\) una successione, allora si possono definire la convergenza
\[
x_n \to \overline{x} \mbox{ per } n \to +\infty \mbox{ se }\norm*{x_n - \overline{x}} \to 0  
\] 
e da essa si può definire anche la continuità
\[
f: X \to Y \mbox{ è continua se } x_n \to \overline{x} \Rightarrow f(x_n) \to f(\overline{x})  
\]
Una successione si può definire di Cauchy se
\[
  \norm*{x_n - x_m} \to 0 \qquad \mbox{ per } n,m \to \infty
\]
Si può affermare che se una successione è convergente, allora è di Cauchy, ma più interessante è poter affermare il contrario, infatti se, in uno spazio \(X\) una successione di Cauchy implica la convergenza, allora tale spazio è completo. \\
Si parla di Spazi di Banach quando si trattano spazi vettoriali normati e completi rispetto a quella norma, mentre spazi vettoriali, con prodotto scalare e completi rispetto alla norma indotta da tale prodotto sono detti Spazi di Hilbert.
\begin{theorem}[Teorema delle Proiezioni]
  Sia \(H\) uno spazio di Hilbert, \(V\) un sottospazio vettoriale di \(H\) chiuso e \(x \in H\). Allora \(\exists! P_V x \in V\) tale che 
  \[
    \norm*{P_V x - x} = \inf_{v \in V} \norm*{v - x}
  \]
  Sapendo anche che 
  \begin{enumerate}
    \item \(x \in V \Leftrightarrow x = P_Vx\)
    \item Definendo \(Q_V x = x x- P_V x\) si ottiene \((Q_V x, v) = 0, \forall v \in V\), ossia \(Q_V x \in V^{\perp}\) e: \[\norm*{x}^2 = \norm*{P_V x}^2 + \norm*{Q_V x}^2\]
  \end{enumerate}
\end{theorem}
\begin{proof}
  La dimostrazione di questo teorema è da eseguirsi seguendo diversi passi. Partendo dall'esistenza si ha 
  \[
  d= \inf_{v \in V} \norm*{v - x}, \, d \geq 0
  \]
  ovvero
  \begin{enumerate}
    \item \(\norm*{v - x} \geq d, \forall v \in V\)
    \item \(\forall \epsilon \, \exists\epsilon \in V \mbox{ tale che } \norm*{v_{\epsilon} - x} \leq d + \epsilon\)
  \end{enumerate}
  che è la definizione di \(\inf\). Utilizzandola per costruire una successione 
  \begin{equation}
    (v_n)_{n \in \mathbb{N}} \subset V \, : \, d \leq\norm*{x - v_n} \leq d + \frac{1}{n} \qquad \left(\epsilon = \frac{1}{n}, n \in \mathbb{N}\right)
    \end{equation}
    per poi verificarne la convergenza. Per farlo bisogna dimostrare che sia una succesione di Cauchy. Usando la seguente identità
    \[
      \norm*{a - b}^2 = 2\norm*{a}^2 + 2\norm*{b}^2 - \norm*{a + b}^2
    \]
    con \(a = v_n - x, b = v_m\) si ottiene
    \[
      \begin{array}{c}
      \norm*{a - b}^2 = \norm*{v_n - v_m}^2 \\
      \norm*{a + b}^2 = \norm*{v_n + v_m - 2x}^2 = 4\left\|\underbrace{\frac{v_n + v_m}{2}}_{\in V} - x \right\|^2 \geq 4d^2
    \end{array} 
    \]
    dove la disuguaglianza finale vale perché si ha \(\norm*{v - x} \geq d, \forall v \in V\) e \(\frac{v_n + v_m}{2} \in V\), essendo \(V\) un sottospazio.
    La norma di \(a \mbox{ e di } b\) tenderà a \(d\), allora si ha 
    \[
    \begin{array}{lcl}
      \norm*{v_n - v_m}^2 & = & 2\norm*{v_n - x}^2 + 2\norm*{v_m - x} - \norm*{v_n + v_m - 2x}^2 \\
      & \leq & 2\norm*{v_n - x}^2 + 2\norm*{v_m -x} - 4d^2
    \end{array}
    \]
    Passando al limite per \(m,n \to \infty\) si ottiene che il secondo membro della disuguaglianza tende a \(0\), forzando 
    \[
     \norm*{v_ - v_m} \to 0
    \]
    Allora si può affermare che la successione sia di Cauchy. Poiché \(H\) è uno spazio di Hilbert, \(v_n\) converge a un elemento \(v \in H\), che, essendo \(V\) chiuso, appartiene anche a \(V\).
    Si deduce dalla continuità della norma che 
    \[
    \norm*{v_n - x} \to \norm*{v - x} = d  
    \]
    quindi \(v\) realizza la minima distanza da \(x\).
    Va ora verificato che l'elemento \(v\) tale che \(\norm*{v - x} = d\) sia unico. Se ci fosse un elemento \(w \in V\) tale per cui \(\norm*{w - x} = d\) si avrebbe
    \[
    \begin{array}{lcl}
      \norm*{w -v}^2 & = & 2\norm*{w - x}^2 + 2\norm*{v - x} - 4\left\|\frac{w+v}{2} -x \right\|^2 \\
      & \leq & 2d^2 + 2d^2 - 4d^2 = 0
    \end{array}
    \]
    per cui gli elementi coincidono. Esiste quindi un solo elemento \(v = P_V x \in V\) tale che 
    \[
      \norm*{x - P_V x} = d
    \]
    Poiché \(V\) è un insieme chiuso, \(x \in V \Leftrightarrow d = 0\), ossia solo se \(x = P_V x\).
    Per mostrare che \(x - P_Vx \in V^{\perp}\), si prendono \(Q_V = x- P_V x, \, w \in V\) e \(t \in \mathbb{R}\). Sapendo che \(P_V x + tw \in V\) per ogni \(t\) si ottiene
    \[
    \begin{array}{lcl}
      d^2 & \leq & \norm*{x - (P_V x + tw)}^2 = \norm*{Q_V x - tw}^2 \\
      & = & \norm*{Q_Vx}^2 - 2t (Q_Vx, w) + t^2\norm*{w}^2 \\
      & = & d^2 - 2t(Q_V x, w) + t^2 \norm*{w}^2
    \end{array}  
    \]
    ossia 
    \[
    P(t) \equiv t^2 \norm*{w}^2 - 2t (Q_V x, w)  \geq 0 
    \]
    Tale trinomio è sempre non negativo e deve avere allora un discriminante non positivo, da cui \((Q_V x, w)^2 \leq 0\). Pertanto per ogni \(w \in V\) si ha \((Q_V x, w) = 0\), che implica \(Q_V x \in V^{\perp}\). ALlora anche 
    \[\norm*{x}^2 = \norm*{P_V x + Q_V x}^2 =\norm*{P_V x}^2 + \norm*{Q_V x}^2\]
\end{proof}
Nel caso di spazi \(H_2= \mathbb{R}\) si utilizza il termine funzionale al posto di operatore.
\begin{definition}
  L'insieme dei funzionali lineari e continui su uno spazion di Hilbert \(H\) prende il nome di spazio duale di \(H\) e si indica con \(H^*\). La sua norma \(L \in H^*\) si indica come \(\norm*{L}_{H^*}\).
  \[
  \norm*{L}_{H^*} = \sup_{\norm*{x}  = 1} \abs*{Lx}
  \]
\end{definition}
Determinare il duale di uno spazio di Hilbert è un problema che verrà risolto dal teorema di rappresentazione di Riesz. 
\begin{theorem}[Teorema di Rappresentazione di Riesz]
  Sia \(H\) uno spazio di Hilbert, per ogni \(L \in H^*\) esiste un unico elemento \(u_L \in H\) tale che 
  \begin{equation}
    Lx = (u_L, x) \qquad \mbox{ per ogni } x \in H
  \end{equation}
  Inoltre si ha 
  \begin{equation}
    \norm*{L}_{H^*} = \norm*{u_L}
  \end{equation}
\end{theorem}
\begin{proof}
  Per dimostrare l'esistenza di \(u_L\), sia \(\mathcal{N}\) il nucleo di L. Se \(\mathcal{N} = H\), la tesi segue scegliendo \(u_L = 0\). Se \(\mathcal{N} \subset H\), allora è anche un sottospazio chiuso di \(H\). \\
  Grazie al teorema di Proiezione si deduce che esiste un elemento \(z\) non nullo appartenente a \(\mathcal{N}^{\perp}\). Allora \(Lz \not = 0\) e, dato un qualunque elemento \(x \in H\), \(w = x - \frac{Lx}{Lz}z \in \mathcal{N}\). Si ha infatti 
  \[
    Lw = L\left(x - \frac{Lx}{Lz}z\right) = Lx - \frac{Lx}{Lz}Lz =0
  \]
  Inoltre, essendo \(z \in \mathcal{N}^{\perp}\), si ha 
  \[
  0 = (z,w) = (z,x) -\frac{Lx}{Lz}\norm*{z}^2 \qquad Lx = \frac{L(z)}{\norm*{z}^2}(z,x)
  \]
  La (6.2) vale con \(u_L = \frac{L(z)}{\norm*{z}^2}z\).
  Se non fosse unico, si avrebbe un elemento \(x \in H, v \not = u_L\) tale che 
  \[
    Lx = (v,x) \qquad \mbox{ per ogni }x \in H
  \]
  che sottratta alla (6.2) darebbe
  \[
  (u_L -v, x) = 0 \qquad \mbox{ per ogni } x \in H  
  \]
  che implica \(v = u_L\). Segue quindi che, essendo \(L = L_{u_L}\), è verificata anche \(\norm*{L}_{H^*} = \norm*{u_L}\)
\end{proof}
Un ruolo importante nella formulazione dei problemi al contorno, è svolto dalle forme bilineari. Siano \(V_1, V_2\) spazi pre-Hilbertiani, una funzione
\[
  a: V_1 \times V_2 \to \mathbb{R}
\]
si definisce forma bilineare in \(V_1 \times V_2\) e soddisfa le seguenti proprietà:
\begin{itemize}
  \item per ogni \(y \in V_2\) fissato, la funzione \(x \longrightarrow a(x,y)\) è lineare su \(V_1\)
  \item per ogni \(x \in V_1\) fissato, la funzione \(y \longrightarrow a(x,y)\) è lineare su \(V_2\)
\end{itemize}
Nel caso particolare \(V_1 = V_2\) si parla di forma bilineare in \(V\), anziché in \(V \times V\). \\
In uno spazio \(V\) di Hilbert, sia \(a = a(u,v)\) una forma bilineare in \(V\) e \(F \in V^*\). Si consideri il seguente problema definito come problema variazionale astratto 
\begin{equation}
  \begin{cases}
    \mbox{Trovare } u \in V \\
    \mbox{tale che} \\
    a(u,v) = \langle F,v \rangle_* & \forall v \in V
  \end{cases}
\end{equation}
Molti problemi per equazioni differenziali possono essere formulati in questo modo, e si può utilizzare un teorema fondamentale per risolverli.
\begin{theorem}{Teorema di Lax-Milgram}
  Sia \(V\) uno spazio di Hilbert reale, con prodotto interno \((\cdot, \cdot)\) e norma \(\norm*{\cdot}\). Siano \(a = a(u,v)\) una forma bilineare in \(V\) e \(F \in V^*\). Se 
  \begin{itemize}
    \item[i)] \(a\) è continua, cioè si può trovare una costante postiva \(M\) tale che 
    \[
      \abs*{a(u,v)} \leq M\norm*{u}\norm*{v}, \qquad \forall u, v \in V
    \]
    \item[ii)] \(a\) è \(V\)-coerciva, ossia esiste una costante \(\alpha > 0\) tale che
    \[
      a(v,v) \geq \alpha\norm*{v}^2, \qquad \forall v \in V
    \]
  \end{itemize}
  Allora esiste una unica soluzione \(\overline{u} \in V\) del problema (6.4). Inoltre vale la stima di stabilità
  \begin{equation}
    \norm*{\overline{u}} \leq \frac{1}{\alpha} \norm*{F}_{V^*}
  \end{equation}
\end{theorem}
\begin{proof}
  Per prima cosa bisogna riscrivere il problema (6.4), quindi per ogni \(u \in V\) fissato, dalla continuità di \(a\) segue che 
  \[
  v \rightarrow a(u,v)  
  \]
  è una applicazione lineare, continua in \(V\) e definisce un elemento di \(V^*\). Come visto nel teorema di Rappresentazione di Riesz, esiste un unico elemento \(A[u] \in V\) tale che 
  \begin{equation}
    a(u,v) = (A[u],v), \qquad \forall v \in V
  \end{equation}
  In maniera analoga, essendo \(F \in V^*\), esiste un unico \(z_F \in V\) tale che 
  \[
    \langle F, v \rangle_* = (z_F, v) \qquad \forall v \in V
  \]
  e inoltre, \(\norm*{F}_{V^*} = \norm*{z_F}\). Il problema (6.4) diventa
  \[
    \begin{cases}
      \mbox{Trovare } u \in V \\
      \mbox{tale che} \\
      (A[u], v) = (z_F,v) & \forall v \in V
    \end{cases}  
  \]
  che equivale a trovare \(u\) tale che 
  \begin{equation}
    A[u] = z_F
  \end{equation}
  Per vedere quante soluzioni ha la (6.7) bisogna fare prima una serie di passaggi. Per prima cosa si mostra che 
  \[
  A :  V \to V  
  \]
è un operatore lineare, continuo, iniettivo e suriettivo. \\
Per mostrare la linearità e continuità di \(A\), si ha, per ogni \(u_1, u_2 , v \in V\) e \(\lambda_1,\lambda_2 \in \mathbb{R}\):
\begin{flalign*}
  (A[\lambda_1 u_1 + \lambda_2], v) = a(\lambda_1 u_1 + \lambda_2 u_2, v) = \lambda_1 a(u_1, v) + \lambda_2 a(u_2,v) =\\
  =\lambda_1(A[u_1],v) + \lambda_2(A[u_2], v) + \lambda_2(A[u_2], v) = (\lambda_1 A[u_1] + \lambda_2 A[u_2],v)
\end{flalign*}
da cui si ricava
\[
  A[\lambda_1 u_1 + \lambda_2 u_2] = \lambda_1 A[u_1] + \lambda_2 A[u_2]
\]
Allora \(A\) è lineare e si può scrivere direttamente \(Au\), invece di \(A[u]\). Per dimostrare la continuità si veda che 
\[\begin{array}{c}
  

\begin{array}{lcl}
  \norm*{Au}^2 & = & (Au, Au) = a(u, Au) \\
  & \leq & M \leq \norm*{u}\norm*{Au} \\
\end{array} \\
\begin{array}{ccc}
  & &\Downarrow \\
\end{array} \\
\begin{array}{lcl}
  &  &\norm*{Au} \leq M \norm*{u} 
\end{array}  
\end{array}
\]
Bisogna poi verificare che \(A\) sia iniettivo e a immagine chiusa, ossia 
\[
\mathcal{N}(A) = \{0\} \qquad \mbox{ e } \qquad \mathcal{R}(A) \mbox{ è un sottospazio chiuso di }V  
\]
Dalla coercività di \(a\) è possibile ricavare infatti
\[
  \alpha\norm*{u}^2 \leq a(u,u) = A(Au, u) \leq \norm*{Au} \norm*{u}
\]
da cui
\begin{equation}
  \norm*{u}\leq\frac{1}{\alpha} \norm*{Au}
\end{equation}
Se perciò \(Au = 0\), deve essere \(u = 0\) e quindi \(\mathcal{N}(A) = \{0\}\).
Occorre mostrare che \(\mathcal{R}(A)\) è un sottospazio chiuso. Per farlo si considera una successione \(\{y_m\} \subset \mathcal{R}\) tale che \(y_m \to t \in V\) per \(m \to \infty\) e che si abbia \(y \in \mathcal{R}(A)\).
Dal momento che \(y_m \in \mathcal{R}(A)\), si ha \(u_m\) tale che \(Au_m = y_m\). Dalla (6.8) si ottiene
\[
 \norm*{u_k - u_m} \leq \frac{1}{\alpha}\norm*{y_k - y_m} 
\]
per cui, essendo \(\{y_m\}\) di Cauchy, lo è anche \(\{u_m\}\). Poiché \(V\) è completo, esiste \(u \in V\) tale che 
\[
  u_m \to u
\]
e la continuità di \(A\) implica che \(y_m = Au_m \to Au\). Si deve quindi avere \(Au = y\), per cui \(y \in \mathcal{R}(A)\), il quale è chiuso. \\
Per verficare che \(A\) sia un operatore suriettivo, ossia che \(\mathcal{R}(A) = V\), si immagini, per assurdo, che \(\mathcal{R}(A) \subset V\). Essendo \(\mathcal{R}(A)\) un sottospazio chiuso, si ha, per il Teorema di Proiezione, che esiste \(z \not = 0, z \in \mathcal{R}(A)^{\perp}\). Ciò implica che 
\[
  0 = (Az, z) = a(z,z) \geq a\norm*{z}^2
\]
da cui si ha \(z = 0\) che contraddice tutto. ALlora \(\mathcal{R}(A) = V\). \\
Come accennato prima, il numero di soluzioni della (6.7) si ricava dal fatto che \(A\) è iniettivo e suriettivo. Per questo esiste ed è unico \(\overline{u} \in V\) tale che \(A\overline{u} = z_F\). Come già visto, allora \(\overline{u}\) è anche l'unica soluzione del problema (6.4). \\
Inoltre dalla (6.8) è possibile ricavare, con \(u = \overline{u}\),
\[
\norm*{\overline{u}} \leq \frac{1}{\alpha} \norm*{A\overline{u}} = \frac{1}{\alpha} \norm*{z_F} = \frac{1}{\alpha}\norm*{F}_{V^*}  
\]
che porta a termine tutta la dimostrazione.
\end{proof}
Sia \(\Omega \subseteq \mathbb{R}^n\). Dato uno spazio di Sobolev\footnote{Si possono definire in maniera poco formale come `spazi di funzioni \(L^p\) aventi derivate \(L^p\)'} \(H^1(\Omega)\), sia \(H^1_0(\Omega)\) la chiusura di \(\mathcal{D}(\Omega)\). Quindi si ha \(u \in H^1_0(\Omega) \Leftrightarrow \exists \{\phi_k\}\subset \mathcal{D}(\Omega)\) tale che \(\phi_k \to u\) in \(H^1(\Omega)\), ossia \(\norm*{\phi_k - u}_0 \to 0\) e \(\norm*{\nabla\phi_k - \nabla u}_0 \to 0\) per \(k \to \infty\).In particolare per gli elementi di \(H^1_0(\Omega)\), vale la disuguaglianza di Poincaré, utile per la soluzione di problemi al contorno di equazioni alle derivate parziali.
\begin{theorem}[Disuguaglianza di Poincaré]
  Sia \(\Omega \subset \mathbb{R}^n\) un dominio limitato. Esiste una costante positiva (detta di Poincaré) \(C_P\) che dipende solo da \(n\) e da \(\Omega\) tale che, \(\forall u \in H^1_0(\Omega)\)
  \begin{equation}
    \norm*{u}_0 \leq C_P \norm*{\nabla u}_0
  \end{equation}
  \begin{proof}
    Generalmente per dimostrare le disuguaglianze in \(H^1_0(\Omega)\) si immagina di aver dimostrato la formula (6.9) \(\forall v \in \mathcal{D}(\Omega)\) per poi estenderla a ogni \(u \in H^1_0(\Omega)\). Per fare questo si prende una successione \(\{v_k\} \subset \mathcal{D}(\Omega)\) che converge a \(u\) in \(H^1_0(\Omega)\) per \(k \to \infty \), ossia 
    \[
      \norm*{v_k - u}_0 \to 0, \qquad \norm*{\nabla v_k - \nabla u}_0 \to 0
    \]
    In particolare si ha 
    \[
    \norm*{v_k}_0 \to \norm*{u}_0, \qquad \norm*{\nabla v_k}_0 \to \norm*{\nabla u}_0
    \]
    e, sapendo che la (6.9) è vera per le \(v_k\), si ricava
    \[
      \norm*{v_k}_0 \leq C_P \norm*{\nabla v_k}_0
    \]
    Passando al limite per \(k \to \infty\) si ottiene appunto la (6.9) per \(u\). Allora è necessario mostrare che sia vera \(\forall v \in \mathcal{D}(\Omega)\). A tale scopo si ha, dal teorema della divergenza ed essendo \(v\) nullo sulla frontiera di \(\Omega\)
    \begin{equation}
      \int_{\Omega} div(v^2\bm{x}) \, d\bm{x} = 0
    \end{equation}
    E poiché \(div(v^2\bm{x})\,d\bm{x} = 2v\nabla v \cdot \bm{x} + nv^2\), dalla (6.10) si deduce 
    \[
      \int_{\Omega} v^2\, d\bm{x} = -\frac{2}{n} \int_{\Omega} v\nabla v \cdot \bm{x} \, dx
    \]
    Dal momento che \(\Omega\) è limitato, si ha {\everymath{\displaystyle}\(\max_{\bm{x} \in \Omega} = M < \infty\)}, e, per la disuguaglianza di Schwartz
    \[
    \int_{\Omega} v^2 \, d\bm{x} \leq \frac{2}{n}\left|\int_{\Omega} v\nabla v \cdot \bm{x} \, d\bm{x} \right| \leq \frac{2M}{n}\left(\int_{\Omega} v^2 \, d\bm{x}\right)^{\frac{1}{2}}\left(\int_{\Omega} \abs*{\nabla v}^2 \, d\bm{x}\right)^{\frac{1}{2}}  
    \]
  Dopo aver semplificato per 
  \[
  \left(\int_{\Omega} v^2 \, d\bm{x}\right)^{\frac{1}{2}}  
  \]
  si ha 
  \[
  \norm*{v}_0 \leq C_P \norm*{\nabla v}_0 \qquad C_P = \frac{2M}{n}  
  \]
  \end{proof}
\end{theorem}
\end{document}